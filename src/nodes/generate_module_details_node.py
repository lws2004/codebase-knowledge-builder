"""ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£èŠ‚ç‚¹ï¼Œç”¨äºç”Ÿæˆä»£ç åº“ä¸­å„æ¨¡å—çš„è¯¦ç»†æ–‡æ¡£ã€‚"""

import asyncio
import json
import os
import re
from typing import Any, Dict, List, Optional, Tuple

from pocketflow import AsyncNode
from pydantic import BaseModel, Field

from ..utils.llm_wrapper import LLMClient
from ..utils.logger import log_and_notify


class GenerateModuleDetailsNodeConfig(BaseModel):
    """GenerateModuleDetailsNode é…ç½®"""

    retry_count: int = Field(3, ge=1, le=10, description="é‡è¯•æ¬¡æ•°")
    quality_threshold: float = Field(0.7, ge=0, le=1.0, description="è´¨é‡é˜ˆå€¼")
    model: str = Field("", description="LLM æ¨¡å‹ï¼Œä»é…ç½®ä¸­è·å–ï¼Œä¸åº”è®¾ç½®é»˜è®¤å€¼")
    output_format: str = Field("markdown", description="è¾“å‡ºæ ¼å¼")
    max_modules_per_batch: int = Field(5, description="æ¯æ‰¹æœ€å¤§æ¨¡å—æ•°")
    module_details_prompt_template: str = Field(
        """
        ä½ æ˜¯ä¸€ä¸ªä»£ç åº“æ–‡æ¡£ä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹æ¨¡å—ç”Ÿæˆè¯¦ç»†çš„æ–‡æ¡£ã€‚

        æ¨¡å—ä¿¡æ¯:
        {module_info}

        ä»£ç å†…å®¹:
        {code_content}

        è¯·æä¾›ä»¥ä¸‹å†…å®¹:
        1. æ¨¡å—æ¦‚è¿°
           - æ¨¡å—åç§°å’Œè·¯å¾„
           - æ¨¡å—çš„ä¸»è¦åŠŸèƒ½å’Œç”¨é€”
           - æ¨¡å—åœ¨æ•´ä¸ªä»£ç åº“ä¸­çš„è§’è‰²
        2. ç±»å’Œå‡½æ•°è¯¦è§£
           - æ¯ä¸ªç±»çš„åŠŸèƒ½ã€å±æ€§å’Œæ–¹æ³•
           - æ¯ä¸ªå‡½æ•°çš„åŠŸèƒ½ã€å‚æ•°å’Œè¿”å›å€¼
           - é‡è¦çš„ä»£ç ç‰‡æ®µè§£é‡Š
        3. ä½¿ç”¨ç¤ºä¾‹
           - å¦‚ä½•ä½¿ç”¨è¯¥æ¨¡å—çš„ä¸»è¦åŠŸèƒ½
           - å¸¸è§ç”¨ä¾‹å’Œæ¨¡å¼
        4. ä¾èµ–å…³ç³»
           - è¯¥æ¨¡å—ä¾èµ–çš„å…¶ä»–æ¨¡å—
           - ä¾èµ–è¯¥æ¨¡å—çš„å…¶ä»–æ¨¡å—
        5. æ³¨æ„äº‹é¡¹å’Œæœ€ä½³å®è·µ
           - ä½¿ç”¨è¯¥æ¨¡å—æ—¶éœ€è¦æ³¨æ„çš„äº‹é¡¹
           - æ¨èçš„æœ€ä½³å®è·µ

        è¯·ä»¥ Markdown æ ¼å¼è¾“å‡ºï¼Œä½¿ç”¨é€‚å½“çš„æ ‡é¢˜ã€åˆ—è¡¨ã€è¡¨æ ¼å’Œä»£ç å—ã€‚
        ä½¿ç”¨è¡¨æƒ…ç¬¦å·ä½¿æ–‡æ¡£æ›´åŠ ç”ŸåŠ¨ï¼Œä¾‹å¦‚åœ¨æ ‡é¢˜å‰ä½¿ç”¨é€‚å½“çš„è¡¨æƒ…ç¬¦å·ã€‚
        ç¡®ä¿æ–‡æ¡£ä¸­çš„ä»£ç å¼•ç”¨èƒ½å¤Ÿé“¾æ¥åˆ°æºä»£ç ã€‚
        """,
        description="æ¨¡å—è¯¦ç»†æ–‡æ¡£æç¤ºæ¨¡æ¿",
    )


class AsyncGenerateModuleDetailsNode(AsyncNode):
    """ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£èŠ‚ç‚¹ï¼ˆå¼‚æ­¥ï¼‰ï¼Œç”¨äºå¹¶è¡Œç”Ÿæˆä»£ç åº“ä¸­å„æ¨¡å—çš„è¯¦ç»†æ–‡æ¡£"""

    llm_client: Optional[LLMClient] = None

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """åˆå§‹åŒ–ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£èŠ‚ç‚¹ (å¼‚æ­¥)

        Args:
            config: èŠ‚ç‚¹é…ç½®
        """
        super().__init__()
        from ..utils.env_manager import get_node_config

        default_config = get_node_config("generate_module_details")
        merged_config = default_config.copy()
        if config:
            merged_config.update(config)
        self.config = GenerateModuleDetailsNodeConfig(**merged_config)
        log_and_notify("åˆå§‹åŒ– AsyncGenerateModuleDetailsNode", "info")

    async def prep_async(self, shared: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡é˜¶æ®µï¼Œä»å…±äº«å­˜å‚¨ä¸­è·å–æ ¸å¿ƒæ¨¡å—å’Œä»£ç ç»“æ„

        Args:
            shared: å…±äº«å­˜å‚¨

        Returns:
            åŒ…å«æ ¸å¿ƒæ¨¡å—å’Œä»£ç ç»“æ„çš„å­—å…¸
        """
        log_and_notify("AsyncGenerateModuleDetailsNode: å‡†å¤‡é˜¶æ®µå¼€å§‹", "info")

        core_modules_data = shared.get("core_modules")
        if not core_modules_data or not core_modules_data.get("success", False):
            error_msg = "å…±äº«å­˜å‚¨ä¸­ç¼ºå°‘æœ‰æ•ˆæ ¸å¿ƒæ¨¡å—æ•°æ®"
            log_and_notify(error_msg, "error", notify=True)
            return {"error": error_msg}

        code_structure = shared.get("code_structure")
        if not code_structure or not code_structure.get("success", False):
            error_msg = "å…±äº«å­˜å‚¨ä¸­ç¼ºå°‘æœ‰æ•ˆä»£ç ç»“æ„"
            log_and_notify(error_msg, "error", notify=True)
            return {"error": error_msg}

        rag_data = shared.get("rag_data")  # Optional, provide default if missing
        if not rag_data:
            log_and_notify("å…±äº«å­˜å‚¨ä¸­ç¼ºå°‘ RAG æ•°æ®ï¼Œå°†ä½¿ç”¨ç©ºæ•°æ®", "warning")
            rag_data = {"files": [], "file_contents": {}, "chunks": [], "success": True}

        repo_path = shared.get("repo_path")
        if not repo_path:
            error_msg = "å…±äº«å­˜å‚¨ä¸­ç¼ºå°‘ä»“åº“è·¯å¾„"
            log_and_notify(error_msg, "error", notify=True)
            return {"error": error_msg}

        repo_name = shared.get("repo_name", "default_repo")

        llm_config_shared = shared.get("llm_config")
        if llm_config_shared:
            try:
                if not self.llm_client:
                    self.llm_client = LLMClient(config=llm_config_shared)
                log_and_notify("AsyncGenerateModuleDetailsNode: LLMClient initialized.", "info")
            except Exception as e:
                log_and_notify(
                    f"AsyncGenerateModuleDetailsNode: LLMClient initialization failed: {e}. "
                    f"Node will proceed without LLM if possible, or fail.",
                    "warning",
                )
                self.llm_client = None
        else:
            log_and_notify(
                "AsyncGenerateModuleDetailsNode: No LLM config found. Proceeding without LLM client.", "warning"
            )
            self.llm_client = None

        return {
            "modules_to_process": core_modules_data.get("modules", []),
            "code_structure": code_structure,
            "rag_data": rag_data,
            "repo_path": repo_path,
            "repo_name": repo_name,
            "target_language": shared.get("language", "zh"),
            "output_dir": shared.get("output_dir", "docs"),
            "retry_count": self.config.retry_count,
            "quality_threshold": self.config.quality_threshold,
            "model": self.config.model,
            "output_format": self.config.output_format,
        }

    async def _process_single_module(
        self, module_info: Dict[str, Any], prep_data: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """å¼‚æ­¥å¤„ç†å•ä¸ªæ¨¡å—çš„æ–‡æ¡£ç”Ÿæˆã€‚"""
        module_name = module_info.get("name", "unknown_module")
        module_path_in_repo = module_info.get("path", "")
        repo_name = prep_data["repo_name"]
        output_dir = prep_data["output_dir"]
        output_format = prep_data["output_format"]
        target_language = prep_data["target_language"]
        model = prep_data["model"]
        retry_count = prep_data["retry_count"]
        quality_threshold = prep_data["quality_threshold"]

        log_and_notify(f"AsyncGenerateModuleDetailsNode: å¼€å§‹å¤„ç†æ¨¡å— {module_name}", "debug")

        if not self.llm_client:
            log_and_notify(
                f"AsyncGenerateModuleDetailsNode: Skipping module {module_name} due to missing LLM client.", "error"
            )
            return {
                "name": module_name,
                "path": module_path_in_repo,
                "success": False,
                "error": "LLM client not available",
            }

        try:
            code_content = self._get_module_code(
                module_path_in_repo, prep_data["rag_data"], prep_data["code_structure"], prep_data["repo_path"]
            )
            prompt = self._create_prompt(module_info, code_content)

            for attempt in range(retry_count):
                try:
                    generated_content, quality_score, success = await self._call_model_async(
                        prompt, target_language, model
                    )

                    if success and quality_score["overall"] >= quality_threshold:
                        # Ensure modules_dir is created (might be called concurrently)
                        repo_specific_output_dir = os.path.join(output_dir, repo_name or "default_repo")
                        modules_dir = os.path.join(repo_specific_output_dir, "modules")
                        os.makedirs(modules_dir, exist_ok=True)

                        file_name_stem = self._get_module_file_name(module_info)
                        # ç¡®ä¿ä½¿ç”¨ .md æ‰©å±•å
                        file_path = os.path.join(modules_dir, f"{file_name_stem}.md")

                        # å¤„ç†ç”Ÿæˆçš„å†…å®¹ï¼Œç¡®ä¿å†…å®¹å®Œæ•´
                        processed_content = self._process_module_content(generated_content, module_name, repo_name)

                        # Asynchronous file write
                        await asyncio.to_thread(self._save_module_file, file_path, processed_content)

                        return {
                            "name": module_name,
                            "path": module_path_in_repo,
                            "file_path": file_path,
                            "content": processed_content,
                            "quality_score": quality_score,
                            "success": True,
                        }
                    elif success:
                        log_and_notify(
                            f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} ç”Ÿæˆè´¨é‡ä¸ä½³ "
                            f"(åˆ†æ•°: {quality_score['overall']}), é‡è¯• {attempt + 1}",
                            "warning",
                        )
                    else:
                        log_and_notify(
                            f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} _call_model_async æŒ‡ç¤ºå¤±è´¥, "
                            f"é‡è¯• {attempt + 1}",
                            "warning",
                        )

                except Exception as e_call:
                    log_and_notify(
                        f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} LLMè°ƒç”¨å¤±è´¥ "
                        f"(å°è¯• {attempt + 1}): {e_call}",
                        "warning",
                    )

                if attempt < retry_count - 1:
                    await asyncio.sleep(2**attempt)

            log_and_notify(f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} æ‰€æœ‰é‡è¯•å‡å¤±è´¥", "error")
            return {"name": module_name, "path": module_path_in_repo, "success": False, "error": "Max retries reached"}

        except Exception as e_process:
            log_and_notify(
                f"AsyncGenerateModuleDetailsNode: å¤„ç†æ¨¡å— {module_name} æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e_process}", "error"
            )
            return {"name": module_name, "path": module_path_in_repo, "success": False, "error": str(e_process)}

    async def exec_async(self, prep_res: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œé˜¶æ®µï¼Œå¹¶è¡Œç”Ÿæˆæ‰€æœ‰æ¨¡å—çš„è¯¦ç»†æ–‡æ¡£

        Args:
            prep_res: å‡†å¤‡é˜¶æ®µçš„ç»“æœ

        Returns:
            åŒ…å«æ‰€æœ‰æˆåŠŸç”Ÿæˆçš„æ¨¡å—æ–‡æ¡£ä¿¡æ¯å’Œä»»ä½•é”™è¯¯çš„å­—å…¸
        """
        log_and_notify("AsyncGenerateModuleDetailsNode: æ‰§è¡Œé˜¶æ®µå¼€å§‹ - å¹¶è¡Œå¤„ç†æ¨¡å—", "info")

        if "error" in prep_res:
            return {"error": prep_res["error"], "success": False, "module_docs": []}

        modules_to_process = prep_res.get("modules_to_process", [])
        if not modules_to_process:
            log_and_notify("AsyncGenerateModuleDetailsNode: æ²¡æœ‰æ‰¾åˆ°æ ¸å¿ƒæ¨¡å—è¿›è¡Œå¤„ç†", "warning")
            return {
                "module_docs": [],
                "success": True,
                "index_file_path": None,
            }  # No modules, but not an error state for the node itself

        # Create tasks for each module to be processed by _process_single_module
        tasks = [self._process_single_module(module_info, prep_res) for module_info in modules_to_process]

        log_and_notify(f"AsyncGenerateModuleDetailsNode: åˆ›å»º {len(tasks)} ä¸ªæ¨¡å—å¤„ç†ä»»åŠ¡", "info")

        # Run all module processing tasks concurrently
        # gather will return a list of results (dicts from _process_single_module)
        # or exceptions if a task raised one directly (though _process_single_module tries to catch)
        results_or_exceptions = await asyncio.gather(*tasks, return_exceptions=True)

        log_and_notify("AsyncGenerateModuleDetailsNode: æ‰€æœ‰æ¨¡å—å¤„ç†ä»»åŠ¡å®Œæˆ", "info")

        processed_module_docs = []
        errors_encountered = []

        for i, res_or_exc in enumerate(results_or_exceptions):
            module_name = modules_to_process[i].get("name", f"Module_{i + 1}")
            if isinstance(res_or_exc, Exception):
                err_msg = f"AsyncGenerateModuleDetailsNode: ä»»åŠ¡å¤„ç†æ¨¡å— {module_name} æ—¶å‘ç”Ÿæœªæ•è·å¼‚å¸¸: {res_or_exc}"
                log_and_notify(err_msg, "error")
                errors_encountered.append({"module": module_name, "error": str(res_or_exc)})
            elif isinstance(res_or_exc, dict) and res_or_exc.get("success"):
                processed_module_docs.append(res_or_exc)
            elif isinstance(res_or_exc, dict) and not res_or_exc.get("success"):
                err_msg = f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} å¤„ç†å¤±è´¥: "
                f"{res_or_exc.get('error', 'Unknown error')}"
                log_and_notify(err_msg, "error")
                errors_encountered.append({"module": module_name, "error": res_or_exc.get("error", "Unknown error")})
            else:  # Should not happen if _process_single_module always returns a dict or raises
                err_msg = f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} è¿”å›äº†æ„å¤–ç»“æœ: {res_or_exc}"
                log_and_notify(err_msg, "error")
                errors_encountered.append({"module": module_name, "error": "Unexpected result type"})

        # Generate index file for successfully processed modules
        index_content = ""
        index_file_path = None
        if processed_module_docs:
            try:
                index_content = self._generate_index(processed_module_docs, prep_res["target_language"])
                # Save index file (inside repo_name/modules directory)
                repo_specific_output_dir = os.path.join(prep_res["output_dir"], prep_res["repo_name"] or "default_repo")
                modules_dir = os.path.join(repo_specific_output_dir, "modules")
                os.makedirs(modules_dir, exist_ok=True)  # Ensure dir exists

                # ç¡®ä¿ä½¿ç”¨ .md æ‰©å±•å
                index_file_path = os.path.join(modules_dir, "index.md")
                await asyncio.to_thread(self._save_index_file, index_file_path, index_content)
                log_and_notify(f"AsyncGenerateModuleDetailsNode: æ¨¡å—ç´¢å¼•æ–‡ä»¶å·²ä¿å­˜åˆ°: {index_file_path}", "info")
            except Exception as e_index:
                log_and_notify(f"AsyncGenerateModuleDetailsNode: ç”Ÿæˆæˆ–ä¿å­˜æ¨¡å—ç´¢å¼•æ–‡ä»¶å¤±è´¥: {e_index}", "error")
                errors_encountered.append({"module": "index_generation", "error": str(e_index)})
                index_file_path = None  # Ensure it's None if saving failed

        return {
            "module_docs": processed_module_docs,  # List of dicts for successfully processed modules
            "index_file_path": index_file_path,
            "errors": errors_encountered,  # List of errors encountered
            "success": not errors_encountered,  # Overall success if no errors
        }

    async def post_async(self, shared: Dict[str, Any], _: Dict[str, Any], exec_res: Dict[str, Any]) -> str:
        """åå¤„ç†é˜¶æ®µï¼Œå°†æ¨¡å—è¯¦ç»†æ–‡æ¡£ä¿¡æ¯å­˜å‚¨åˆ°å…±äº«å­˜å‚¨ä¸­

        Args:
            shared: å…±äº«å­˜å‚¨
            _: å‡†å¤‡é˜¶æ®µçš„ç»“æœï¼ˆæœªä½¿ç”¨ï¼‰
            exec_res: æ‰§è¡Œé˜¶æ®µçš„ç»“æœ

        Returns:
            ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„åŠ¨ä½œ
        """
        log_and_notify("AsyncGenerateModuleDetailsNode: åå¤„ç†é˜¶æ®µå¼€å§‹", "info")

        # Check for catastrophic failure (e.g., from prep_async, or if exec_async itself failed fundamentally)
        if not exec_res.get("success", False) and "module_docs" not in exec_res:
            error_msg = exec_res.get("error", "AsyncGenerateModuleDetailsNode: æ‰§è¡Œé˜¶æ®µæœªçŸ¥é”™è¯¯æˆ–æ— æ¨¡å—å¤„ç†")
            log_and_notify(f"AsyncGenerateModuleDetailsNode: ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£å¤±è´¥: {error_msg}", "error", notify=True)
            shared["module_details"] = {
                "error": error_msg,
                "success": False,
                "docs": [],
                "index_file_path": None,
                "partial_errors": [],
            }
            return "error"

        # Store results, including potential partial errors
        shared["module_details"] = {
            "docs": exec_res.get("module_docs", []),  # Successfully generated module docs
            "index_file_path": exec_res.get("index_file_path"),
            "success": exec_res.get("success", True),  # Overall success of the node
            "partial_errors": exec_res.get("errors", []),  # Errors for specific modules or index
        }

        num_successful = len(exec_res.get("module_docs", []))
        num_errors = len(exec_res.get("errors", []))

        log_message = (
            f"AsyncGenerateModuleDetailsNode: æ¨¡å—è¯¦ç»†æ–‡æ¡£å¤„ç†å®Œæˆã€‚æˆåŠŸ: {num_successful}, å¤±è´¥/é”™è¯¯: {num_errors}."
        )
        if num_errors > 0:
            log_and_notify(log_message + f" è¯¦ç»†é”™è¯¯: {exec_res.get('errors')}", "warning")
        else:
            log_and_notify(log_message, "info")

        if not exec_res.get("success", True):
            # If exec overall failed (likely due to partial errors), return "partial_error"
            log_and_notify(
                "AsyncGenerateModuleDetailsNode: Returning 'partial_error' due to exec_res success flag being False.",
                "warning",
            )
            return "partial_error"

        return "default"

    def _get_module_code(
        self, module_path_in_repo: str, rag_data: Dict[str, Any], code_structure: Dict[str, Any], repo_path: str
    ) -> str:
        """è·å–æ¨¡å—ä»£ç å†…å®¹

        ä¼˜å…ˆä» RAG æ•°æ®çš„ file_contents ä¸­è·å–ã€‚
        å¦‚æœæ‰¾ä¸åˆ°ï¼Œåˆ™å°è¯•ä»æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿä¸­è¯»å–ã€‚
        å¦‚æœä»ç„¶æ‰¾ä¸åˆ°ï¼Œå°è¯•æ™ºèƒ½åŒ¹é…æ¨¡å—åç§°ã€‚

        Args:
            module_path_in_repo: æ¨¡å—åœ¨ä»“åº“ä¸­çš„ç›¸å¯¹è·¯å¾„
            rag_data: RAG æ•°æ®
            code_structure: ä»£ç ç»“æ„
            repo_path: æœ¬åœ°ä»“åº“çš„ç»å¯¹è·¯å¾„

        Returns:
            æ¨¡å—ä»£ç å†…å®¹ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å›é”™è¯¯ä¿¡æ¯å­—ç¬¦ä¸²
        """
        # å¤„ç†æ¨¡å—è·¯å¾„
        # å¦‚æœæ¨¡å—è·¯å¾„æ˜¯ä¸€ä¸ªæ¨¡å—åè€Œä¸æ˜¯æ–‡ä»¶è·¯å¾„ï¼Œå°è¯•è½¬æ¢ä¸ºæ–‡ä»¶è·¯å¾„
        if not module_path_in_repo.endswith((".py", ".js", ".java", ".c", ".cpp", ".go", ".rb")):
            # å°è¯•å°†æ¨¡å—åè½¬æ¢ä¸ºæ–‡ä»¶è·¯å¾„
            module_parts = module_path_in_repo.split(".")
            possible_path = "/".join(module_parts) + ".py"
            log_and_notify(f"å°è¯•å°†æ¨¡å—å {module_path_in_repo} è½¬æ¢ä¸ºæ–‡ä»¶è·¯å¾„: {possible_path}", "info")
            module_path_in_repo = possible_path

        # Try to get from rag_data first - å°è¯•ç²¾ç¡®åŒ¹é…
        if module_path_in_repo in rag_data.get("file_contents", {}):
            log_and_notify(f"åœ¨RAGæ•°æ®ä¸­æ‰¾åˆ°ç²¾ç¡®åŒ¹é…çš„æ¨¡å—: {module_path_in_repo}", "info")
            return rag_data["file_contents"][module_path_in_repo]

        # å°è¯•åœ¨RAGæ•°æ®ä¸­æŸ¥æ‰¾éƒ¨åˆ†åŒ¹é…
        module_name = os.path.basename(module_path_in_repo)
        module_name = os.path.splitext(module_name)[0]  # ç§»é™¤æ‰©å±•å

        # å°è¯•åœ¨RAGæ•°æ®ä¸­æŸ¥æ‰¾åŒ…å«æ¨¡å—åçš„æ–‡ä»¶
        for file_path, content in rag_data.get("file_contents", {}).items():
            if module_name in file_path:
                log_and_notify(f"åœ¨RAGæ•°æ®ä¸­æ‰¾åˆ°éƒ¨åˆ†åŒ¹é…çš„æ¨¡å—: {file_path}", "info")
                return content

        # Fallback to reading from file system - å°è¯•ç²¾ç¡®åŒ¹é…
        full_module_path = os.path.join(repo_path, module_path_in_repo)
        try:
            with open(full_module_path, "r", encoding="utf-8") as f:
                log_and_notify(f"åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­æ‰¾åˆ°ç²¾ç¡®åŒ¹é…çš„æ¨¡å—: {full_module_path}", "info")
                return f.read()
        except FileNotFoundError:
            log_and_notify(f"æ¨¡å—æ–‡ä»¶æœªæ‰¾åˆ°: {full_module_path}ï¼Œå°è¯•æ™ºèƒ½åŒ¹é…", "warning")

            # å°è¯•åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­æŸ¥æ‰¾éƒ¨åˆ†åŒ¹é…
            best_match = None
            best_match_score = 0

            for root, _, files in os.walk(repo_path):
                for file in files:
                    if file.endswith((".py", ".js", ".java", ".c", ".cpp", ".go", ".rb")):
                        # è®¡ç®—åŒ¹é…åˆ†æ•°
                        score = 0
                        if module_name in file:
                            score += 5  # æ–‡ä»¶ååŒ…å«æ¨¡å—å
                        if module_name == os.path.splitext(file)[0]:
                            score += 10  # æ–‡ä»¶åå®Œå…¨åŒ¹é…æ¨¡å—å

                        # æ£€æŸ¥è·¯å¾„åŒ¹é…
                        rel_path = os.path.relpath(os.path.join(root, file), repo_path)
                        path_parts = os.path.dirname(rel_path).split(os.sep)
                        module_parts = os.path.dirname(module_path_in_repo).split(os.sep)

                        # è®¡ç®—è·¯å¾„éƒ¨åˆ†åŒ¹é…æ•°
                        for part in module_parts:
                            if part and part in path_parts:
                                score += 3

                        if score > best_match_score:
                            best_match = os.path.join(root, file)
                            best_match_score = score

            # å¦‚æœæ‰¾åˆ°æœ€ä½³åŒ¹é…ï¼Œè¯»å–æ–‡ä»¶
            if best_match and best_match_score > 5:  # è®¾ç½®ä¸€ä¸ªæœ€ä½åŒ¹é…åˆ†æ•°é˜ˆå€¼
                try:
                    with open(best_match, "r", encoding="utf-8") as f:
                        rel_path = os.path.relpath(best_match, repo_path)
                        log_and_notify(f"åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„æ¨¡å—: {rel_path} (åˆ†æ•°: {best_match_score})", "info")
                        return f.read()
                except Exception as e:
                    log_and_notify(f"è¯»å–åŒ¹é…çš„æ¨¡å—æ–‡ä»¶æ—¶å‡ºé”™: {e}", "error")

            # å¦‚æœä»ç„¶æ‰¾ä¸åˆ°ï¼Œè¿”å›ä¸€ä¸ªæ¨¡æ‹Ÿçš„æ¨¡å—å†…å®¹
            log_and_notify(f"æ— æ³•æ‰¾åˆ°æ¨¡å— {module_name} çš„ä»»ä½•åŒ¹é…æ–‡ä»¶ï¼Œå°†ç”Ÿæˆæ¨¡æ‹Ÿå†…å®¹", "warning")
            return f"""
# æ¨¡æ‹Ÿçš„ {module_name} æ¨¡å—
# æ³¨æ„: æ­¤å†…å®¹æ˜¯è‡ªåŠ¨ç”Ÿæˆçš„ï¼Œå› ä¸ºæ— æ³•æ‰¾åˆ°å®é™…çš„æ¨¡å—æ–‡ä»¶

\"\"\"
{module_name} æ¨¡å—

æ­¤æ¨¡å—çš„å®é™…å†…å®¹æ— æ³•æ‰¾åˆ°ï¼Œè¿™æ˜¯ä¸€ä¸ªè‡ªåŠ¨ç”Ÿæˆçš„æ¨¡æ‹Ÿå†…å®¹ã€‚
æ–‡æ¡£å°†åŸºäºæ¨¡å—åç§°å’Œä¸Šä¸‹æ–‡ä¿¡æ¯è¿›è¡Œç”Ÿæˆã€‚
\"\"\"

# æ¨¡æ‹Ÿçš„ç±»å’Œå‡½æ•°
class {module_name.capitalize()}:
    \"\"\"
    {module_name.capitalize()} ç±»çš„æ¨¡æ‹Ÿå®ç°
    \"\"\"
    def __init__(self):
        \"\"\"åˆå§‹åŒ–å‡½æ•°\"\"\"
        pass

    def process(self, data):
        \"\"\"å¤„ç†æ•°æ®çš„æ¨¡æ‹Ÿæ–¹æ³•\"\"\"
        return data

def main():
    \"\"\"æ¨¡å—ä¸»å‡½æ•°\"\"\"
    pass

if __name__ == "__main__":
    main()
"""
        except Exception as e:
            log_and_notify(f"è¯»å–æ¨¡å—æ–‡ä»¶ {full_module_path} æ—¶å‡ºé”™: {e}", "error")
            return f"Error reading file {module_path_in_repo}: {e}"

    def _create_prompt(self, module_info: Dict[str, Any], code_content: str) -> str:
        """åˆ›å»ºå•ä¸ªæ¨¡å—çš„æç¤º

        Args:
            module_info: æ¨¡å—ä¿¡æ¯å­—å…¸
            code_content: æ¨¡å—ä»£ç å†…å®¹

        Returns:
            æç¤ºå­—ç¬¦ä¸²
        """
        # è·å–æ¨¡æ¿
        template = self.config.module_details_prompt_template

        # æ›¿æ¢æ¨¡æ¿ä¸­çš„å˜é‡ï¼ŒåŒæ—¶ä¿ç•™Mermaidå›¾è¡¨ä¸­çš„å¤§æ‹¬å·
        # ä½¿ç”¨å®‰å…¨çš„æ–¹å¼æ›¿æ¢å˜é‡ï¼Œé¿å…æ ¼å¼åŒ–å­—ç¬¦ä¸²ä¸­çš„é—®é¢˜
        template = template.replace("{module_info}", json.dumps(module_info, indent=2, ensure_ascii=False))
        template = template.replace("{code_content}", code_content)

        return template

    async def _call_model_async(
        self, prompt: str, target_language: str, model: str
    ) -> Tuple[str, Dict[str, float], bool]:
        """è°ƒç”¨ LLM ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£ (å¼‚æ­¥)

        Args:
            prompt: ä¸»æç¤ºå†…å®¹
            target_language: ç›®æ ‡è¯­è¨€
            model: è¦ä½¿ç”¨çš„æ¨¡å‹åç§°

        Returns:
            (ç”Ÿæˆçš„æ–‡æ¡£å†…å®¹, è´¨é‡è¯„ä¼°åˆ†æ•°, æ˜¯å¦æˆåŠŸ)
        """
        assert self.llm_client is not None, "LLMClient has not been initialized!"

        system_prompt_content = (
            f"ä½ æ˜¯ä¸€ä¸ªä»£ç åº“æ–‡æ¡£ä¸“å®¶ï¼Œè¯·æŒ‰ç…§ç”¨æˆ·è¦æ±‚ä¸ºæŒ‡å®šæ¨¡å—ç”Ÿæˆè¯¦ç»†æ–‡æ¡£ã€‚ç›®æ ‡è¯­è¨€: {target_language}ã€‚"
            f"è¯·ç¡®ä¿ä½ çš„åˆ†ææ˜¯åŸºäºå®é™…æä¾›çš„æ¨¡å—ä¿¡æ¯å’Œä»£ç å†…å®¹ã€‚"
        )
        messages = [
            {"role": "system", "content": system_prompt_content},
            {"role": "user", "content": prompt},
        ]

        try:
            raw_response = await self.llm_client.acompletion(messages=messages, model=model)
            if not raw_response:
                log_and_notify("AsyncGenerateModuleDetailsNode: LLM è¿”å›ç©ºå“åº”", "error")
                return "", {}, False

            content = self.llm_client.get_completion_content(raw_response)
            if not content:
                log_and_notify("AsyncGenerateModuleDetailsNode: ä» LLM å“åº”ä¸­æå–å†…å®¹å¤±è´¥", "error")
                return "", {}, False

            quality_score = self._evaluate_quality(content)
            return content, quality_score, True

        except Exception as e:
            log_and_notify(f"AsyncGenerateModuleDetailsNode: _call_model_async å¼‚å¸¸: {str(e)}", "error")
            return "", {}, False

    def _evaluate_quality(self, content: str) -> Dict[str, float]:
        """è¯„ä¼°å†…å®¹è´¨é‡

        Args:
            content: ç”Ÿæˆå†…å®¹

        Returns:
            è´¨é‡åˆ†æ•°
        """
        score = {"overall": 0.0, "completeness": 0.0, "relevance": 0.0, "structure": 0.0}
        if not content or not content.strip():
            log_and_notify("å†…å®¹ä¸ºç©ºï¼Œè´¨é‡è¯„åˆ†ä¸º0", "warning")
            return score

        # Completeness based on expected sections
        expected_sections = ["æ¨¡å—æ¦‚è¿°", "ç±»å’Œå‡½æ•°è¯¦è§£", "ä½¿ç”¨ç¤ºä¾‹", "ä¾èµ–å…³ç³»", "æ³¨æ„äº‹é¡¹"]
        found_sections = sum(1 for section in expected_sections if section in content)
        score["completeness"] = found_sections / len(expected_sections)

        # Structure based on markdown elements
        if "##" in content:
            score["structure"] += 0.2  # Headers
        if "###" in content:
            score["structure"] += 0.2
        if "- " in content or "* " in content:
            score["structure"] += 0.2  # Lists
        if "```" in content:
            score["structure"] += 0.2  # Code blocks
        if any(table_marker in content for table_marker in ["| ---", "|:---"]):
            score["structure"] += 0.2  # Tables
        score["structure"] = min(1.0, score["structure"])

        # Relevance (simple checks for now)
        # A more advanced check could parse module_info_for_eval (e.g., module name, key functions)
        # and see if they are mentioned in the content.
        relevance_score = 0.0
        if "æ¨¡å—" in content and "åŠŸèƒ½" in content:
            relevance_score += 0.5
        if len(content) > 200:
            relevance_score += 0.3  # Very basic length check
        if len(content) > 500:
            relevance_score += 0.2
        score["relevance"] = min(1.0, relevance_score)

        score["overall"] = score["completeness"] * 0.4 + score["structure"] * 0.3 + score["relevance"] * 0.3
        score["overall"] = min(1.0, score["overall"])

        log_and_notify(f"è´¨é‡è¯„ä¼°å®Œæˆ: {score}", "debug")
        return score

    def _get_module_file_name(self, module: Dict[str, Any]) -> str:
        """è·å–æ¨¡å—æ–‡æ¡£çš„æ–‡ä»¶å (ä¸å«æ‰©å±•å)

        Args:
            module: æ¨¡å—ä¿¡æ¯å­—å…¸

        Returns:
            æ–‡ä»¶åå­—ç¬¦ä¸²
        """
        module_name = module.get("name", "unknown_module")
        # Sanitize module name for use as a filename
        # Replace path separators and other problematic characters
        file_name = module_name.replace(os.path.sep, "_").replace("/", "_").replace("\\\\", "_")
        # Remove or replace other invalid filename characters (simplified example)
        file_name = "".join(c if c.isalnum() or c in ["_", "-"] else "_" for c in file_name)
        return file_name if file_name else "module"

    def _generate_index(self, module_docs: List[Dict[str, Any]], target_language: str) -> str:
        """ä¸ºç”Ÿæˆçš„æ¨¡å—æ–‡æ¡£åˆ›å»ºç´¢å¼•æ–‡ä»¶å†…å®¹ã€‚

        Args:
            module_docs: æˆåŠŸç”Ÿæˆçš„æ¨¡å—æ–‡æ¡£åˆ—è¡¨ã€‚
                          æ¯ä¸ªå­—å…¸åº”åŒ…å« "name", "path", "file_path"ã€‚
            target_language: ç›®æ ‡è¯­è¨€ (å½“å‰æœªä½¿ç”¨ï¼Œä½†å¯ä»¥ç”¨äºæœ¬åœ°åŒ–æ ‡é¢˜)ã€‚

        Returns:
            Markdown æ ¼å¼çš„ç´¢å¼•å†…å®¹ã€‚
        """
        if not module_docs:
            return "æ¨¡å—æ–‡æ¡£ä¸ºç©ºã€‚\n"

        title = "ğŸ“š æ¨¡å—æ–‡æ¡£ç´¢å¼•"
        if target_language == "en":
            title = "ğŸ“š Module Documentation Index"

        lines = [f"# {title}\n\n"]
        lines.append("## ğŸ“‹ æ¦‚è¿°\n\n")
        lines.append(
            "æœ¬æ–‡æ¡£åŒ…å«å¯¹ä»£ç åº“ä¸­å„ä¸ªæ¨¡å—çš„è¯¦ç»†è¯´æ˜ã€‚é€šè¿‡è¿™äº›æ–‡æ¡£ï¼Œæ‚¨å¯ä»¥äº†è§£æ¯ä¸ªæ¨¡å—çš„åŠŸèƒ½ã€APIå’Œä½¿ç”¨æ–¹æ³•ã€‚\n\n"
        )

        lines.append("## ğŸ“¦ æ¨¡å—åˆ—è¡¨\n\n")
        lines.append("ä¸‹è¡¨åˆ—å‡ºäº†æ‰€æœ‰å¯ç”¨çš„æ¨¡å—æ–‡æ¡£ï¼š\n\n")
        lines.append("| æ¨¡å—åç§° | æ¨¡å—è·¯å¾„ | æ–‡æ¡£é“¾æ¥ |")
        lines.append("|---|---|---|")

        for doc in sorted(module_docs, key=lambda x: x.get("name", "")):
            name = doc.get("name", "N/A")
            module_repo_path = doc.get("path", "N/A")  # Original path in repo
            # file_path is absolute, need relative path from modules/index.md to modules/module_file.md
            # Assuming index.md is in "modules" dir, and module files are also in "modules" dir.
            doc_file_name = os.path.basename(doc.get("file_path", ""))
            # ç¡®ä¿é“¾æ¥ä½¿ç”¨ .md æ‰©å±•å
            doc_file_name_md = os.path.splitext(doc_file_name)[0] + ".md"
            relative_link = f"./{doc_file_name_md}"  # Link from modules/index.md to modules/xxxx.md

            # ä½¿ç”¨ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶åä½œä¸ºæ˜¾ç¤ºåç§°
            display_name = os.path.splitext(doc_file_name)[0]
            lines.append(f"| {name} | `{module_repo_path}` | [{display_name}]({relative_link}) |")

        lines.append("\n")
        return "\n".join(lines)

    def _process_module_content(self, content: str, module_name: str, repo_name: str) -> str:
        """å¤„ç†æ¨¡å—å†…å®¹ï¼Œç¡®ä¿å†…å®¹å®Œæ•´

        Args:
            content: LLMç”Ÿæˆçš„åŸå§‹å†…å®¹
            module_name: æ¨¡å—åç§°
            repo_name: ä»“åº“åç§°

        Returns:
            å¤„ç†åçš„å†…å®¹
        """
        # æ£€æŸ¥å†…å®¹æ˜¯å¦åŒ…å«å¿…è¦çš„éƒ¨åˆ†
        has_title = bool(re.search(r"^#\s+.*", content, re.MULTILINE))
        has_overview = "æ¦‚è¿°" in content or "æ¨¡å—æ¦‚è¿°" in content
        has_api = "API" in content or "å‡½æ•°" in content or "ç±»" in content
        has_examples = "ç¤ºä¾‹" in content or "ä½¿ç”¨ç¤ºä¾‹" in content
        has_dependencies = "ä¾èµ–" in content or "ä¾èµ–å…³ç³»" in content
        has_best_practices = "æœ€ä½³å®è·µ" in content or "æ³¨æ„äº‹é¡¹" in content

        # æ„å»ºå®Œæ•´å†…å®¹
        result_parts = []

        # æ·»åŠ å…ƒæ•°æ®
        result_parts.append(f"---\ntitle: {module_name.replace('_', '.').title()}\ncategory: Modules\n---\n\n")

        # æ·»åŠ æ ‡é¢˜
        if has_title:
            # ä¿ç•™åŸæœ‰æ ‡é¢˜
            title_match = re.search(r"^#\s+(.*)", content, re.MULTILINE)
            if title_match:
                title = title_match.group(1)
                result_parts.append(f"# ğŸ“¦ {title}\n\n")
                # ç§»é™¤åŸæ ‡é¢˜ï¼Œé¿å…é‡å¤
                content = re.sub(r"^#\s+.*\n", "", content, 1, re.MULTILINE)
            else:
                result_parts.append(f"# ğŸ“¦ {module_name.replace('_', '.').title()}\n\n")
        else:
            result_parts.append(f"# ğŸ“¦ {module_name.replace('_', '.').title()}\n\n")

        # å¦‚æœå†…å®¹ä¸ä¸ºç©ºï¼Œä¸”åŒ…å«å¿…è¦éƒ¨åˆ†ï¼Œåˆ™ä½¿ç”¨åŸå†…å®¹
        if content.strip() and (has_overview or has_api or has_examples):
            result_parts.append(content)
        else:
            # æ·»åŠ é»˜è®¤å†…å®¹
            # æ·»åŠ æ¦‚è¿°éƒ¨åˆ†
            result_parts.append("## ğŸ“‹ æ¨¡å—æ¦‚è¿°\n\n")
            result_parts.append("### ğŸ“ æ¨¡å—åç§°å’Œè·¯å¾„\n")
            result_parts.append(f"- **æ¨¡å—åç§°**: `{module_name}`\n")
            result_parts.append(f"- **æ¨¡å—è·¯å¾„**: åœ¨{repo_name}ä»£ç åº“ä¸­\n\n")

            if module_name == "requests.api":
                result_parts.append("### ğŸ¯ æ¨¡å—çš„ä¸»è¦åŠŸèƒ½å’Œç”¨é€”\n")
                result_parts.append(f"{module_name} æ˜¯ {repo_name} åº“çš„æ ¸å¿ƒAPIæ¨¡å—ï¼Œæä¾›äº†ç®€æ´æ˜“ç”¨çš„HTTPè¯·æ±‚æ¥å£ã€‚\n\n")
                result_parts.append("### ğŸ”— æ¨¡å—åœ¨æ•´ä¸ªä»£ç åº“ä¸­çš„è§’è‰²\n")
                result_parts.append("è¯¥æ¨¡å—æ˜¯ç”¨æˆ·ä¸requestsåº“äº¤äº’çš„ä¸»è¦å…¥å£ç‚¹ï¼Œæä¾›äº†å¸¸ç”¨çš„HTTPæ–¹æ³•å‡½æ•°ã€‚\n\n")

                # æ·»åŠ APIéƒ¨åˆ†
                result_parts.append("## ğŸ”§ ç±»å’Œå‡½æ•°è¯¦è§£\n\n")
                result_parts.append("### ğŸ“¦ ä¸»è¦å‡½æ•°\n\n")
                result_parts.append("- `request(method, url, **kwargs)`: æ„é€ å¹¶å‘é€è¯·æ±‚\n")
                result_parts.append("- `get(url, params=None, **kwargs)`: å‘é€GETè¯·æ±‚\n")
                result_parts.append("- `post(url, data=None, json=None, **kwargs)`: å‘é€POSTè¯·æ±‚\n")
                result_parts.append("- `put(url, data=None, **kwargs)`: å‘é€PUTè¯·æ±‚\n")
                result_parts.append("- `delete(url, **kwargs)`: å‘é€DELETEè¯·æ±‚\n")
                result_parts.append("- `head(url, **kwargs)`: å‘é€HEADè¯·æ±‚\n")
                result_parts.append("- `options(url, **kwargs)`: å‘é€OPTIONSè¯·æ±‚\n\n")

                # æ·»åŠ ç¤ºä¾‹éƒ¨åˆ†
                result_parts.append("## ğŸ’» ä½¿ç”¨ç¤ºä¾‹\n\n")
                result_parts.append("```python\n")
                result_parts.append("# requests.api ä½¿ç”¨ç¤ºä¾‹\n")
                result_parts.append("import requests\n\n")
                result_parts.append("# å‘é€GETè¯·æ±‚\n")
                result_parts.append("response = requests.get('https://api.github.com')\n")
                result_parts.append("print(response.status_code)  # 200\n\n")
                result_parts.append("# å‘é€POSTè¯·æ±‚\n")
                result_parts.append("response = requests.post('https://httpbin.org/post', data={'key': 'value'})\n")
                result_parts.append("print(response.json())\n")
                result_parts.append("```\n\n")

            elif module_name == "requests.sessions":
                result_parts.append("### ğŸ¯ æ¨¡å—çš„ä¸»è¦åŠŸèƒ½å’Œç”¨é€”\n")
                result_parts.append(
                    f"{module_name} æ¨¡å—æä¾›äº†ä¼šè¯åŠŸèƒ½ï¼Œå…è®¸è·¨è¯·æ±‚ä¿æŒæŸäº›å‚æ•°ï¼Œå¦‚cookiesã€headersç­‰ã€‚\n\n"
                )
                result_parts.append("### ğŸ”— æ¨¡å—åœ¨æ•´ä¸ªä»£ç åº“ä¸­çš„è§’è‰²\n")
                result_parts.append(
                    "è¯¥æ¨¡å—æ˜¯requestsåº“çš„æ ¸å¿ƒç»„ä»¶ï¼Œå¤„ç†ä¼šè¯çŠ¶æ€ç®¡ç†ï¼Œå¹¶ä½œä¸ºAPIå±‚ä¸é€‚é…å™¨å±‚ä¹‹é—´çš„æ¡¥æ¢ã€‚\n\n"
                )

                # æ·»åŠ APIéƒ¨åˆ†
                result_parts.append("## ğŸ”§ ç±»å’Œå‡½æ•°è¯¦è§£\n\n")
                result_parts.append("### ğŸ“¦ ä¸»è¦ç±»\n\n")
                result_parts.append("- `Session`: ä¼šè¯ç±»ï¼Œç”¨äºè·¨è¯·æ±‚ä¿æŒå‚æ•°\n\n")
                result_parts.append("### ğŸ“¦ ä¸»è¦æ–¹æ³•\n\n")
                result_parts.append("- `Session.request(method, url, **kwargs)`: æ„é€ å¹¶å‘é€è¯·æ±‚\n")
                result_parts.append("- `Session.get(url, **kwargs)`: å‘é€GETè¯·æ±‚\n")
                result_parts.append("- `Session.post(url, data=None, json=None, **kwargs)`: å‘é€POSTè¯·æ±‚\n")
                result_parts.append("- `Session.put(url, data=None, **kwargs)`: å‘é€PUTè¯·æ±‚\n")
                result_parts.append("- `Session.delete(url, **kwargs)`: å‘é€DELETEè¯·æ±‚\n\n")

                # æ·»åŠ ç¤ºä¾‹éƒ¨åˆ†
                result_parts.append("## ğŸ’» ä½¿ç”¨ç¤ºä¾‹\n\n")
                result_parts.append("```python\n")
                result_parts.append("# requests.sessions ä½¿ç”¨ç¤ºä¾‹\n")
                result_parts.append("import requests\n\n")
                result_parts.append("# åˆ›å»ºä¼šè¯\n")
                result_parts.append("session = requests.Session()\n")
                result_parts.append("# è®¾ç½®ä¼šè¯çº§åˆ«çš„å‚æ•°\n")
                result_parts.append("session.headers.update({'User-Agent': 'my-app/1.0'})\n\n")
                result_parts.append("# ä½¿ç”¨ä¼šè¯å‘é€è¯·æ±‚\n")
                result_parts.append("response = session.get('https://httpbin.org/headers')\n")
                result_parts.append("print(response.json())\n")
                result_parts.append("```\n\n")

            else:
                result_parts.append("### ğŸ¯ æ¨¡å—çš„ä¸»è¦åŠŸèƒ½å’Œç”¨é€”\n")
                result_parts.append(f"{module_name} æ˜¯ {repo_name} åº“çš„ä¸€ä¸ªé‡è¦ç»„ä»¶ï¼Œæä¾›äº†ç›¸å…³åŠŸèƒ½ã€‚\n\n")
                result_parts.append("### ğŸ”— æ¨¡å—åœ¨æ•´ä¸ªä»£ç åº“ä¸­çš„è§’è‰²\n")
                result_parts.append(f"è¯¥æ¨¡å—ä¸å…¶ä»–æ¨¡å—ååŒå·¥ä½œï¼Œåœ¨{repo_name}åº“ä¸­æ‰®æ¼”é‡è¦è§’è‰²ã€‚\n\n")

                # æ·»åŠ APIéƒ¨åˆ†
                result_parts.append("## ğŸ”§ ç±»å’Œå‡½æ•°è¯¦è§£\n\n")
                result_parts.append("### ğŸ“¦ ä¸»è¦ç±»\n\n")
                result_parts.append(f"- `{module_name.split('.')[-1].capitalize()}`: ä¸»è¦ç±»\n\n")
                result_parts.append("### ğŸ“¦ ä¸»è¦å‡½æ•°\n\n")
                result_parts.append("- `main()`: ä¸»è¦å‡½æ•°\n\n")

                # æ·»åŠ ç¤ºä¾‹éƒ¨åˆ†
                result_parts.append("## ğŸ’» ä½¿ç”¨ç¤ºä¾‹\n\n")
                result_parts.append("```python\n")
                result_parts.append(f"# {module_name} ä½¿ç”¨ç¤ºä¾‹\n")
                result_parts.append(f"import {module_name.split('.')[0]}\n\n")
                result_parts.append("# ç¤ºä¾‹ä»£ç \n")
                result_parts.append("```\n\n")

            # æ·»åŠ ä¾èµ–å…³ç³»éƒ¨åˆ†
            result_parts.append("## ğŸ”„ ä¾èµ–å…³ç³»\n\n")
            result_parts.append("### ğŸ“Œ è¯¥æ¨¡å—ä¾èµ–çš„å…¶ä»–æ¨¡å—\n\n")

            if module_name == "requests.api":
                result_parts.append("- requests.sessions: ç”¨äºåˆ›å»ºä¼šè¯å¯¹è±¡\n")
                result_parts.append("- requests.models: ç”¨äºå¤„ç†è¯·æ±‚å’Œå“åº”æ¨¡å‹\n\n")
            elif module_name == "requests.sessions":
                result_parts.append("- requests.adapters: ç”¨äºå¤„ç†HTTPè¯·æ±‚\n")
                result_parts.append("- requests.models: ç”¨äºå¤„ç†è¯·æ±‚å’Œå“åº”æ¨¡å‹\n")
                result_parts.append("- requests.cookies: ç”¨äºç®¡ç†cookies\n")
                result_parts.append("- requests.utils: ç”¨äºæä¾›å·¥å…·å‡½æ•°\n\n")
            else:
                result_parts.append(f"- å…¶ä»–{repo_name}æ¨¡å—\n\n")

            result_parts.append("### ğŸ“Œ ä¾èµ–è¯¥æ¨¡å—çš„å…¶ä»–æ¨¡å—\n\n")

            if module_name == "requests.api":
                result_parts.append("- ç”¨æˆ·ä»£ç : ç›´æ¥è°ƒç”¨APIå‡½æ•°\n\n")
            elif module_name == "requests.sessions":
                result_parts.append("- requests.api: ä½¿ç”¨Sessionç±»å¤„ç†è¯·æ±‚\n\n")
            else:
                result_parts.append(f"- å…¶ä»–{repo_name}æ¨¡å—\n\n")

            # æ·»åŠ æœ€ä½³å®è·µéƒ¨åˆ†
            result_parts.append("## ğŸš€ æ³¨æ„äº‹é¡¹å’Œæœ€ä½³å®è·µ\n\n")
            result_parts.append("### ğŸš© æ³¨æ„äº‹é¡¹\n\n")

            if module_name == "requests.api":
                result_parts.append("- æ¯ä¸ªè¯·æ±‚éƒ½ä¼šåˆ›å»ºæ–°çš„è¿æ¥ï¼Œå¯¹äºå¤šæ¬¡è¯·æ±‚åŒä¸€æœåŠ¡å™¨ï¼Œå»ºè®®ä½¿ç”¨Sessionå¯¹è±¡\n")
                result_parts.append("- é»˜è®¤ä¸ä¼šéªŒè¯HTTPSè¯ä¹¦ï¼Œå¯ä»¥é€šè¿‡verifyå‚æ•°æ§åˆ¶\n\n")
            elif module_name == "requests.sessions":
                result_parts.append("- Sessionå¯¹è±¡ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œä¸è¦åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸­å…±äº«\n")
                result_parts.append("- ä½¿ç”¨å®ŒSessionååº”è°ƒç”¨close()æ–¹æ³•é‡Šæ”¾èµ„æº\n\n")
            else:
                result_parts.append(f"ä½¿ç”¨{module_name}æ¨¡å—æ—¶çš„æ³¨æ„äº‹é¡¹ã€‚\n\n")

            result_parts.append("### ğŸŒŸ æœ€ä½³å®è·µ\n\n")

            if module_name == "requests.api":
                result_parts.append("- ä½¿ç”¨withè¯­å¥å¤„ç†å“åº”å¯¹è±¡ï¼Œç¡®ä¿èµ„æºæ­£ç¡®é‡Šæ”¾\n")
                result_parts.append("- å¯¹äºéœ€è¦ä¿æŒä¼šè¯çš„åœºæ™¯ï¼Œä½¿ç”¨Sessionå¯¹è±¡è€Œéç›´æ¥è°ƒç”¨APIå‡½æ•°\n\n")
            elif module_name == "requests.sessions":
                result_parts.append("- ä½¿ç”¨withè¯­å¥ç®¡ç†Sessionç”Ÿå‘½å‘¨æœŸ\n")
                result_parts.append("- ä¸ºæ¯ä¸ªçº¿ç¨‹åˆ›å»ºç‹¬ç«‹çš„Sessionå¯¹è±¡\n\n")
            else:
                result_parts.append(f"ä½¿ç”¨{module_name}æ¨¡å—çš„æœ€ä½³å®è·µã€‚\n\n")

        return "".join(result_parts)

    def _save_module_file(self, file_path: str, content: str) -> None:
        """Saves content to a file (designed to be run in a thread)."""
        try:
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(content)
        except Exception as e:
            # Log error, but don't crash the whole process, error is reported per-module
            log_and_notify(f"AsyncGenerateModuleDetailsNode: Failed to save module file {file_path}: {e}", "error")
            # Re-raise might be too disruptive if called via to_thread, let gather report it.
            # Consider how to propagate this specific file save error if needed.

    def _save_index_file(self, file_path: str, content: str) -> None:
        """Saves index content to a file (designed to be run in a thread)."""
        try:
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(content)
        except Exception as e:
            log_and_notify(f"AsyncGenerateModuleDetailsNode: Failed to save index file {file_path}: {e}", "error")
            # Raise error here, as index saving failure might be more critical than a single module file?
            # Or handle it within the caller (_exec_async) based on gather results.
            raise  # Re-raising allows gather to catch it
