"""ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£èŠ‚ç‚¹ï¼Œç”¨äºç”Ÿæˆä»£ç åº“ä¸­å„æ¨¡å—çš„è¯¦ç»†æ–‡æ¡£ã€‚"""

import asyncio
import json
import os
from typing import Any, Dict, List, Optional, Tuple

from pocketflow import AsyncNode
from pydantic import BaseModel, Field

from ..utils.llm_wrapper import LLMClient
from ..utils.logger import log_and_notify


class GenerateModuleDetailsNodeConfig(BaseModel):
    """GenerateModuleDetailsNode é…ç½®"""

    retry_count: int = Field(3, ge=1, le=10, description="é‡è¯•æ¬¡æ•°")
    quality_threshold: float = Field(0.7, ge=0, le=1.0, description="è´¨é‡é˜ˆå€¼")
    model: str = Field("", description="LLM æ¨¡å‹ï¼Œä»é…ç½®ä¸­è·å–ï¼Œä¸åº”è®¾ç½®é»˜è®¤å€¼")
    output_format: str = Field("markdown", description="è¾“å‡ºæ ¼å¼")
    max_modules_per_batch: int = Field(5, description="æ¯æ‰¹æœ€å¤§æ¨¡å—æ•°")
    module_details_prompt_template: str = Field(
        """
        ä½ æ˜¯ä¸€ä¸ªä»£ç åº“æ–‡æ¡£ä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹æ¨¡å—ç”Ÿæˆè¯¦ç»†çš„æ–‡æ¡£ã€‚

        æ¨¡å—ä¿¡æ¯:
        {module_info}

        ä»£ç å†…å®¹:
        {code_content}

        è¯·æä¾›ä»¥ä¸‹å†…å®¹:
        1. æ¨¡å—æ¦‚è¿°
           - æ¨¡å—åç§°å’Œè·¯å¾„
           - æ¨¡å—çš„ä¸»è¦åŠŸèƒ½å’Œç”¨é€”
           - æ¨¡å—åœ¨æ•´ä¸ªä»£ç åº“ä¸­çš„è§’è‰²
        2. ç±»å’Œå‡½æ•°è¯¦è§£
           - æ¯ä¸ªç±»çš„åŠŸèƒ½ã€å±æ€§å’Œæ–¹æ³•
           - æ¯ä¸ªå‡½æ•°çš„åŠŸèƒ½ã€å‚æ•°å’Œè¿”å›å€¼
           - é‡è¦çš„ä»£ç ç‰‡æ®µè§£é‡Š
        3. ä½¿ç”¨ç¤ºä¾‹
           - å¦‚ä½•ä½¿ç”¨è¯¥æ¨¡å—çš„ä¸»è¦åŠŸèƒ½
           - å¸¸è§ç”¨ä¾‹å’Œæ¨¡å¼
        4. ä¾èµ–å…³ç³»
           - è¯¥æ¨¡å—ä¾èµ–çš„å…¶ä»–æ¨¡å—
           - ä¾èµ–è¯¥æ¨¡å—çš„å…¶ä»–æ¨¡å—
        5. æ³¨æ„äº‹é¡¹å’Œæœ€ä½³å®è·µ
           - ä½¿ç”¨è¯¥æ¨¡å—æ—¶éœ€è¦æ³¨æ„çš„äº‹é¡¹
           - æ¨èçš„æœ€ä½³å®è·µ

        è¯·ä»¥ Markdown æ ¼å¼è¾“å‡ºï¼Œä½¿ç”¨é€‚å½“çš„æ ‡é¢˜ã€åˆ—è¡¨ã€è¡¨æ ¼å’Œä»£ç å—ã€‚
        ä½¿ç”¨è¡¨æƒ…ç¬¦å·ä½¿æ–‡æ¡£æ›´åŠ ç”ŸåŠ¨ï¼Œä¾‹å¦‚åœ¨æ ‡é¢˜å‰ä½¿ç”¨é€‚å½“çš„è¡¨æƒ…ç¬¦å·ã€‚
        ç¡®ä¿æ–‡æ¡£ä¸­çš„ä»£ç å¼•ç”¨èƒ½å¤Ÿé“¾æ¥åˆ°æºä»£ç ã€‚
        """,
        description="æ¨¡å—è¯¦ç»†æ–‡æ¡£æç¤ºæ¨¡æ¿",
    )


class AsyncGenerateModuleDetailsNode(AsyncNode):
    """ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£èŠ‚ç‚¹ï¼ˆå¼‚æ­¥ï¼‰ï¼Œç”¨äºå¹¶è¡Œç”Ÿæˆä»£ç åº“ä¸­å„æ¨¡å—çš„è¯¦ç»†æ–‡æ¡£"""

    llm_client: Optional[LLMClient] = None

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """åˆå§‹åŒ–ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£èŠ‚ç‚¹ (å¼‚æ­¥)

        Args:
            config: èŠ‚ç‚¹é…ç½®
        """
        super().__init__()
        from ..utils.env_manager import get_node_config

        default_config = get_node_config("generate_module_details")
        merged_config = default_config.copy()
        if config:
            merged_config.update(config)
        self.config = GenerateModuleDetailsNodeConfig(**merged_config)
        log_and_notify("åˆå§‹åŒ– AsyncGenerateModuleDetailsNode", "info")

    async def prep_async(self, shared: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡é˜¶æ®µï¼Œä»å…±äº«å­˜å‚¨ä¸­è·å–æ ¸å¿ƒæ¨¡å—å’Œä»£ç ç»“æ„

        Args:
            shared: å…±äº«å­˜å‚¨

        Returns:
            åŒ…å«æ ¸å¿ƒæ¨¡å—å’Œä»£ç ç»“æ„çš„å­—å…¸
        """
        log_and_notify("AsyncGenerateModuleDetailsNode: å‡†å¤‡é˜¶æ®µå¼€å§‹", "info")

        core_modules_data = shared.get("core_modules")
        if not core_modules_data or not core_modules_data.get("success", False):
            error_msg = "å…±äº«å­˜å‚¨ä¸­ç¼ºå°‘æœ‰æ•ˆæ ¸å¿ƒæ¨¡å—æ•°æ®"
            log_and_notify(error_msg, "error", notify=True)
            return {"error": error_msg}

        code_structure = shared.get("code_structure")
        if not code_structure or not code_structure.get("success", False):
            error_msg = "å…±äº«å­˜å‚¨ä¸­ç¼ºå°‘æœ‰æ•ˆä»£ç ç»“æ„"
            log_and_notify(error_msg, "error", notify=True)
            return {"error": error_msg}

        rag_data = shared.get("rag_data")  # Optional, provide default if missing
        if not rag_data:
            log_and_notify("å…±äº«å­˜å‚¨ä¸­ç¼ºå°‘ RAG æ•°æ®ï¼Œå°†ä½¿ç”¨ç©ºæ•°æ®", "warning")
            rag_data = {"files": [], "file_contents": {}, "chunks": [], "success": True}

        repo_path = shared.get("repo_path")
        if not repo_path:
            error_msg = "å…±äº«å­˜å‚¨ä¸­ç¼ºå°‘ä»“åº“è·¯å¾„"
            log_and_notify(error_msg, "error", notify=True)
            return {"error": error_msg}

        repo_name = shared.get("repo_name", "default_repo")

        llm_config_shared = shared.get("llm_config")
        if llm_config_shared:
            try:
                if not self.llm_client:
                    self.llm_client = LLMClient(config=llm_config_shared)
                log_and_notify("AsyncGenerateModuleDetailsNode: LLMClient initialized.", "info")
            except Exception as e:
                log_and_notify(
                    f"AsyncGenerateModuleDetailsNode: LLMClient initialization failed: {e}. "
                    f"Node will proceed without LLM if possible, or fail.",
                    "warning",
                )
                self.llm_client = None
        else:
            log_and_notify(
                "AsyncGenerateModuleDetailsNode: No LLM config found. Proceeding without LLM client.", "warning"
            )
            self.llm_client = None

        return {
            "modules_to_process": core_modules_data.get("modules", []),
            "code_structure": code_structure,
            "rag_data": rag_data,
            "repo_path": repo_path,
            "repo_name": repo_name,
            "target_language": shared.get("language", "zh"),
            "output_dir": shared.get("output_dir", "docs"),
            "retry_count": self.config.retry_count,
            "quality_threshold": self.config.quality_threshold,
            "model": self.config.model,
            "output_format": self.config.output_format,
        }

    async def _process_single_module(
        self, module_info: Dict[str, Any], prep_data: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """å¼‚æ­¥å¤„ç†å•ä¸ªæ¨¡å—çš„æ–‡æ¡£ç”Ÿæˆã€‚"""
        module_name = module_info.get("name", "unknown_module")
        module_path_in_repo = module_info.get("path", "")
        repo_name = prep_data["repo_name"]
        output_dir = prep_data["output_dir"]
        output_format = prep_data["output_format"]
        target_language = prep_data["target_language"]
        model = prep_data["model"]
        retry_count = prep_data["retry_count"]
        quality_threshold = prep_data["quality_threshold"]

        log_and_notify(f"AsyncGenerateModuleDetailsNode: å¼€å§‹å¤„ç†æ¨¡å— {module_name}", "debug")

        if not self.llm_client:
            log_and_notify(
                f"AsyncGenerateModuleDetailsNode: Skipping module {module_name} due to missing LLM client.", "error"
            )
            return {
                "name": module_name,
                "path": module_path_in_repo,
                "success": False,
                "error": "LLM client not available",
            }

        try:
            code_content = self._get_module_code(
                module_path_in_repo, prep_data["rag_data"], prep_data["code_structure"], prep_data["repo_path"]
            )
            prompt = self._create_prompt(module_info, code_content)

            for attempt in range(retry_count):
                try:
                    generated_content, quality_score, success = await self._call_model_async(
                        prompt, target_language, model
                    )

                    if success and quality_score["overall"] >= quality_threshold:
                        # Ensure modules_dir is created (might be called concurrently)
                        repo_specific_output_dir = os.path.join(output_dir, repo_name or "default_repo")
                        modules_dir = os.path.join(repo_specific_output_dir, "modules")
                        os.makedirs(modules_dir, exist_ok=True)

                        file_name_stem = self._get_module_file_name(module_info)
                        # ç¡®ä¿ä½¿ç”¨ .md æ‰©å±•å
                        file_path = os.path.join(modules_dir, f"{file_name_stem}.md")

                        # Asynchronous file write
                        await asyncio.to_thread(self._save_module_file, file_path, generated_content)

                        return {
                            "name": module_name,
                            "path": module_path_in_repo,
                            "file_path": file_path,
                            "content": generated_content,
                            "quality_score": quality_score,
                            "success": True,
                        }
                    elif success:
                        log_and_notify(
                            f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} ç”Ÿæˆè´¨é‡ä¸ä½³ "
                            f"(åˆ†æ•°: {quality_score['overall']}), é‡è¯• {attempt + 1}",
                            "warning",
                        )
                    else:
                        log_and_notify(
                            f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} _call_model_async æŒ‡ç¤ºå¤±è´¥, "
                            f"é‡è¯• {attempt + 1}",
                            "warning",
                        )

                except Exception as e_call:
                    log_and_notify(
                        f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} LLMè°ƒç”¨å¤±è´¥ "
                        f"(å°è¯• {attempt + 1}): {e_call}",
                        "warning",
                    )

                if attempt < retry_count - 1:
                    await asyncio.sleep(2**attempt)

            log_and_notify(f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} æ‰€æœ‰é‡è¯•å‡å¤±è´¥", "error")
            return {"name": module_name, "path": module_path_in_repo, "success": False, "error": "Max retries reached"}

        except Exception as e_process:
            log_and_notify(
                f"AsyncGenerateModuleDetailsNode: å¤„ç†æ¨¡å— {module_name} æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e_process}", "error"
            )
            return {"name": module_name, "path": module_path_in_repo, "success": False, "error": str(e_process)}

    async def exec_async(self, prep_res: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œé˜¶æ®µï¼Œå¹¶è¡Œç”Ÿæˆæ‰€æœ‰æ¨¡å—çš„è¯¦ç»†æ–‡æ¡£

        Args:
            prep_res: å‡†å¤‡é˜¶æ®µçš„ç»“æœ

        Returns:
            åŒ…å«æ‰€æœ‰æˆåŠŸç”Ÿæˆçš„æ¨¡å—æ–‡æ¡£ä¿¡æ¯å’Œä»»ä½•é”™è¯¯çš„å­—å…¸
        """
        log_and_notify("AsyncGenerateModuleDetailsNode: æ‰§è¡Œé˜¶æ®µå¼€å§‹ - å¹¶è¡Œå¤„ç†æ¨¡å—", "info")

        if "error" in prep_res:
            return {"error": prep_res["error"], "success": False, "module_docs": []}

        modules_to_process = prep_res.get("modules_to_process", [])
        if not modules_to_process:
            log_and_notify("AsyncGenerateModuleDetailsNode: æ²¡æœ‰æ‰¾åˆ°æ ¸å¿ƒæ¨¡å—è¿›è¡Œå¤„ç†", "warning")
            return {
                "module_docs": [],
                "success": True,
                "index_file_path": None,
            }  # No modules, but not an error state for the node itself

        # Create tasks for each module to be processed by _process_single_module
        tasks = [self._process_single_module(module_info, prep_res) for module_info in modules_to_process]

        log_and_notify(f"AsyncGenerateModuleDetailsNode: åˆ›å»º {len(tasks)} ä¸ªæ¨¡å—å¤„ç†ä»»åŠ¡", "info")

        # Run all module processing tasks concurrently
        # gather will return a list of results (dicts from _process_single_module)
        # or exceptions if a task raised one directly (though _process_single_module tries to catch)
        results_or_exceptions = await asyncio.gather(*tasks, return_exceptions=True)

        log_and_notify("AsyncGenerateModuleDetailsNode: æ‰€æœ‰æ¨¡å—å¤„ç†ä»»åŠ¡å®Œæˆ", "info")

        processed_module_docs = []
        errors_encountered = []

        for i, res_or_exc in enumerate(results_or_exceptions):
            module_name = modules_to_process[i].get("name", f"Module_{i + 1}")
            if isinstance(res_or_exc, Exception):
                err_msg = f"AsyncGenerateModuleDetailsNode: ä»»åŠ¡å¤„ç†æ¨¡å— {module_name} æ—¶å‘ç”Ÿæœªæ•è·å¼‚å¸¸: {res_or_exc}"
                log_and_notify(err_msg, "error")
                errors_encountered.append({"module": module_name, "error": str(res_or_exc)})
            elif isinstance(res_or_exc, dict) and res_or_exc.get("success"):
                processed_module_docs.append(res_or_exc)
            elif isinstance(res_or_exc, dict) and not res_or_exc.get("success"):
                err_msg = f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} å¤„ç†å¤±è´¥: "
                f"{res_or_exc.get('error', 'Unknown error')}"
                log_and_notify(err_msg, "error")
                errors_encountered.append({"module": module_name, "error": res_or_exc.get("error", "Unknown error")})
            else:  # Should not happen if _process_single_module always returns a dict or raises
                err_msg = f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} è¿”å›äº†æ„å¤–ç»“æœ: {res_or_exc}"
                log_and_notify(err_msg, "error")
                errors_encountered.append({"module": module_name, "error": "Unexpected result type"})

        # Generate index file for successfully processed modules
        index_content = ""
        index_file_path = None
        if processed_module_docs:
            try:
                index_content = self._generate_index(processed_module_docs, prep_res["target_language"])
                # Save index file (inside repo_name/modules directory)
                repo_specific_output_dir = os.path.join(prep_res["output_dir"], prep_res["repo_name"] or "default_repo")
                modules_dir = os.path.join(repo_specific_output_dir, "modules")
                os.makedirs(modules_dir, exist_ok=True)  # Ensure dir exists

                # ç¡®ä¿ä½¿ç”¨ .md æ‰©å±•å
                index_file_path = os.path.join(modules_dir, "index.md")
                await asyncio.to_thread(self._save_index_file, index_file_path, index_content)
                log_and_notify(f"AsyncGenerateModuleDetailsNode: æ¨¡å—ç´¢å¼•æ–‡ä»¶å·²ä¿å­˜åˆ°: {index_file_path}", "info")
            except Exception as e_index:
                log_and_notify(f"AsyncGenerateModuleDetailsNode: ç”Ÿæˆæˆ–ä¿å­˜æ¨¡å—ç´¢å¼•æ–‡ä»¶å¤±è´¥: {e_index}", "error")
                errors_encountered.append({"module": "index_generation", "error": str(e_index)})
                index_file_path = None  # Ensure it's None if saving failed

        return {
            "module_docs": processed_module_docs,  # List of dicts for successfully processed modules
            "index_file_path": index_file_path,
            "errors": errors_encountered,  # List of errors encountered
            "success": not errors_encountered,  # Overall success if no errors
        }

    async def post_async(self, shared: Dict[str, Any], _: Dict[str, Any], exec_res: Dict[str, Any]) -> str:
        """åå¤„ç†é˜¶æ®µï¼Œå°†æ¨¡å—è¯¦ç»†æ–‡æ¡£ä¿¡æ¯å­˜å‚¨åˆ°å…±äº«å­˜å‚¨ä¸­

        Args:
            shared: å…±äº«å­˜å‚¨
            _: å‡†å¤‡é˜¶æ®µçš„ç»“æœï¼ˆæœªä½¿ç”¨ï¼‰
            exec_res: æ‰§è¡Œé˜¶æ®µçš„ç»“æœ

        Returns:
            ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„åŠ¨ä½œ
        """
        log_and_notify("AsyncGenerateModuleDetailsNode: åå¤„ç†é˜¶æ®µå¼€å§‹", "info")

        # Check for catastrophic failure (e.g., from prep_async, or if exec_async itself failed fundamentally)
        if not exec_res.get("success", False) and "module_docs" not in exec_res:
            error_msg = exec_res.get("error", "AsyncGenerateModuleDetailsNode: æ‰§è¡Œé˜¶æ®µæœªçŸ¥é”™è¯¯æˆ–æ— æ¨¡å—å¤„ç†")
            log_and_notify(f"AsyncGenerateModuleDetailsNode: ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£å¤±è´¥: {error_msg}", "error", notify=True)
            shared["module_details"] = {
                "error": error_msg,
                "success": False,
                "docs": [],
                "index_file_path": None,
                "partial_errors": [],
            }
            return "error"

        # Store results, including potential partial errors
        shared["module_details"] = {
            "docs": exec_res.get("module_docs", []),  # Successfully generated module docs
            "index_file_path": exec_res.get("index_file_path"),
            "success": exec_res.get("success", True),  # Overall success of the node
            "partial_errors": exec_res.get("errors", []),  # Errors for specific modules or index
        }

        num_successful = len(exec_res.get("module_docs", []))
        num_errors = len(exec_res.get("errors", []))

        log_message = (
            f"AsyncGenerateModuleDetailsNode: æ¨¡å—è¯¦ç»†æ–‡æ¡£å¤„ç†å®Œæˆã€‚æˆåŠŸ: {num_successful}, å¤±è´¥/é”™è¯¯: {num_errors}."
        )
        if num_errors > 0:
            log_and_notify(log_message + f" è¯¦ç»†é”™è¯¯: {exec_res.get('errors')}", "warning")
        else:
            log_and_notify(log_message, "info")

        if not exec_res.get("success", True):
            # If exec overall failed (likely due to partial errors), return "partial_error"
            log_and_notify(
                "AsyncGenerateModuleDetailsNode: Returning 'partial_error' due to exec_res success flag being False.",
                "warning",
            )
            return "partial_error"

        return "default"

    def _get_module_code(
        self, module_path_in_repo: str, rag_data: Dict[str, Any], code_structure: Dict[str, Any], repo_path: str
    ) -> str:
        """è·å–æ¨¡å—ä»£ç å†…å®¹

        ä¼˜å…ˆä» RAG æ•°æ®çš„ file_contents ä¸­è·å–ã€‚
        å¦‚æœæ‰¾ä¸åˆ°ï¼Œåˆ™å°è¯•ä»æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿä¸­è¯»å–ã€‚
        å¦‚æœä»ç„¶æ‰¾ä¸åˆ°ï¼Œå°è¯•æ™ºèƒ½åŒ¹é…æ¨¡å—åç§°ã€‚

        Args:
            module_path_in_repo: æ¨¡å—åœ¨ä»“åº“ä¸­çš„ç›¸å¯¹è·¯å¾„
            rag_data: RAG æ•°æ®
            code_structure: ä»£ç ç»“æ„
            repo_path: æœ¬åœ°ä»“åº“çš„ç»å¯¹è·¯å¾„

        Returns:
            æ¨¡å—ä»£ç å†…å®¹ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å›é”™è¯¯ä¿¡æ¯å­—ç¬¦ä¸²
        """
        # Try to get from rag_data first
        if module_path_in_repo in rag_data.get("file_contents", {}):
            return rag_data["file_contents"][module_path_in_repo]

        # Fallback to reading from file system
        full_module_path = os.path.join(repo_path, module_path_in_repo)
        try:
            with open(full_module_path, "r", encoding="utf-8") as f:
                return f.read()
        except FileNotFoundError:
            log_and_notify(f"æ¨¡å—æ–‡ä»¶æœªæ‰¾åˆ°: {full_module_path}ï¼Œå°è¯•æ™ºèƒ½åŒ¹é…", "warning")

            # å°è¯•æ™ºèƒ½åŒ¹é…æ¨¡å—åç§°
            module_name = os.path.basename(module_path_in_repo)
            module_name = os.path.splitext(module_name)[0]  # ç§»é™¤æ‰©å±•å

            # 1. å°è¯•åœ¨ RAG æ•°æ®ä¸­æŸ¥æ‰¾åŒ…å«æ¨¡å—åçš„æ–‡ä»¶
            for file_path, content in rag_data.get("file_contents", {}).items():
                if module_name in file_path:
                    log_and_notify(f"åœ¨ RAG æ•°æ®ä¸­æ‰¾åˆ°åŒ¹é…çš„æ¨¡å—: {file_path}", "info")
                    return content

            # 2. å°è¯•åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­æŸ¥æ‰¾
            for root, _, files in os.walk(repo_path):
                for file in files:
                    if module_name in file and file.endswith((".py", ".js", ".java", ".c", ".cpp", ".go", ".rb")):
                        rel_path = os.path.relpath(os.path.join(root, file), repo_path)
                        log_and_notify(f"åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­æ‰¾åˆ°åŒ¹é…çš„æ¨¡å—: {rel_path}", "info")
                        try:
                            with open(os.path.join(root, file), "r", encoding="utf-8") as f:
                                return f.read()
                        except Exception as e:
                            log_and_notify(f"è¯»å–åŒ¹é…çš„æ¨¡å—æ–‡ä»¶æ—¶å‡ºé”™: {e}", "error")

            # å¦‚æœä»ç„¶æ‰¾ä¸åˆ°ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
            log_and_notify(f"æ— æ³•æ‰¾åˆ°æ¨¡å— {module_name} çš„ä»»ä½•åŒ¹é…æ–‡ä»¶", "error")
            return f"Error: File not found at {module_path_in_repo} and no matching files found"
        except Exception as e:
            log_and_notify(f"è¯»å–æ¨¡å—æ–‡ä»¶ {full_module_path} æ—¶å‡ºé”™: {e}", "error")
            return f"Error reading file {module_path_in_repo}: {e}"

    def _create_prompt(self, module_info: Dict[str, Any], code_content: str) -> str:
        """åˆ›å»ºå•ä¸ªæ¨¡å—çš„æç¤º

        Args:
            module_info: æ¨¡å—ä¿¡æ¯å­—å…¸
            code_content: æ¨¡å—ä»£ç å†…å®¹

        Returns:
            æç¤ºå­—ç¬¦ä¸²
        """
        return self.config.module_details_prompt_template.format(
            module_info=json.dumps(module_info, indent=2, ensure_ascii=False), code_content=code_content
        )

    async def _call_model_async(
        self, prompt: str, target_language: str, model: str
    ) -> Tuple[str, Dict[str, float], bool]:
        """è°ƒç”¨ LLM ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£ (å¼‚æ­¥)

        Args:
            prompt: ä¸»æç¤ºå†…å®¹
            target_language: ç›®æ ‡è¯­è¨€
            model: è¦ä½¿ç”¨çš„æ¨¡å‹åç§°

        Returns:
            (ç”Ÿæˆçš„æ–‡æ¡£å†…å®¹, è´¨é‡è¯„ä¼°åˆ†æ•°, æ˜¯å¦æˆåŠŸ)
        """
        assert self.llm_client is not None, "LLMClient has not been initialized!"

        system_prompt_content = (
            f"ä½ æ˜¯ä¸€ä¸ªä»£ç åº“æ–‡æ¡£ä¸“å®¶ï¼Œè¯·æŒ‰ç…§ç”¨æˆ·è¦æ±‚ä¸ºæŒ‡å®šæ¨¡å—ç”Ÿæˆè¯¦ç»†æ–‡æ¡£ã€‚ç›®æ ‡è¯­è¨€: {target_language}ã€‚"
            f"è¯·ç¡®ä¿ä½ çš„åˆ†ææ˜¯åŸºäºå®é™…æä¾›çš„æ¨¡å—ä¿¡æ¯å’Œä»£ç å†…å®¹ã€‚"
        )
        messages = [
            {"role": "system", "content": system_prompt_content},
            {"role": "user", "content": prompt},
        ]

        try:
            raw_response = await self.llm_client.acompletion(messages=messages, model=model)
            if not raw_response:
                log_and_notify("AsyncGenerateModuleDetailsNode: LLM è¿”å›ç©ºå“åº”", "error")
                return "", {}, False

            content = self.llm_client.get_completion_content(raw_response)
            if not content:
                log_and_notify("AsyncGenerateModuleDetailsNode: ä» LLM å“åº”ä¸­æå–å†…å®¹å¤±è´¥", "error")
                return "", {}, False

            quality_score = self._evaluate_quality(content)
            return content, quality_score, True

        except Exception as e:
            log_and_notify(f"AsyncGenerateModuleDetailsNode: _call_model_async å¼‚å¸¸: {str(e)}", "error")
            return "", {}, False

    def _evaluate_quality(self, content: str) -> Dict[str, float]:
        """è¯„ä¼°å†…å®¹è´¨é‡

        Args:
            content: ç”Ÿæˆå†…å®¹

        Returns:
            è´¨é‡åˆ†æ•°
        """
        score = {"overall": 0.0, "completeness": 0.0, "relevance": 0.0, "structure": 0.0}
        if not content or not content.strip():
            log_and_notify("å†…å®¹ä¸ºç©ºï¼Œè´¨é‡è¯„åˆ†ä¸º0", "warning")
            return score

        # Completeness based on expected sections
        expected_sections = ["æ¨¡å—æ¦‚è¿°", "ç±»å’Œå‡½æ•°è¯¦è§£", "ä½¿ç”¨ç¤ºä¾‹", "ä¾èµ–å…³ç³»", "æ³¨æ„äº‹é¡¹"]
        found_sections = sum(1 for section in expected_sections if section in content)
        score["completeness"] = found_sections / len(expected_sections)

        # Structure based on markdown elements
        if "##" in content:
            score["structure"] += 0.2  # Headers
        if "###" in content:
            score["structure"] += 0.2
        if "- " in content or "* " in content:
            score["structure"] += 0.2  # Lists
        if "```" in content:
            score["structure"] += 0.2  # Code blocks
        if any(table_marker in content for table_marker in ["| ---", "|:---"]):
            score["structure"] += 0.2  # Tables
        score["structure"] = min(1.0, score["structure"])

        # Relevance (simple checks for now)
        # A more advanced check could parse module_info_for_eval (e.g., module name, key functions)
        # and see if they are mentioned in the content.
        relevance_score = 0.0
        if "æ¨¡å—" in content and "åŠŸèƒ½" in content:
            relevance_score += 0.5
        if len(content) > 200:
            relevance_score += 0.3  # Very basic length check
        if len(content) > 500:
            relevance_score += 0.2
        score["relevance"] = min(1.0, relevance_score)

        score["overall"] = score["completeness"] * 0.4 + score["structure"] * 0.3 + score["relevance"] * 0.3
        score["overall"] = min(1.0, score["overall"])

        log_and_notify(f"è´¨é‡è¯„ä¼°å®Œæˆ: {score}", "debug")
        return score

    def _get_module_file_name(self, module: Dict[str, Any]) -> str:
        """è·å–æ¨¡å—æ–‡æ¡£çš„æ–‡ä»¶å (ä¸å«æ‰©å±•å)

        Args:
            module: æ¨¡å—ä¿¡æ¯å­—å…¸

        Returns:
            æ–‡ä»¶åå­—ç¬¦ä¸²
        """
        module_name = module.get("name", "unknown_module")
        # Sanitize module name for use as a filename
        # Replace path separators and other problematic characters
        file_name = module_name.replace(os.path.sep, "_").replace("/", "_").replace("\\\\", "_")
        # Remove or replace other invalid filename characters (simplified example)
        file_name = "".join(c if c.isalnum() or c in ["_", "-"] else "_" for c in file_name)
        return file_name if file_name else "module"

    def _generate_index(self, module_docs: List[Dict[str, Any]], target_language: str) -> str:
        """ä¸ºç”Ÿæˆçš„æ¨¡å—æ–‡æ¡£åˆ›å»ºç´¢å¼•æ–‡ä»¶å†…å®¹ã€‚

        Args:
            module_docs: æˆåŠŸç”Ÿæˆçš„æ¨¡å—æ–‡æ¡£åˆ—è¡¨ã€‚
                          æ¯ä¸ªå­—å…¸åº”åŒ…å« "name", "path", "file_path"ã€‚
            target_language: ç›®æ ‡è¯­è¨€ (å½“å‰æœªä½¿ç”¨ï¼Œä½†å¯ä»¥ç”¨äºæœ¬åœ°åŒ–æ ‡é¢˜)ã€‚

        Returns:
            Markdown æ ¼å¼çš„ç´¢å¼•å†…å®¹ã€‚
        """
        if not module_docs:
            return "æ¨¡å—æ–‡æ¡£ä¸ºç©ºã€‚\n"

        title = "ğŸ“š æ¨¡å—æ–‡æ¡£ç´¢å¼•"
        if target_language == "en":
            title = "ğŸ“š Module Documentation Index"

        lines = [f"# {title}\n\n"]
        lines.append("## ğŸ“‹ æ¦‚è¿°\n\n")
        lines.append(
            "æœ¬æ–‡æ¡£åŒ…å«å¯¹ä»£ç åº“ä¸­å„ä¸ªæ¨¡å—çš„è¯¦ç»†è¯´æ˜ã€‚é€šè¿‡è¿™äº›æ–‡æ¡£ï¼Œæ‚¨å¯ä»¥äº†è§£æ¯ä¸ªæ¨¡å—çš„åŠŸèƒ½ã€APIå’Œä½¿ç”¨æ–¹æ³•ã€‚\n\n"
        )

        lines.append("## ğŸ“¦ æ¨¡å—åˆ—è¡¨\n\n")
        lines.append("ä¸‹è¡¨åˆ—å‡ºäº†æ‰€æœ‰å¯ç”¨çš„æ¨¡å—æ–‡æ¡£ï¼š\n\n")
        lines.append("| æ¨¡å—åç§° | æ¨¡å—è·¯å¾„ | æ–‡æ¡£é“¾æ¥ |")
        lines.append("|---|---|---|")

        for doc in sorted(module_docs, key=lambda x: x.get("name", "")):
            name = doc.get("name", "N/A")
            module_repo_path = doc.get("path", "N/A")  # Original path in repo
            # file_path is absolute, need relative path from modules/index.md to modules/module_file.md
            # Assuming index.md is in "modules" dir, and module files are also in "modules" dir.
            doc_file_name = os.path.basename(doc.get("file_path", ""))
            # ç¡®ä¿é“¾æ¥ä½¿ç”¨ .md æ‰©å±•å
            doc_file_name_md = os.path.splitext(doc_file_name)[0] + ".md"
            relative_link = f"./{doc_file_name_md}"  # Link from modules/index.md to modules/xxxx.md

            # ä½¿ç”¨ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶åä½œä¸ºæ˜¾ç¤ºåç§°
            display_name = os.path.splitext(doc_file_name)[0]
            lines.append(f"| {name} | `{module_repo_path}` | [{display_name}]({relative_link}) |")

        lines.append("\n")
        return "\n".join(lines)

    def _save_module_file(self, file_path: str, content: str) -> None:
        """Saves content to a file (designed to be run in a thread)."""
        try:
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(content)
        except Exception as e:
            # Log error, but don't crash the whole process, error is reported per-module
            log_and_notify(f"AsyncGenerateModuleDetailsNode: Failed to save module file {file_path}: {e}", "error")
            # Re-raise might be too disruptive if called via to_thread, let gather report it.
            # Consider how to propagate this specific file save error if needed.

    def _save_index_file(self, file_path: str, content: str) -> None:
        """Saves index content to a file (designed to be run in a thread)."""
        try:
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(content)
        except Exception as e:
            log_and_notify(f"AsyncGenerateModuleDetailsNode: Failed to save index file {file_path}: {e}", "error")
            # Raise error here, as index saving failure might be more critical than a single module file?
            # Or handle it within the caller (_exec_async) based on gather results.
            raise  # Re-raising allows gather to catch it
