"""ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£èŠ‚ç‚¹ï¼Œç”¨äºç”Ÿæˆä»£ç åº“ä¸­å„æ¨¡å—çš„è¯¦ç»†æ–‡æ¡£ã€‚"""

import json
import os
from typing import Any, Dict, List, Optional

from pocketflow import Node
from pydantic import BaseModel, Field

from ..utils.llm_wrapper.llm_client import LLMClient
from ..utils.logger import log_and_notify


class GenerateModuleDetailsNodeConfig(BaseModel):
    """GenerateModuleDetailsNode é…ç½®"""

    retry_count: int = Field(3, ge=1, le=10, description="é‡è¯•æ¬¡æ•°")
    quality_threshold: float = Field(0.7, ge=0, le=1.0, description="è´¨é‡é˜ˆå€¼")
    model: str = Field("", description="LLM æ¨¡å‹ï¼Œä»é…ç½®ä¸­è·å–ï¼Œä¸åº”è®¾ç½®é»˜è®¤å€¼")
    output_format: str = Field("markdown", description="è¾“å‡ºæ ¼å¼")
    max_modules_per_batch: int = Field(5, description="æ¯æ‰¹æœ€å¤§æ¨¡å—æ•°")
    module_details_prompt_template: str = Field(
        """
        ä½ æ˜¯ä¸€ä¸ªä»£ç åº“æ–‡æ¡£ä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹æ¨¡å—ç”Ÿæˆè¯¦ç»†çš„æ–‡æ¡£ã€‚

        æ¨¡å—ä¿¡æ¯:
        {module_info}

        ä»£ç å†…å®¹:
        {code_content}

        è¯·æä¾›ä»¥ä¸‹å†…å®¹:
        1. æ¨¡å—æ¦‚è¿°
           - æ¨¡å—åç§°å’Œè·¯å¾„
           - æ¨¡å—çš„ä¸»è¦åŠŸèƒ½å’Œç”¨é€”
           - æ¨¡å—åœ¨æ•´ä¸ªä»£ç åº“ä¸­çš„è§’è‰²
        2. ç±»å’Œå‡½æ•°è¯¦è§£
           - æ¯ä¸ªç±»çš„åŠŸèƒ½ã€å±æ€§å’Œæ–¹æ³•
           - æ¯ä¸ªå‡½æ•°çš„åŠŸèƒ½ã€å‚æ•°å’Œè¿”å›å€¼
           - é‡è¦çš„ä»£ç ç‰‡æ®µè§£é‡Š
        3. ä½¿ç”¨ç¤ºä¾‹
           - å¦‚ä½•ä½¿ç”¨è¯¥æ¨¡å—çš„ä¸»è¦åŠŸèƒ½
           - å¸¸è§ç”¨ä¾‹å’Œæ¨¡å¼
        4. ä¾èµ–å…³ç³»
           - è¯¥æ¨¡å—ä¾èµ–çš„å…¶ä»–æ¨¡å—
           - ä¾èµ–è¯¥æ¨¡å—çš„å…¶ä»–æ¨¡å—
        5. æ³¨æ„äº‹é¡¹å’Œæœ€ä½³å®è·µ
           - ä½¿ç”¨è¯¥æ¨¡å—æ—¶éœ€è¦æ³¨æ„çš„äº‹é¡¹
           - æ¨èçš„æœ€ä½³å®è·µ

        è¯·ä»¥ Markdown æ ¼å¼è¾“å‡ºï¼Œä½¿ç”¨é€‚å½“çš„æ ‡é¢˜ã€åˆ—è¡¨ã€è¡¨æ ¼å’Œä»£ç å—ã€‚
        ä½¿ç”¨è¡¨æƒ…ç¬¦å·ä½¿æ–‡æ¡£æ›´åŠ ç”ŸåŠ¨ï¼Œä¾‹å¦‚åœ¨æ ‡é¢˜å‰ä½¿ç”¨é€‚å½“çš„è¡¨æƒ…ç¬¦å·ã€‚
        ç¡®ä¿æ–‡æ¡£ä¸­çš„ä»£ç å¼•ç”¨èƒ½å¤Ÿé“¾æ¥åˆ°æºä»£ç ã€‚
        """,
        description="æ¨¡å—è¯¦ç»†æ–‡æ¡£æç¤ºæ¨¡æ¿",
    )


class GenerateModuleDetailsNode(Node):
    """ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£èŠ‚ç‚¹ï¼Œç”¨äºç”Ÿæˆä»£ç åº“ä¸­å„æ¨¡å—çš„è¯¦ç»†æ–‡æ¡£"""

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """åˆå§‹åŒ–ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£èŠ‚ç‚¹

        Args:
            config: èŠ‚ç‚¹é…ç½®
        """
        super().__init__()

        # ä»é…ç½®æ–‡ä»¶è·å–é»˜è®¤é…ç½®
        from ..utils.env_manager import get_node_config

        default_config = get_node_config("generate_module_details")

        # åˆå¹¶é…ç½®
        merged_config = default_config.copy()
        if config:
            merged_config.update(config)

        self.config = GenerateModuleDetailsNodeConfig(**merged_config)
        log_and_notify("åˆå§‹åŒ–ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£èŠ‚ç‚¹", "info")

    def prep(self, shared: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡é˜¶æ®µï¼Œä»å…±äº«å­˜å‚¨ä¸­è·å–æ ¸å¿ƒæ¨¡å—å’Œä»£ç ç»“æ„

        Args:
            shared: å…±äº«å­˜å‚¨

        Returns:
            åŒ…å«æ ¸å¿ƒæ¨¡å—å’Œä»£ç ç»“æ„çš„å­—å…¸
        """
        log_and_notify("GenerateModuleDetailsNode: å‡†å¤‡é˜¶æ®µå¼€å§‹", "info")

        # ä»å…±äº«å­˜å‚¨ä¸­è·å–æ ¸å¿ƒæ¨¡å—
        core_modules = shared.get("core_modules")
        if not core_modules:
            error_msg = "å…±äº«å­˜å‚¨ä¸­ç¼ºå°‘æ ¸å¿ƒæ¨¡å—"
            log_and_notify(error_msg, "error", notify=True)
            return {"error": error_msg}

        # æ£€æŸ¥æ ¸å¿ƒæ¨¡å—æ˜¯å¦æœ‰æ•ˆ
        if not core_modules.get("success", False):
            error_msg = "æ ¸å¿ƒæ¨¡å—æ— æ•ˆ"
            log_and_notify(error_msg, "error", notify=True)
            return {"error": error_msg}

        # ä»å…±äº«å­˜å‚¨ä¸­è·å–ä»£ç ç»“æ„
        code_structure = shared.get("code_structure")
        if not code_structure:
            error_msg = "å…±äº«å­˜å‚¨ä¸­ç¼ºå°‘ä»£ç ç»“æ„"
            log_and_notify(error_msg, "error", notify=True)
            return {"error": error_msg}

        # æ£€æŸ¥ä»£ç ç»“æ„æ˜¯å¦æœ‰æ•ˆ
        if not code_structure.get("success", False):
            error_msg = "ä»£ç ç»“æ„æ— æ•ˆ"
            log_and_notify(error_msg, "error", notify=True)
            return {"error": error_msg}

        # ä»å…±äº«å­˜å‚¨ä¸­è·å– RAG æ•°æ®
        rag_data = shared.get("rag_data")
        if not rag_data:
            log_and_notify("å…±äº«å­˜å‚¨ä¸­ç¼ºå°‘ RAG æ•°æ®ï¼Œå°†ä½¿ç”¨ç©ºæ•°æ®", "warning")
            rag_data = {"files": [], "file_contents": {}, "chunks": [], "success": True}

        # ä»å…±äº«å­˜å‚¨ä¸­è·å–ä»“åº“è·¯å¾„
        repo_path = shared.get("repo_path")
        if not repo_path:
            error_msg = "å…±äº«å­˜å‚¨ä¸­ç¼ºå°‘ä»“åº“è·¯å¾„"
            log_and_notify(error_msg, "error", notify=True)
            return {"error": error_msg}

        # è·å– LLM é…ç½®
        llm_config = shared.get("llm_config", {})

        # è·å–ç›®æ ‡è¯­è¨€
        target_language = shared.get("language", "zh")

        # è·å–è¾“å‡ºç›®å½•
        output_dir = shared.get("output_dir", "docs")

        return {
            "core_modules": core_modules,
            "code_structure": code_structure,
            "rag_data": rag_data,
            "repo_path": repo_path,
            "llm_config": llm_config,
            "target_language": target_language,
            "output_dir": output_dir,
            "retry_count": self.config.retry_count,
            "quality_threshold": self.config.quality_threshold,
            "model": self.config.model,
            "output_format": self.config.output_format,
            "max_modules_per_batch": self.config.max_modules_per_batch,
        }

    def exec(self, prep_res: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œé˜¶æ®µï¼Œç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£

        Args:
            prep_res: å‡†å¤‡é˜¶æ®µçš„ç»“æœ

        Returns:
            ç”Ÿæˆç»“æœ
        """
        log_and_notify("GenerateModuleDetailsNode: æ‰§è¡Œé˜¶æ®µå¼€å§‹", "info")

        # æ£€æŸ¥å‡†å¤‡é˜¶æ®µæ˜¯å¦å‡ºé”™
        if "error" in prep_res:
            return {"error": prep_res["error"], "success": False}

        core_modules = prep_res["core_modules"]
        code_structure = prep_res["code_structure"]
        rag_data = prep_res["rag_data"]
        repo_path = prep_res["repo_path"]
        llm_config = prep_res["llm_config"]
        target_language = prep_res["target_language"]
        output_dir = prep_res["output_dir"]
        retry_count = prep_res["retry_count"]
        quality_threshold = prep_res["quality_threshold"]
        model = prep_res["model"]
        output_format = prep_res["output_format"]
        prep_res["max_modules_per_batch"]

        # è·å–æ¨¡å—åˆ—è¡¨
        modules = core_modules.get("modules", [])
        if not modules:
            log_and_notify("æ²¡æœ‰æ‰¾åˆ°æ ¸å¿ƒæ¨¡å—", "warning")
            return {"modules": [], "success": True}

        # åˆ›å»ºæ¨¡å—æ–‡æ¡£ç›®å½•
        modules_dir = os.path.join(output_dir, "modules")
        os.makedirs(modules_dir, exist_ok=True)
        log_and_notify(f"åˆ›å»ºæ¨¡å—æ–‡æ¡£ç›®å½•: {modules_dir}", "info")

        # ç”Ÿæˆæ¯ä¸ªæ¨¡å—çš„è¯¦ç»†æ–‡æ¡£
        module_docs = []

        for i, module in enumerate(modules):
            try:
                log_and_notify(
                    f"æ­£åœ¨ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£ ({i + 1}/{len(modules)}): {module.get('name', 'unknown')}", "info"
                )

                # è·å–æ¨¡å—ä»£ç å†…å®¹
                module_path = module.get("path", "")
                code_content = self._get_module_code(module_path, rag_data, code_structure, repo_path)

                # å‡†å¤‡æç¤º
                prompt = self._create_prompt(module, code_content)

                # å°è¯•è°ƒç”¨ LLM
                for attempt in range(retry_count):
                    try:
                        log_and_notify(f"å°è¯•ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£ (å°è¯• {attempt + 1}/{retry_count})", "info")

                        # è°ƒç”¨ LLM
                        content, quality_score, success = self._call_model(llm_config, prompt, target_language, model)

                        if success and quality_score["overall"] >= quality_threshold:
                            log_and_notify(f"æˆåŠŸç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£ (è´¨é‡åˆ†æ•°: {quality_score['overall']})", "info")

                            # ä¿å­˜æ–‡æ¡£
                            file_name = self._get_module_file_name(module)
                            file_path = os.path.join(modules_dir, file_name + "." + output_format)

                            with open(file_path, "w", encoding="utf-8") as f:
                                f.write(content)

                            log_and_notify(f"æ¨¡å—æ–‡æ¡£å·²ä¿å­˜åˆ°: {file_path}", "info")

                            module_docs.append(
                                {
                                    "name": module.get("name", ""),
                                    "path": module.get("path", ""),
                                    "file_path": file_path,
                                    "content": content,
                                    "quality_score": quality_score,
                                }
                            )

                            break
                        elif success:
                            log_and_notify(f"ç”Ÿæˆè´¨é‡ä¸ä½³ (åˆ†æ•°: {quality_score['overall']}), é‡è¯•ä¸­...", "warning")
                    except Exception as e:
                        log_and_notify(f"LLM è°ƒç”¨å¤±è´¥: {str(e)}, é‡è¯•ä¸­...", "warning")
            except Exception as e:
                log_and_notify(f"ç”Ÿæˆæ¨¡å— {module.get('name', 'unknown')} çš„è¯¦ç»†æ–‡æ¡£å¤±è´¥: {str(e)}", "error")

        # ç”Ÿæˆæ¨¡å—ç´¢å¼•æ–‡æ¡£
        index_content = self._generate_index(module_docs, target_language)
        index_path = os.path.join(output_dir, "modules.md")

        with open(index_path, "w", encoding="utf-8") as f:
            f.write(index_content)

        log_and_notify(f"æ¨¡å—ç´¢å¼•æ–‡æ¡£å·²ä¿å­˜åˆ°: {index_path}", "info")

        log_and_notify(f"æˆåŠŸç”Ÿæˆ {len(module_docs)} ä¸ªæ¨¡å—çš„è¯¦ç»†æ–‡æ¡£", "info")

        return {"modules": module_docs, "index_path": index_path, "success": True}

    def post(self, shared: Dict[str, Any], prep_res: Dict[str, Any], exec_res: Dict[str, Any]) -> str:
        """åå¤„ç†é˜¶æ®µï¼Œå°†ç”Ÿæˆç»“æœå­˜å‚¨åˆ°å…±äº«å­˜å‚¨ä¸­

        Args:
            shared: å…±äº«å­˜å‚¨
            prep_res: å‡†å¤‡é˜¶æ®µçš„ç»“æœ
            exec_res: æ‰§è¡Œé˜¶æ®µçš„ç»“æœ

        Returns:
            ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„åŠ¨ä½œ
        """
        log_and_notify("GenerateModuleDetailsNode: åå¤„ç†é˜¶æ®µå¼€å§‹", "info")

        # æ£€æŸ¥æ‰§è¡Œé˜¶æ®µæ˜¯å¦å‡ºé”™
        if not exec_res.get("success", False):
            error_msg = exec_res.get("error", "æœªçŸ¥é”™è¯¯")
            log_and_notify(f"ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£å¤±è´¥: {error_msg}", "error", notify=True)
            shared["module_details"] = {"error": error_msg, "success": False}
            return "error"

        # å°†ç”Ÿæˆç»“æœå­˜å‚¨åˆ°å…±äº«å­˜å‚¨ä¸­
        shared["module_details"] = {
            "modules": exec_res.get("modules", []),
            "index_path": exec_res.get("index_path", ""),
            "success": True,
        }

        log_and_notify(f"æˆåŠŸç”Ÿæˆ {len(exec_res.get('modules', []))} ä¸ªæ¨¡å—çš„è¯¦ç»†æ–‡æ¡£", "info", notify=True)

        return "default"

    def _get_module_code(
        self, module_path: str, rag_data: Dict[str, Any], code_structure: Dict[str, Any], repo_path: str
    ) -> str:
        """è·å–æ¨¡å—ä»£ç å†…å®¹

        Args:
            module_path: æ¨¡å—è·¯å¾„
            rag_data: RAG æ•°æ®
            code_structure: ä»£ç ç»“æ„
            repo_path: ä»“åº“è·¯å¾„

        Returns:
            æ¨¡å—ä»£ç å†…å®¹
        """
        # å°è¯•ä» RAG æ•°æ®ä¸­è·å–
        file_contents = rag_data.get("file_contents", {})
        if module_path in file_contents:
            return file_contents[module_path]

        # å°è¯•ä»ä»£ç ç»“æ„ä¸­è·å–
        files = code_structure.get("files", {})
        if module_path in files and "content" in files[module_path]:
            return files[module_path]["content"]

        # å°è¯•ä»æ–‡ä»¶ç³»ç»Ÿä¸­è¯»å–
        try:
            full_path = os.path.join(repo_path, module_path)
            if os.path.exists(full_path) and os.path.isfile(full_path):
                with open(full_path, "r", encoding="utf-8", errors="replace") as f:
                    return f.read()
        except Exception as e:
            log_and_notify(f"è¯»å–æ¨¡å—ä»£ç å¤±è´¥: {str(e)}", "warning")

        # å¦‚æœæ˜¯ç›®å½•ï¼Œå°è¯•åˆ—å‡ºç›®å½•å†…å®¹
        try:
            full_path = os.path.join(repo_path, module_path)
            if os.path.exists(full_path) and os.path.isdir(full_path):
                files = os.listdir(full_path)
                return f"ç›®å½• {module_path} åŒ…å«ä»¥ä¸‹æ–‡ä»¶:\n" + "\n".join(files)
        except Exception as e:
            log_and_notify(f"åˆ—å‡ºç›®å½•å†…å®¹å¤±è´¥: {str(e)}", "warning")

        return f"æ— æ³•è·å–æ¨¡å— {module_path} çš„ä»£ç å†…å®¹"

    def _create_prompt(self, module: Dict[str, Any], code_content: str) -> str:
        """åˆ›å»ºæç¤º

        Args:
            module: æ¨¡å—ä¿¡æ¯
            code_content: ä»£ç å†…å®¹

        Returns:
            æç¤º
        """
        # æ ¼å¼åŒ–æ¨¡å—ä¿¡æ¯
        module_info = json.dumps(module, indent=2, ensure_ascii=False)

        # æ ¼å¼åŒ–æç¤º
        return self.config.module_details_prompt_template.format(module_info=module_info, code_content=code_content)

    def _call_model(self, llm_config: Dict[str, Any], prompt: str, target_language: str, model: str) -> tuple:
        """è°ƒç”¨ LLM

        Args:
            llm_config: LLM é…ç½®
            prompt: æç¤º
            target_language: ç›®æ ‡è¯­è¨€
            model: æ¨¡å‹

        Returns:
            ç”Ÿæˆå†…å®¹ã€è´¨é‡åˆ†æ•°å’ŒæˆåŠŸæ ‡å¿—
        """
        try:
            # åˆ›å»º LLM å®¢æˆ·ç«¯
            llm_client = LLMClient(llm_config)

            # å‡†å¤‡ç³»ç»Ÿæç¤º
            system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä»£ç åº“æ–‡æ¡£ä¸“å®¶ï¼Œæ“…é•¿åˆ†æä»£ç å¹¶ç”Ÿæˆè¯¦ç»†çš„æ¨¡å—æ–‡æ¡£ã€‚
è¯·ç”¨{target_language}è¯­è¨€å›ç­”ï¼Œä½†ä¿æŒä»£ç ã€å˜é‡åå’ŒæŠ€æœ¯æœ¯è¯­çš„åŸå§‹å½¢å¼ã€‚
ä½ çš„å›ç­”åº”è¯¥æ˜¯æ ¼å¼è‰¯å¥½çš„ Markdownï¼Œä½¿ç”¨é€‚å½“çš„æ ‡é¢˜ã€åˆ—è¡¨ã€è¡¨æ ¼å’Œä»£ç å—ã€‚
ä½¿ç”¨è¡¨æƒ…ç¬¦å·ä½¿æ–‡æ¡£æ›´åŠ ç”ŸåŠ¨ï¼Œä¾‹å¦‚åœ¨æ ‡é¢˜å‰ä½¿ç”¨é€‚å½“çš„è¡¨æƒ…ç¬¦å·ã€‚
ç¡®ä¿æ–‡æ¡£ä¸­çš„ä»£ç å¼•ç”¨èƒ½å¤Ÿé“¾æ¥åˆ°æºä»£ç ã€‚"""

            # è°ƒç”¨ LLM
            messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]

            response = llm_client.completion(
                messages=messages, temperature=0.3, model=model, trace_name="ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£"
            , max_input_tokens=None)

            # è·å–å“åº”å†…å®¹
            content = llm_client.get_completion_content(response)

            # è¯„ä¼°è´¨é‡
            quality_score = self._evaluate_quality(content)

            return content, quality_score, True
        except Exception as e:
            log_and_notify(f"è°ƒç”¨ LLM å¤±è´¥: {str(e)}", "error")
            raise

    def _evaluate_quality(self, content: str) -> Dict[str, float]:
        """è¯„ä¼°å†…å®¹è´¨é‡

        Args:
            content: ç”Ÿæˆå†…å®¹

        Returns:
            è´¨é‡åˆ†æ•°
        """
        scores = {"completeness": 0.0, "structure": 0.0, "relevance": 0.0, "overall": 0.0}

        # æ£€æŸ¥å®Œæ•´æ€§
        required_sections = ["æ¨¡å—æ¦‚è¿°", "ç±»å’Œå‡½æ•°", "ä½¿ç”¨ç¤ºä¾‹", "ä¾èµ–å…³ç³»", "æ³¨æ„äº‹é¡¹"]

        found_sections = 0
        for section in required_sections:
            if section in content:
                found_sections += 1

        scores["completeness"] = found_sections / len(required_sections)

        # æ£€æŸ¥ç»“æ„
        has_headings = "# " in content
        has_lists = "- " in content or "* " in content
        has_code_blocks = "```" in content
        has_emojis = any(ord(c) > 0x1F000 for c in content)

        structure_score = 0.0
        if has_headings:
            structure_score += 0.4
        if has_lists:
            structure_score += 0.2
        if has_code_blocks:
            structure_score += 0.2
        if has_emojis:
            structure_score += 0.2

        scores["structure"] = structure_score

        # æ£€æŸ¥ç›¸å…³æ€§ï¼ˆç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥åŸºäºä»£ç åº“å†…å®¹è¯„ä¼°ï¼‰
        scores["relevance"] = 0.8  # å‡è®¾ç›¸å…³æ€§è¾ƒé«˜

        # è®¡ç®—æ€»ä½“åˆ†æ•°
        scores["overall"] = (scores["completeness"] + scores["structure"] + scores["relevance"]) / 3

        return scores

    def _get_module_file_name(self, module: Dict[str, Any]) -> str:
        """è·å–æ¨¡å—æ–‡ä»¶å

        Args:
            module: æ¨¡å—ä¿¡æ¯

        Returns:
            æ¨¡å—æ–‡ä»¶å
        """
        # å°è¯•ä½¿ç”¨æ¨¡å—åç§°
        name = module.get("name", "")
        if name:
            # æ›¿æ¢ä¸å…è®¸çš„å­—ç¬¦
            name = name.replace("/", "_").replace("\\", "_").replace(" ", "_").lower()
            return name

        # å¦‚æœæ²¡æœ‰åç§°ï¼Œä½¿ç”¨è·¯å¾„
        path = module.get("path", "unknown")
        # ç§»é™¤æ‰©å±•å
        path = os.path.splitext(path)[0]
        # æ›¿æ¢ä¸å…è®¸çš„å­—ç¬¦
        path = path.replace("/", "_").replace("\\", "_").replace(" ", "_").lower()

        return path

    def _generate_index(self, module_docs: List[Dict[str, Any]], target_language: str) -> str:
        """ç”Ÿæˆæ¨¡å—ç´¢å¼•æ–‡æ¡£

        Args:
            module_docs: æ¨¡å—æ–‡æ¡£åˆ—è¡¨
            target_language: ç›®æ ‡è¯­è¨€

        Returns:
            ç´¢å¼•æ–‡æ¡£å†…å®¹
        """
        # ç¡®å®šæ ‡é¢˜
        title = "æ¨¡å—è¯¦ç»†æ–‡æ¡£" if target_language == "zh" else "Module Details"

        # ç”Ÿæˆç´¢å¼•å†…å®¹
        content = f"# ğŸ“š {title}\n\n"

        if not module_docs:
            content += "æ²¡æœ‰æ‰¾åˆ°æ ¸å¿ƒæ¨¡å—ã€‚\n" if target_language == "zh" else "No core modules found.\n"
            return content

        # æ·»åŠ æ¨¡å—åˆ—è¡¨
        content += "## æ¨¡å—åˆ—è¡¨\n\n" if target_language == "zh" else "## Module List\n\n"

        for doc in module_docs:
            name = doc.get("name", "")
            path = doc.get("path", "")
            file_path = doc.get("file_path", "")

            # è·å–ç›¸å¯¹è·¯å¾„
            rel_path = os.path.relpath(file_path, os.path.dirname(os.path.dirname(file_path)))

            content += f"- [{name}]({rel_path}) - `{path}`\n"

        return content
