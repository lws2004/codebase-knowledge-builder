"""ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£èŠ‚ç‚¹ï¼Œç”¨äºç”Ÿæˆä»£ç åº“ä¸­å„æ¨¡å—çš„è¯¦ç»†æ–‡æ¡£ã€‚"""

import asyncio
import json
import os
import re
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, cast

from pocketflow import AsyncNode
from pydantic import BaseModel, Field

from ..utils.llm_wrapper import LLMClient
from ..utils.logger import log_and_notify


class GenerateModuleDetailsNodeConfig(BaseModel):
    """GenerateModuleDetailsNode é…ç½®"""

    retry_count: int = Field(3, ge=1, le=10, description="é‡è¯•æ¬¡æ•°")
    quality_threshold: float = Field(0.7, ge=0, le=1.0, description="è´¨é‡é˜ˆå€¼")
    model: str = Field("", description="LLM æ¨¡å‹ï¼Œä»é…ç½®ä¸­è·å–ï¼Œä¸åº”è®¾ç½®é»˜è®¤å€¼")
    output_format: str = Field("``", description="è¾“å‡ºæ ¼å¼")
    max_modules_per_batch: int = Field(5, description="æ¯æ‰¹æœ€å¤§æ¨¡å—æ•°")
    module_details_prompt_template: str = Field(
        """
        ä½ æ˜¯ä¸€ä¸ªä»£ç åº“æ–‡æ¡£ä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹æ¨¡å—ç”Ÿæˆè¯¦ç»†çš„æ–‡æ¡£ã€‚

        æ¨¡å—ä¿¡æ¯:
        {module_info}

        ä»£ç å†…å®¹:
        {code_content}

        è¯·æä¾›ä»¥ä¸‹å†…å®¹:
        1. æ¨¡å—æ¦‚è¿°
           - æ¨¡å—åç§°å’Œè·¯å¾„
           - æ¨¡å—çš„ä¸»è¦åŠŸèƒ½å’Œç”¨é€”
           - æ¨¡å—åœ¨æ•´ä¸ªä»£ç åº“ä¸­çš„è§’è‰²
        2. ç±»å’Œå‡½æ•°è¯¦è§£
           - æ¯ä¸ªç±»çš„åŠŸèƒ½ã€å±æ€§å’Œæ–¹æ³•
           - æ¯ä¸ªå‡½æ•°çš„åŠŸèƒ½ã€å‚æ•°å’Œè¿”å›å€¼
           - é‡è¦çš„ä»£ç ç‰‡æ®µè§£é‡Š
        3. ä½¿ç”¨ç¤ºä¾‹
           - å¦‚ä½•ä½¿ç”¨è¯¥æ¨¡å—çš„ä¸»è¦åŠŸèƒ½
           - å¸¸è§ç”¨ä¾‹å’Œæ¨¡å¼
        4. ä¾èµ–å…³ç³»
           - è¯¥æ¨¡å—ä¾èµ–çš„å…¶ä»–æ¨¡å—
           - ä¾èµ–è¯¥æ¨¡å—çš„å…¶ä»–æ¨¡å—
        5. æ³¨æ„äº‹é¡¹å’Œæœ€ä½³å®è·µ
           - ä½¿ç”¨è¯¥æ¨¡å—æ—¶éœ€è¦æ³¨æ„çš„äº‹é¡¹
           - æ¨èçš„æœ€ä½³å®è·µ

        è¯·ä»¥ ```` æ ¼å¼è¾“å‡ºï¼Œä½¿ç”¨é€‚å½“çš„æ ‡é¢˜ã€åˆ—è¡¨ã€è¡¨æ ¼å’Œä»£ç å—ã€‚
        ä½¿ç”¨è¡¨æƒ…ç¬¦å·ä½¿æ–‡æ¡£æ›´åŠ ç”ŸåŠ¨ï¼Œä¾‹å¦‚åœ¨æ ‡é¢˜å‰ä½¿ç”¨é€‚å½“çš„è¡¨æƒ…ç¬¦å·ã€‚
        ç¡®ä¿æ–‡æ¡£ä¸­çš„ä»£ç å¼•ç”¨èƒ½å¤Ÿé“¾æ¥åˆ°æºä»£ç ã€‚
        """,
        description="æ¨¡å—è¯¦ç»†æ–‡æ¡£æç¤ºæ¨¡æ¿",
    )


class AsyncGenerateModuleDetailsNode(AsyncNode):
    """ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£èŠ‚ç‚¹ï¼ˆå¼‚æ­¥ï¼‰ï¼Œç”¨äºå¹¶è¡Œç”Ÿæˆä»£ç åº“ä¸­å„æ¨¡å—çš„è¯¦ç»†æ–‡æ¡£"""

    llm_client: Optional[LLMClient] = None

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """åˆå§‹åŒ–ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£èŠ‚ç‚¹ (å¼‚æ­¥)

        Args:
            config: èŠ‚ç‚¹é…ç½®
        """
        super().__init__()
        from ..utils.env_manager import get_node_config

        default_config = get_node_config("generate_module_details")
        merged_config = default_config.copy()
        if config:
            merged_config.update(config)
        self.config = GenerateModuleDetailsNodeConfig(**merged_config)
        log_and_notify("åˆå§‹åŒ– AsyncGenerateModuleDetailsNode", "info")

    async def prep_async(self, shared: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡é˜¶æ®µï¼Œä»å…±äº«å­˜å‚¨ä¸­è·å–æ ¸å¿ƒæ¨¡å—å’Œä»£ç ç»“æ„

        Args:
            shared: å…±äº«å­˜å‚¨

        Returns:
            åŒ…å«æ ¸å¿ƒæ¨¡å—å’Œä»£ç ç»“æ„çš„å­—å…¸
        """
        log_and_notify("AsyncGenerateModuleDetailsNode: å‡†å¤‡é˜¶æ®µå¼€å§‹", "info")

        core_modules_data = shared.get("core_modules")
        if not core_modules_data or not core_modules_data.get("success", False):
            error_msg = "å…±äº«å­˜å‚¨ä¸­ç¼ºå°‘æœ‰æ•ˆæ ¸å¿ƒæ¨¡å—æ•°æ®"
            log_and_notify(error_msg, "error", notify=True)
            return {"error": error_msg}

        code_structure = shared.get("code_structure")
        if not code_structure or not code_structure.get("success", False):
            error_msg = "å…±äº«å­˜å‚¨ä¸­ç¼ºå°‘æœ‰æ•ˆä»£ç ç»“æ„"
            log_and_notify(error_msg, "error", notify=True)
            return {"error": error_msg}

        rag_data = shared.get("rag_data")  # Optional, provide default if missing
        if not rag_data:
            log_and_notify("å…±äº«å­˜å‚¨ä¸­ç¼ºå°‘ RAG æ•°æ®ï¼Œå°†ä½¿ç”¨ç©ºæ•°æ®", "warning")
            rag_data = {"files": [], "file_contents": {}, "chunks": [], "success": True}

        repo_path = shared.get("repo_path")
        if not repo_path:
            error_msg = "å…±äº«å­˜å‚¨ä¸­ç¼ºå°‘ä»“åº“è·¯å¾„"
            log_and_notify(error_msg, "error", notify=True)
            return {"error": error_msg}

        repo_name = shared.get("repo_name", "default_repo")

        llm_config_shared = shared.get("llm_config")
        if llm_config_shared:
            try:
                if not self.llm_client:
                    self.llm_client = LLMClient(config=llm_config_shared)
                log_and_notify("AsyncGenerateModuleDetailsNode: LLMClient initialized.", "info")
            except Exception as e:
                log_and_notify(
                    f"AsyncGenerateModuleDetailsNode: LLMClient initialization failed: {e}. "
                    f"Node will proceed without LLM if possible, or fail.",
                    "warning",
                )
                self.llm_client = None
        else:
            log_and_notify(
                "AsyncGenerateModuleDetailsNode: No LLM config found. Proceeding without LLM client.", "warning"
            )
            self.llm_client = None

        return {
            "modules_to_process": core_modules_data.get("modules", []),
            "code_structure": code_structure,
            "rag_data": rag_data,
            "repo_path": repo_path,
            "repo_name": repo_name,
            "target_language": shared.get("language", "zh"),
            "output_dir": shared.get("output_dir", "docs"),
            "retry_count": self.config.retry_count,
            "quality_threshold": self.config.quality_threshold,
            "model": self.config.model,
            "output_format": self.config.output_format,
        }

    async def _process_single_module(
        self, module_info: Dict[str, Any], prep_data: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """å¼‚æ­¥å¤„ç†å•ä¸ªæ¨¡å—çš„æ–‡æ¡£ç”Ÿæˆã€‚"""
        module_name = module_info.get("name", "unknown_module")
        module_path_in_repo = module_info.get("path", "")
        repo_name = prep_data["repo_name"]
        output_dir = prep_data["output_dir"]
        target_language = prep_data["target_language"]
        model = prep_data["model"]
        retry_count = prep_data["retry_count"]
        quality_threshold = prep_data["quality_threshold"]

        log_and_notify(f"AsyncGenerateModuleDetailsNode: å¼€å§‹å¤„ç†æ¨¡å— {module_name}", "debug")

        if not self.llm_client:
            log_and_notify(
                f"AsyncGenerateModuleDetailsNode: Skipping module {module_name} due to missing LLM client.", "error"
            )
            return {
                "name": module_name,
                "path": module_path_in_repo,
                "success": False,
                "error": "LLM client not available",
            }

        try:
            code_content = self._get_module_code(
                module_path_in_repo, prep_data["rag_data"], prep_data["code_structure"], prep_data["repo_path"]
            )
            prompt = self._create_prompt(module_info, code_content)

            for attempt in range(retry_count):
                try:
                    generated_content, quality_score, success = await self._call_model_async(
                        prompt, target_language, model
                    )

                    if success and quality_score["overall"] >= quality_threshold:
                        # Ensure modules_dir is created (might be called concurrently)
                        repo_specific_output_dir = os.path.join(output_dir, repo_name or "default_repo")
                        modules_dir = os.path.join(repo_specific_output_dir, "modules")
                        os.makedirs(modules_dir, exist_ok=True)

                        file_name_stem = self._get_module_file_name(module_info)
                        # ç¡®ä¿ä½¿ç”¨ .md æ‰©å±•å
                        file_path = os.path.join(modules_dir, f"{file_name_stem}.md")

                        # å¤„ç†ç”Ÿæˆçš„å†…å®¹ï¼Œç¡®ä¿å†…å®¹å®Œæ•´
                        processed_content = self._process_module_content(generated_content, module_name, repo_name)

                        # Asynchronous file write
                        await asyncio.to_thread(self._save_module_file, file_path, processed_content)

                        return {
                            "name": module_name,
                            "path": module_path_in_repo,
                            "file_path": file_path,
                            "content": processed_content,
                            "quality_score": quality_score,
                            "success": True,
                        }
                    elif success:
                        log_and_notify(
                            f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} ç”Ÿæˆè´¨é‡ä¸ä½³ "
                            f"(åˆ†æ•°: {quality_score['overall']}), é‡è¯• {attempt + 1}",
                            "warning",
                        )
                    else:
                        log_and_notify(
                            f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} _call_model_async æŒ‡ç¤ºå¤±è´¥, "
                            f"é‡è¯• {attempt + 1}",
                            "warning",
                        )

                except Exception as e_call:
                    log_and_notify(
                        f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} LLMè°ƒç”¨å¤±è´¥ "
                        f"(å°è¯• {attempt + 1}): {e_call}",
                        "warning",
                    )

                if attempt < retry_count - 1:
                    await asyncio.sleep(2**attempt)

            log_and_notify(f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} æ‰€æœ‰é‡è¯•å‡å¤±è´¥", "error")
            return {"name": module_name, "path": module_path_in_repo, "success": False, "error": "Max retries reached"}

        except Exception as e_process:
            log_and_notify(
                f"AsyncGenerateModuleDetailsNode: å¤„ç†æ¨¡å— {module_name} æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e_process}", "error"
            )
            return {"name": module_name, "path": module_path_in_repo, "success": False, "error": str(e_process)}

    async def exec_async(self, prep_res: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œé˜¶æ®µï¼Œå¹¶è¡Œç”Ÿæˆæ‰€æœ‰æ¨¡å—çš„è¯¦ç»†æ–‡æ¡£

        Args:
            prep_res: å‡†å¤‡é˜¶æ®µçš„ç»“æœ

        Returns:
            åŒ…å«æ‰€æœ‰æˆåŠŸç”Ÿæˆçš„æ¨¡å—æ–‡æ¡£ä¿¡æ¯å’Œä»»ä½•é”™è¯¯çš„å­—å…¸
        """
        log_and_notify("AsyncGenerateModuleDetailsNode: æ‰§è¡Œé˜¶æ®µå¼€å§‹ - å¹¶è¡Œå¤„ç†æ¨¡å—", "info")

        if "error" in prep_res:
            return {"error": prep_res["error"], "success": False, "module_docs": []}

        modules_to_process = prep_res.get("modules_to_process", [])
        if not modules_to_process:
            log_and_notify("AsyncGenerateModuleDetailsNode: æ²¡æœ‰æ‰¾åˆ°æ ¸å¿ƒæ¨¡å—è¿›è¡Œå¤„ç†", "warning")
            return {
                "module_docs": [],
                "success": True,
                "index_file_path": None,
            }  # No modules, but not an error state for the node itself

        # Create tasks for each module to be processed by _process_single_module
        tasks = [self._process_single_module(module_info, prep_res) for module_info in modules_to_process]

        log_and_notify(f"AsyncGenerateModuleDetailsNode: åˆ›å»º {len(tasks)} ä¸ªæ¨¡å—å¤„ç†ä»»åŠ¡", "info")

        # Run all module processing tasks concurrently
        # gather will return a list of results (dicts from _process_single_module)
        # or exceptions if a task raised one directly (though _process_single_module tries to catch)
        results_or_exceptions = await asyncio.gather(*tasks, return_exceptions=True)

        log_and_notify("AsyncGenerateModuleDetailsNode: æ‰€æœ‰æ¨¡å—å¤„ç†ä»»åŠ¡å®Œæˆ", "info")

        processed_module_docs = []
        errors_encountered = []

        for i, res_or_exc in enumerate(results_or_exceptions):
            module_name = modules_to_process[i].get("name", f"Module_{i + 1}")
            if isinstance(res_or_exc, Exception):
                err_msg = f"AsyncGenerateModuleDetailsNode: ä»»åŠ¡å¤„ç†æ¨¡å— {module_name} æ—¶å‘ç”Ÿæœªæ•è·å¼‚å¸¸: {res_or_exc}"
                log_and_notify(err_msg, "error")
                errors_encountered.append({"module": module_name, "error": str(res_or_exc)})
            elif isinstance(res_or_exc, dict) and res_or_exc.get("success"):
                processed_module_docs.append(res_or_exc)
            elif isinstance(res_or_exc, dict) and not res_or_exc.get("success"):
                err_msg = f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} å¤„ç†å¤±è´¥: "
                f"{res_or_exc.get('error', 'Unknown error')}"
                log_and_notify(err_msg, "error")
                errors_encountered.append({"module": module_name, "error": res_or_exc.get("error", "Unknown error")})
            else:  # Should not happen if _process_single_module always returns a dict or raises
                err_msg = f"AsyncGenerateModuleDetailsNode: æ¨¡å— {module_name} è¿”å›äº†æ„å¤–ç»“æœ: {res_or_exc}"
                log_and_notify(err_msg, "error")
                errors_encountered.append({"module": module_name, "error": "Unexpected result type"})

        # Generate index file for successfully processed modules
        index_content = ""
        index_file_path = None
        if processed_module_docs:
            try:
                index_content = self._generate_index(processed_module_docs, prep_res["target_language"])
                # Save index file (inside repo_name/modules directory)
                repo_specific_output_dir = os.path.join(prep_res["output_dir"], prep_res["repo_name"] or "default_repo")
                modules_dir = os.path.join(repo_specific_output_dir, "modules")
                os.makedirs(modules_dir, exist_ok=True)  # Ensure dir exists

                # ç¡®ä¿ä½¿ç”¨ .md æ‰©å±•å
                index_file_path = os.path.join(modules_dir, "index.md")
                await asyncio.to_thread(self._save_index_file, index_file_path, index_content)
                log_and_notify(f"AsyncGenerateModuleDetailsNode: æ¨¡å—ç´¢å¼•æ–‡ä»¶å·²ä¿å­˜åˆ°: {index_file_path}", "info")
            except Exception as e_index:
                log_and_notify(f"AsyncGenerateModuleDetailsNode: ç”Ÿæˆæˆ–ä¿å­˜æ¨¡å—ç´¢å¼•æ–‡ä»¶å¤±è´¥: {e_index}", "error")
                errors_encountered.append({"module": "index_generation", "error": str(e_index)})
                index_file_path = None  # Ensure it's None if saving failed

        return {
            "module_docs": processed_module_docs,  # List of dicts for successfully processed modules
            "index_file_path": index_file_path,
            "errors": errors_encountered,  # List of errors encountered
            "success": not errors_encountered,  # Overall success if no errors
        }

    async def post_async(self, shared: Dict[str, Any], _: Dict[str, Any], exec_res: Dict[str, Any]) -> str:
        """åå¤„ç†é˜¶æ®µï¼Œå°†æ¨¡å—è¯¦ç»†æ–‡æ¡£ä¿¡æ¯å­˜å‚¨åˆ°å…±äº«å­˜å‚¨ä¸­

        Args:
            shared: å…±äº«å­˜å‚¨
            _: å‡†å¤‡é˜¶æ®µçš„ç»“æœï¼ˆæœªä½¿ç”¨ï¼‰
            exec_res: æ‰§è¡Œé˜¶æ®µçš„ç»“æœ

        Returns:
            ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„åŠ¨ä½œ
        """
        log_and_notify("AsyncGenerateModuleDetailsNode: åå¤„ç†é˜¶æ®µå¼€å§‹", "info")

        # Check for catastrophic failure (e.g., from prep_async, or if exec_async itself failed fundamentally)
        if not exec_res.get("success", False) and "module_docs" not in exec_res:
            error_msg = exec_res.get("error", "AsyncGenerateModuleDetailsNode: æ‰§è¡Œé˜¶æ®µæœªçŸ¥é”™è¯¯æˆ–æ— æ¨¡å—å¤„ç†")
            log_and_notify(f"AsyncGenerateModuleDetailsNode: ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£å¤±è´¥: {error_msg}", "error", notify=True)
            shared["module_details"] = {
                "error": error_msg,
                "success": False,
                "docs": [],
                "index_file_path": None,
                "partial_errors": [],
            }
            return "error"

        # Store results, including potential partial errors
        shared["module_details"] = {
            "docs": exec_res.get("module_docs", []),  # Successfully generated module docs
            "index_file_path": exec_res.get("index_file_path"),
            "success": exec_res.get("success", True),  # Overall success of the node
            "partial_errors": exec_res.get("errors", []),  # Errors for specific modules or index
        }

        num_successful = len(exec_res.get("module_docs", []))
        num_errors = len(exec_res.get("errors", []))

        log_message = (
            f"AsyncGenerateModuleDetailsNode: æ¨¡å—è¯¦ç»†æ–‡æ¡£å¤„ç†å®Œæˆã€‚æˆåŠŸ: {num_successful}, å¤±è´¥/é”™è¯¯: {num_errors}."
        )
        if num_errors > 0:
            log_and_notify(log_message + f" è¯¦ç»†é”™è¯¯: {exec_res.get('errors')}", "warning")
        else:
            log_and_notify(log_message, "info")

        if not exec_res.get("success", True):
            # If exec overall failed (likely due to partial errors), return "partial_error"
            log_and_notify(
                "AsyncGenerateModuleDetailsNode: Returning 'partial_error' due to exec_res success flag being False.",
                "warning",
            )
            return "partial_error"

        return "default"

    def _get_module_code(
        self, module_path_in_repo: str, rag_data: Dict[str, Any], code_structure: Dict[str, Any], repo_path: str
    ) -> str:
        """è·å–æ¨¡å—çš„ä»£ç å†…å®¹ã€‚

        ä¼˜å…ˆä» RAG æ•°æ®çš„ file_contents ä¸­è·å–ã€‚
        å¦‚æœæ‰¾ä¸åˆ°ï¼Œåˆ™å°è¯•ä»æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿä¸­è¯»å–ã€‚
        å¦‚æœä»ç„¶æ‰¾ä¸åˆ°ï¼Œå°è¯•æ™ºèƒ½åŒ¹é…æ¨¡å—åç§°ã€‚

        Args:
            module_path_in_repo (str): æ¨¡å—åœ¨ä»“åº“ä¸­çš„ç›¸å¯¹è·¯å¾„ã€‚
            rag_data (Dict[str, Any]): RAG æ•°æ®ã€‚
            code_structure (Dict[str, Any]): ä»£ç ç»“æ„ã€‚
            repo_path (str): æœ¬åœ°ä»“åº“çš„ç»å¯¹è·¯å¾„ã€‚

        Returns:
            str: æ¨¡å—ä»£ç å†…å®¹ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å›é”™è¯¯ä¿¡æ¯å­—ç¬¦ä¸²ã€‚
        """
        # å¤„ç†æ¨¡å—è·¯å¾„
        # å¦‚æœæ¨¡å—è·¯å¾„æ˜¯ä¸€ä¸ªæ¨¡å—åè€Œä¸æ˜¯æ–‡ä»¶è·¯å¾„ï¼Œå°è¯•è½¬æ¢ä¸ºæ–‡ä»¶è·¯å¾„
        if not module_path_in_repo.endswith((".py", ".js", ".java", ".c", ".cpp", ".go", ".rb")):
            # å°è¯•å°†æ¨¡å—åè½¬æ¢ä¸ºæ–‡ä»¶è·¯å¾„
            module_parts = module_path_in_repo.split(".")
            possible_path = "/".join(module_parts) + ".py"
            log_and_notify(f"å°è¯•å°†æ¨¡å—å {module_path_in_repo} è½¬æ¢ä¸ºæ–‡ä»¶è·¯å¾„: {possible_path}", "info")
            module_path_in_repo = possible_path

        # Try to get from rag_data first - å°è¯•ç²¾ç¡®åŒ¹é…
        if module_path_in_repo in rag_data.get("file_contents", {}):
            log_and_notify(f"åœ¨RAGæ•°æ®ä¸­æ‰¾åˆ°ç²¾ç¡®åŒ¹é…çš„æ¨¡å—: {module_path_in_repo}", "info")
            return cast(str, rag_data["file_contents"][module_path_in_repo])

        # å°è¯•åœ¨RAGæ•°æ®ä¸­æŸ¥æ‰¾éƒ¨åˆ†åŒ¹é…
        module_name = os.path.basename(module_path_in_repo)
        module_name = os.path.splitext(module_name)[0]  # ç§»é™¤æ‰©å±•å

        # å°è¯•åœ¨RAGæ•°æ®ä¸­æŸ¥æ‰¾åŒ…å«æ¨¡å—åçš„æ–‡ä»¶
        for file_path, content_from_rag in rag_data.get("file_contents", {}).items():
            if module_name in file_path:
                log_and_notify(f"åœ¨RAGæ•°æ®ä¸­æ‰¾åˆ°éƒ¨åˆ†åŒ¹é…çš„æ¨¡å—: {file_path}", "info")
                return cast(str, content_from_rag)  # ç¡®ä¿è¿”å› str

        # Fallback to reading from file system - å°è¯•ç²¾ç¡®åŒ¹é…
        full_module_path = os.path.join(repo_path, module_path_in_repo)
        try:
            with open(full_module_path, "r", encoding="utf-8") as f:
                log_and_notify(f"åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­æ‰¾åˆ°ç²¾ç¡®åŒ¹é…çš„æ¨¡å—: {full_module_path}", "info")
                return f.read()
        except FileNotFoundError:
            log_and_notify(f"æ¨¡å—æ–‡ä»¶æœªæ‰¾åˆ°: {full_module_path}ï¼Œå°è¯•æ™ºèƒ½åŒ¹é…", "warning")

            # å°è¯•åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­æŸ¥æ‰¾éƒ¨åˆ†åŒ¹é…
            best_match = None
            best_match_score = 0

            for root, _, files in os.walk(repo_path):
                for file in files:
                    if file.endswith((".py", ".js", ".java", ".c", ".cpp", ".go", ".rb")):
                        # è®¡ç®—åŒ¹é…åˆ†æ•°
                        score = 0
                        if module_name in file:
                            score += 5  # æ–‡ä»¶ååŒ…å«æ¨¡å—å
                        if module_name == os.path.splitext(file)[0]:
                            score += 10  # æ–‡ä»¶åå®Œå…¨åŒ¹é…æ¨¡å—å

                        # æ£€æŸ¥è·¯å¾„åŒ¹é…
                        rel_path = os.path.relpath(os.path.join(root, file), repo_path)
                        path_parts = os.path.dirname(rel_path).split(os.sep)
                        module_parts = os.path.dirname(module_path_in_repo).split(os.sep)

                        # è®¡ç®—è·¯å¾„éƒ¨åˆ†åŒ¹é…æ•°
                        for part in module_parts:
                            if part and part in path_parts:
                                score += 3

                        if score > best_match_score:
                            best_match = os.path.join(root, file)
                            best_match_score = score

            # å¦‚æœæ‰¾åˆ°æœ€ä½³åŒ¹é…ï¼Œè¯»å–æ–‡ä»¶
            if best_match and best_match_score > 5:  # è®¾ç½®ä¸€ä¸ªæœ€ä½åŒ¹é…åˆ†æ•°é˜ˆå€¼
                try:
                    with open(best_match, "r", encoding="utf-8") as f:
                        rel_path = os.path.relpath(best_match, repo_path)
                        log_and_notify(f"åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„æ¨¡å—: {rel_path} (åˆ†æ•°: {best_match_score})", "info")
                        return f.read()
                except Exception as e:
                    log_and_notify(f"è¯»å–åŒ¹é…çš„æ¨¡å—æ–‡ä»¶æ—¶å‡ºé”™: {e}", "error")

            # å¦‚æœä»ç„¶æ‰¾ä¸åˆ°ï¼Œè¿”å›ä¸€ä¸ªæ¨¡æ‹Ÿçš„æ¨¡å—å†…å®¹
            log_and_notify(f"æ— æ³•æ‰¾åˆ°æ¨¡å— {module_name} çš„ä»»ä½•åŒ¹é…æ–‡ä»¶ï¼Œå°†ç”Ÿæˆæ¨¡æ‹Ÿå†…å®¹", "warning")
            return f"""
# æ¨¡æ‹Ÿçš„ {module_name} æ¨¡å—
# æ³¨æ„: æ­¤å†…å®¹æ˜¯è‡ªåŠ¨ç”Ÿæˆçš„ï¼Œå› ä¸ºæ— æ³•æ‰¾åˆ°å®é™…çš„æ¨¡å—æ–‡ä»¶

\"\"\"
{module_name} æ¨¡å—

æ­¤æ¨¡å—çš„å®é™…å†…å®¹æ— æ³•æ‰¾åˆ°ï¼Œè¿™æ˜¯ä¸€ä¸ªè‡ªåŠ¨ç”Ÿæˆçš„æ¨¡æ‹Ÿå†…å®¹ã€‚
æ–‡æ¡£å°†åŸºäºæ¨¡å—åç§°å’Œä¸Šä¸‹æ–‡ä¿¡æ¯è¿›è¡Œç”Ÿæˆã€‚
\"\"\"

# æ¨¡æ‹Ÿçš„ç±»å’Œå‡½æ•°
class {module_name.capitalize()}:
    \"\"\"
    {module_name.capitalize()} ç±»çš„æ¨¡æ‹Ÿå®ç°
    \"\"\"
    def __init__(self):
        \"\"\"åˆå§‹åŒ–å‡½æ•°\"\"\"
        pass

    def process(self, data):
        \"\"\"å¤„ç†æ•°æ®çš„æ¨¡æ‹Ÿæ–¹æ³•\"\"\"
        return data

def main():
    \"\"\"æ¨¡å—ä¸»å‡½æ•°\"\"\"
    pass

if __name__ == "__main__":
    main()
"""
        except Exception as e:
            log_and_notify(f"è¯»å–æ¨¡å—æ–‡ä»¶ {full_module_path} æ—¶å‡ºé”™: {e}", "error")
            return f"Error reading file {module_path_in_repo}: {e}"

    def _create_prompt(self, module_info: Dict[str, Any], code_content: str) -> str:
        """åˆ›å»ºå•ä¸ªæ¨¡å—çš„æç¤º

        Args:
            module_info: æ¨¡å—ä¿¡æ¯å­—å…¸
            code_content: æ¨¡å—ä»£ç å†…å®¹

        Returns:
            æç¤ºå­—ç¬¦ä¸²
        """
        # è·å–æ¨¡æ¿
        template = self.config.module_details_prompt_template

        # æ›¿æ¢æ¨¡æ¿ä¸­çš„å˜é‡ï¼ŒåŒæ—¶ä¿ç•™Mermaidå›¾è¡¨ä¸­çš„å¤§æ‹¬å·
        # ä½¿ç”¨å®‰å…¨çš„æ–¹å¼æ›¿æ¢å˜é‡ï¼Œé¿å…æ ¼å¼åŒ–å­—ç¬¦ä¸²ä¸­çš„é—®é¢˜
        template = template.replace("{module_info}", json.dumps(module_info, indent=2, ensure_ascii=False))
        template = template.replace("{code_content}", code_content)

        return template

    def _prepare_module_document(
        self,
        module_path_in_repo: str,
        rag_data: Dict[str, Any],
        code_structure: Dict[str, Any],
        repo_path: str,
        prep_data: Dict[str, Any],
    ) -> str:
        """å‡†å¤‡æ¨¡å—æ–‡æ¡£å†…å®¹

        Args:
            module_path_in_repo: æ¨¡å—è·¯å¾„
            rag_data: RAGæ•°æ®
            code_structure: ä»£ç ç»“æ„
            repo_path: ä»“åº“è·¯å¾„
            prep_data: å‡†å¤‡é˜¶æ®µæ•°æ®

        Returns:
            æ¨¡å—æ–‡æ¡£å†…å®¹
        """
        # repo_name = prep_data["repo_name"] # æœªä½¿ç”¨
        # output_dir = prep_data["output_dir"] # æœªä½¿ç”¨
        # target_language = prep_data["target_language"] # æœªä½¿ç”¨
        # model = prep_data["model"] # æœªä½¿ç”¨

        # è·å–æ¨¡å—åç§°
        module_name = Path(module_path_in_repo).stem

        # è·å–æ¨¡å—ä»£ç 
        module_code = self._get_module_code(module_path_in_repo, rag_data, code_structure, repo_path)

        # æ„å»ºæ–‡æ¡£å†…å®¹
        content_parts = []
        content_parts.append(f"# ğŸ“¦ {module_name} æ¨¡å—")

        # åˆ†ææ¨¡å—å†…å®¹
        content_parts.append("## ğŸ§  åˆ†æç»“æœ")
        content_parts.append(f"- **æ¨¡å—åç§°**: {module_name}")
        content_parts.append(f"- **æ–‡ä»¶è·¯å¾„**: {module_path_in_repo}")
        content_parts.append(f"- **ä»£ç è¡Œæ•°**: {len(module_code.splitlines())}")

        # æ·»åŠ æ¨¡å—åˆ†æ
        if "module_analysis" in rag_data:
            content_parts.append("\n## ğŸ“Š æ¨¡å—åˆ†æ")
            content_parts.append(rag_data["module_analysis"])

        # æ·»åŠ ä½¿ç”¨ç¤ºä¾‹
        if "examples" in rag_data:
            content_parts.append("\n## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹")
            content_parts.append(rag_data["examples"])

        # æ·»åŠ æœ€ä½³å®è·µ
        if "best_practices" in rag_data:
            content_parts.append("\n## âœ… æœ€ä½³å®è·µ")
            content_parts.append(rag_data["best_practices"])

        # æ·»åŠ æ³¨æ„äº‹é¡¹
        if "notes" in rag_data:
            content_parts.append("\n## âš ï¸ æ³¨æ„äº‹é¡¹")
            content_parts.append(rag_data["notes"])

        # æ„å»ºå®Œæ•´å†…å®¹
        return "\n".join(content_parts)

    async def _call_model_async(
        self, prompt: str, target_language: str, model: str
    ) -> Tuple[str, Dict[str, float], bool]:
        """è°ƒç”¨ LLM ç”Ÿæˆæ¨¡å—è¯¦ç»†æ–‡æ¡£ (å¼‚æ­¥)

        Args:
            prompt: ä¸»æç¤ºå†…å®¹
            target_language: ç›®æ ‡è¯­è¨€
            model: è¦ä½¿ç”¨çš„æ¨¡å‹åç§°

        Returns:
            (ç”Ÿæˆçš„æ–‡æ¡£å†…å®¹, è´¨é‡è¯„ä¼°åˆ†æ•°, æ˜¯å¦æˆåŠŸ)
        """
        assert self.llm_client is not None, "LLMClient has not been initialized!"

        system_prompt_content = (
            f"ä½ æ˜¯ä¸€ä¸ªä»£ç åº“æ–‡æ¡£ä¸“å®¶ï¼Œè¯·æŒ‰ç…§ç”¨æˆ·è¦æ±‚ä¸ºæŒ‡å®šæ¨¡å—ç”Ÿæˆè¯¦ç»†æ–‡æ¡£ã€‚ç›®æ ‡è¯­è¨€: {target_language}ã€‚"
            f"è¯·ç¡®ä¿ä½ çš„åˆ†ææ˜¯åŸºäºå®é™…æä¾›çš„æ¨¡å—ä¿¡æ¯å’Œä»£ç å†…å®¹ã€‚"
        )
        messages = [
            {"role": "system", "content": system_prompt_content},
            {"role": "user", "content": prompt},
        ]

        try:
            raw_response = await self.llm_client.acompletion(messages=messages, model=model)
            if not raw_response:
                log_and_notify("AsyncGenerateModuleDetailsNode: LLM è¿”å›ç©ºå“åº”", "error")
                return "", {}, False

            content = self.llm_client.get_completion_content(raw_response)
            if not content:
                log_and_notify("AsyncGenerateModuleDetailsNode: ä» LLM å“åº”ä¸­æå–å†…å®¹å¤±è´¥", "error")
                return "", {}, False

            quality_score = self._evaluate_quality(content)
            return content, quality_score, True

        except Exception as e:
            log_and_notify(f"AsyncGenerateModuleDetailsNode: _call_model_async å¼‚å¸¸: {str(e)}", "error")
            return "", {}, False

    def _evaluate_quality(self, content: str) -> Dict[str, float]:
        """è¯„ä¼°ç”Ÿæˆå†…å®¹çš„è´¨é‡ã€‚

        Args:
            content (str): ç”Ÿæˆçš„å†…å®¹ã€‚

        Returns:
            Dict[str, float]: åŒ…å«æ•´ä½“ã€å®Œæ•´æ€§ã€ç›¸å…³æ€§å’Œç»“æ„åˆ†æ•°çš„å­—å…¸ã€‚
        """
        score = {"overall": 0.0, "completeness": 0.0, "relevance": 0.0, "structure": 0.0}
        if not content or not content.strip():
            log_and_notify("å†…å®¹ä¸ºç©ºï¼Œè´¨é‡è¯„åˆ†ä¸º0", "warning")
            return score

        # Completeness based on expected sections
        expected_sections = ["æ¨¡å—æ¦‚è¿°", "ç±»å’Œå‡½æ•°è¯¦è§£", "ä½¿ç”¨ç¤ºä¾‹", "ä¾èµ–å…³ç³»", "æ³¨æ„äº‹é¡¹"]
        found_sections = sum(1 for section in expected_sections if section in content)
        score["completeness"] = found_sections / len(expected_sections)

        # Structure based on markdown elements
        if "##" in content:
            score["structure"] += 0.2  # Headers
        if "###" in content:
            score["structure"] += 0.2
        if "- " in content or "* " in content:
            score["structure"] += 0.2  # Lists
        if "```" in content:
            score["structure"] += 0.2  # Code blocks
        if any(table_marker in content for table_marker in ["| ---", "|:---"]):
            score["structure"] += 0.2  # Tables
        score["structure"] = min(1.0, score["structure"])

        # Relevance (simple checks for now)
        # A more advanced check could parse module_info_for_eval (e.g., module name, key functions)
        # and see if they are mentioned in the content.
        relevance_score = 0.0
        if "æ¨¡å—" in content and "åŠŸèƒ½" in content:
            relevance_score += 0.5
        if len(content) > 200:
            relevance_score += 0.3  # Very basic length check
        if len(content) > 500:
            relevance_score += 0.2
        score["relevance"] = min(1.0, relevance_score)

        score["overall"] = score["completeness"] * 0.4 + score["structure"] * 0.3 + score["relevance"] * 0.3
        score["overall"] = min(1.0, score["overall"])

        log_and_notify(f"è´¨é‡è¯„ä¼°å®Œæˆ: {score}", "debug")
        return score

    def _get_module_file_name(self, module: Dict[str, Any]) -> str:
        """è·å–æ¨¡å—æ–‡æ¡£çš„æ–‡ä»¶å (ä¸å«æ‰©å±•å)ã€‚

        Args:
            module (Dict[str, Any]): æ¨¡å—ä¿¡æ¯å­—å…¸ã€‚

        Returns:
            str: æ–‡ä»¶åå­—ç¬¦ä¸²ã€‚
        """
        module_name = module.get("name", "unknown_module")
        # Sanitize module name for use as a filename
        # Replace path separators and other problematic characters
        file_name = module_name.replace(os.path.sep, "_").replace("/", "_").replace("\\\\", "_")
        # Remove or replace other invalid filename characters (simplified example)
        file_name = "".join(c if c.isalnum() or c in ["_", "-"] else "_" for c in file_name)
        return file_name if file_name else "module"

    def _generate_index(self, module_docs: List[Dict[str, Any]], target_language: str) -> str:
        """ä¸ºç”Ÿæˆçš„æ¨¡å—æ–‡æ¡£åˆ›å»ºç´¢å¼•æ–‡ä»¶å†…å®¹ã€‚

        Args:
            module_docs (List[Dict[str, Any]]): æˆåŠŸç”Ÿæˆçš„æ¨¡å—æ–‡æ¡£åˆ—è¡¨ã€‚
                                              æ¯ä¸ªå­—å…¸åº”åŒ…å« "name", "path", "file_path"ã€‚
            target_language (str): ç›®æ ‡è¯­è¨€ (å½“å‰æœªä½¿ç”¨ï¼Œä½†å¯ä»¥ç”¨äºæœ¬åœ°åŒ–æ ‡é¢˜)ã€‚

        Returns:
            str: Markdown æ ¼å¼çš„ç´¢å¼•å†…å®¹ã€‚
        """
        if not module_docs:
            return "æ¨¡å—æ–‡æ¡£ä¸ºç©ºã€‚\n"

        title = "ğŸ“š æ¨¡å—æ–‡æ¡£ç´¢å¼•"
        if target_language == "en":
            title = "ğŸ“š Module Documentation Index"

        lines = [f"# {title}\n\n"]
        lines.append("## ğŸ“‹ æ¦‚è¿°\n\n")
        lines.append(
            "æœ¬æ–‡æ¡£åŒ…å«å¯¹ä»£ç åº“ä¸­å„ä¸ªæ¨¡å—çš„è¯¦ç»†è¯´æ˜ã€‚é€šè¿‡è¿™äº›æ–‡æ¡£ï¼Œæ‚¨å¯ä»¥äº†è§£æ¯ä¸ªæ¨¡å—çš„åŠŸèƒ½ã€APIå’Œä½¿ç”¨æ–¹æ³•ã€‚\n\n"
        )

        lines.append("## ğŸ“¦ æ¨¡å—åˆ—è¡¨\n\n")
        lines.append("ä¸‹è¡¨åˆ—å‡ºäº†æ‰€æœ‰å¯ç”¨çš„æ¨¡å—æ–‡æ¡£ï¼š\n\n")
        lines.append("| æ¨¡å—åç§° | æ¨¡å—è·¯å¾„ | æ–‡æ¡£é“¾æ¥ |")
        lines.append("|---|---|---|")

        for doc in sorted(module_docs, key=lambda x: x.get("name", "")):
            name = doc.get("name", "N/A")
            module_repo_path = doc.get("path", "N/A")  # Original path in repo
            # file_path is absolute, need relative path from modules/index.md to modules/module_file.md
            # Assuming index.md is in "modules" dir, and module files are also in "modules" dir.
            doc_file_name = os.path.basename(doc.get("file_path", ""))
            # ç¡®ä¿é“¾æ¥ä½¿ç”¨ .md æ‰©å±•å
            doc_file_name_md = os.path.splitext(doc_file_name)[0] + ".md"
            relative_link = f"./{doc_file_name_md}"  # Link from modules/index.md to modules/xxxx.md

            # ä½¿ç”¨ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶åä½œä¸ºæ˜¾ç¤ºåç§°
            display_name = os.path.splitext(doc_file_name)[0]
            lines.append(f"| {name} | `{module_repo_path}` | [{display_name}]({relative_link}) |")

        lines.append("\n")
        return "\n".join(lines)

    def _process_module_content(self, content: str, module_name: str, repo_name: str) -> str:
        # æ£€æŸ¥å†…å®¹æ˜¯å¦åŒ…å«å¿…è¦çš„éƒ¨åˆ†
        has_title = bool(re.search(r"^#\s+.*", content, re.MULTILINE))
        has_overview = "æ¦‚è¿°" in content or "æ¨¡å—æ¦‚è¿°" in content
        has_api = "API" in content or "å‡½æ•°" in content or "ç±»" in content
        has_examples = "ç¤ºä¾‹" in content or "ä½¿ç”¨ç¤ºä¾‹" in content

        result_parts = []

        # æ·»åŠ å…ƒæ•°æ®å’Œæ ‡é¢˜
        result_parts.extend(self._prepare_metadata_and_title(content, module_name))
        content = re.sub(r"^#\s+.*\n", "", content, 1, re.MULTILINE) if has_title else content

        # ä¿ç•™åŸå†…å®¹æˆ–ç”Ÿæˆé»˜è®¤å†…å®¹
        if content.strip() and (has_overview or has_api or has_examples):
            result_parts.append(content)
        else:
            result_parts.extend(self._generate_default_content(module_name, repo_name))

        return ''.join(result_parts)

    def _prepare_metadata_and_title(self, content: str, module_name: str) -> List[str]:
        """å‡†å¤‡å…ƒæ•°æ®å’Œæ ‡é¢˜éƒ¨åˆ†"""
        parts = []
        # æ·»åŠ å…ƒæ•°æ®
        parts.append(f"---\ntitle: {module_name.replace('_', '.').title()}\ncategory: Modules\n---\n\n")
        # æ·»åŠ æ ‡é¢˜
        title_match = re.search(r"^#\s+(.*)", content, re.MULTILINE)
        if title_match:
            parts.append(f"# ğŸ“¦ {title_match.group(1)}\n\n")
        else:
            parts.append(f"# ğŸ“¦ {module_name.replace('_', '.').title()}\n\n")
        return parts

    def _generate_default_content(self, module_name: str, repo_name: str) -> List[str]:
        """ç”Ÿæˆé»˜è®¤å†…å®¹éƒ¨åˆ†"""
        parts = []
        parts.extend(self._generate_default_overview(module_name, repo_name))
        parts.extend(self._generate_default_api(module_name))
        parts.extend(self._generate_default_examples(module_name))
        parts.extend(self._generate_default_dependencies(module_name, repo_name))
        parts.extend(self._generate_best_practices(module_name))
        return parts

    def _generate_default_overview(self, module_name: str, repo_name: str) -> List[str]:
        """ç”Ÿæˆé»˜è®¤çš„æ¨¡å—æ¦‚è¿°"""
        return [
            "## ğŸ“‹ æ¨¡å—æ¦‚è¿°\n\n",
            "### ğŸ“ æ¨¡å—åç§°å’Œè·¯å¾„\n",
            f"- **æ¨¡å—åç§°**: `{module_name}`\n",
            f"- **æ¨¡å—è·¯å¾„**: åœ¨{repo_name}ä»£ç åº“ä¸­\n\n"
        ]

    def _generate_default_api(self, module_name: str) -> List[str]:
        """ç”Ÿæˆé»˜è®¤çš„APIéƒ¨åˆ†"""
        return [
            "## ğŸ”§ ç±»å’Œå‡½æ•°è¯¦è§£\n\n",
            "### ğŸ“¦ ä¸»è¦ç±»\n\n",
            f"- `{module_name.split('.')[-1].capitalize()}`: ä¸»è¦ç±»\n\n",
            "### ğŸ“¦ ä¸»è¦å‡½æ•°\n\n",
            "- `main()`: ä¸»è¦å‡½æ•°\n\n"
        ]

    def _generate_default_examples(self, module_name: str) -> List[str]:
        """ç”Ÿæˆé»˜è®¤çš„ä½¿ç”¨ç¤ºä¾‹"""
        return [
            "## ğŸ’» ä½¿ç”¨ç¤ºä¾‹\n\n",
            "``python\n",
            f"# {module_name} ä½¿ç”¨ç¤ºä¾‹\n",
            f"import {module_name.split('.')[0]}\n\n",
            "# ç¤ºä¾‹ä»£ç \n",
            "```\n\n"
        ]

    def _generate_default_dependencies(self, module_name: str, repo_name: str) -> List[str]:
        """ç”Ÿæˆé»˜è®¤çš„ä¾èµ–å…³ç³»"""
        return [
            "## ğŸ”„ ä¾èµ–å…³ç³»\n\n",
            "### ğŸ“Œ è¯¥æ¨¡å—ä¾èµ–çš„å…¶ä»–æ¨¡å—\n\n",
            f"- å…¶ä»–{repo_name}æ¨¡å—\n\n",
            "### ğŸ“Œ ä¾èµ–è¯¥æ¨¡å—çš„å…¶ä»–æ¨¡å—\n\n",
            f"- å…¶ä»–{repo_name}æ¨¡å—\n\n"
        ]

    def _generate_best_practices(self, module_name: str) -> List[str]:
        """ç”Ÿæˆæ³¨æ„äº‹é¡¹å’Œæœ€ä½³å®è·µ"""
        return [
            "## ğŸš€ æ³¨æ„äº‹é¡¹å’Œæœ€ä½³å®è·µ\n\n",
            "### ğŸš© æ³¨æ„äº‹é¡¹\n\n",
            f"ä½¿ç”¨{module_name}æ¨¡å—æ—¶çš„æ³¨æ„äº‹é¡¹ã€‚\n\n",
            "### ğŸŒŸ æœ€ä½³å®è·µ\n\n",
            f"ä½¿ç”¨{module_name}æ¨¡å—çš„æœ€ä½³å®è·µã€‚\n\n"
        ]

    def _save_module_file(self, file_path: str, content: str) -> None:
        """å°‡å…§å®¹ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆè¨­è¨ˆç‚ºåœ¨ç·šç¨‹ä¸­é‹è¡Œï¼‰ã€‚

        Args:
            file_path (str): è¦ä¿å­˜åˆ°çš„æ–‡ä»¶è·¯å¾‘ã€‚
            content (str): è¦ä¿å­˜çš„å…§å®¹ã€‚
        """
        try:
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(content)
        except Exception as e:
            # Log error, but don't crash the whole process, error is reported per-module
            log_and_notify(f"AsyncGenerateModuleDetailsNode: Failed to save module file {file_path}: {e}", "error")
            # Re-raise might be too disruptive if called via to_thread, let gather report it.
            # Consider how to propagate this specific file save error if needed.

    def _save_index_file(self, file_path: str, content: str) -> None:
        """å°‡ç´¢å¼•å…§å®¹ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆè¨­è¨ˆç‚ºåœ¨ç·šç¨‹ä¸­é‹è¡Œï¼‰ã€‚

        Args:
            file_path (str): è¦ä¿å­˜åˆ°çš„æ–‡ä»¶è·¯å¾‘ã€‚
            content (str): è¦ä¿å­˜çš„ç´¢å¼•å…§å®¹ã€‚
        """
        try:
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(content)
        except Exception as e:
            log_and_notify(f"AsyncGenerateModuleDetailsNode: Failed to save index file {file_path}: {e}", "error")
            # Raise error here, as index saving failure might be more critical than a single module file?
            # Or handle it within the caller (_exec_async) based on gather results.
            raise  # Re-raising allows gather to catch it
