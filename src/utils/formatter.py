"""æ ¼å¼åŒ–å·¥å…·ï¼Œç”¨äºæ ¼å¼åŒ–ç”Ÿæˆçš„æ–‡æ¡£å†…å®¹ã€‚"""

import os
import re
from pathlib import Path
from typing import Any, Dict, List, Optional


def fix_mermaid_syntax(content: str, llm_client=None, context: Optional[str] = None) -> str:
    """ä¿®å¤Mermaidå›¾è¡¨ä¸­çš„è¯­æ³•é—®é¢˜

    Args:
        content: åŸå§‹å†…å®¹
        llm_client: LLM å®¢æˆ·ç«¯å®ä¾‹
        context: ä¸Šä¸‹æ–‡ä¿¡æ¯

    Returns:
        ä¿®å¤åçš„å†…å®¹
    """
    try:
        # ä½¿ç”¨æ–°çš„éªŒè¯å’Œé‡æ–°ç”Ÿæˆç³»ç»Ÿ
        from .mermaid_regenerator import validate_and_regenerate_mermaid

        fixed_content, was_fixed = validate_and_regenerate_mermaid(content, llm_client, context)

        if was_fixed:
            print("æ£€æµ‹åˆ°Mermaidè¯­æ³•é”™è¯¯ï¼Œå·²ä½¿ç”¨LLMé‡æ–°ç”Ÿæˆ")

        return fixed_content

    except Exception as e:
        print(f"ä½¿ç”¨æ–°éªŒè¯ç³»ç»Ÿå¤±è´¥ï¼Œå›é€€åˆ°æ—§ç³»ç»Ÿ: {e}")
        # å›é€€åˆ°åŸæœ‰é€»è¾‘
        return _legacy_fix_mermaid_syntax(content)


def _legacy_fix_mermaid_syntax(content: str) -> str:
    """æ—§ç‰ˆæœ¬çš„ Mermaid ä¿®å¤é€»è¾‘ï¼ˆå›é€€æ–¹æ¡ˆï¼‰

    Args:
        content: åŸå§‹å†…å®¹

    Returns:
        ä¿®å¤åçš„å†…å®¹
    """
    import re

    # æŸ¥æ‰¾æ‰€æœ‰Mermaidä»£ç å—ï¼Œä½¿ç”¨æ›´ç²¾ç¡®çš„æ­£åˆ™è¡¨è¾¾å¼
    mermaid_pattern = r"```mermaid\n((?:(?!```)[\s\S])*?)\n```"

    def fix_mermaid_block(match):
        mermaid_content = match.group(1).strip()

        # å¦‚æœå†…å®¹ä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œè·³è¿‡
        if not mermaid_content or len(mermaid_content) < 5:
            return match.group(0)

        # æ£€æŸ¥æ˜¯å¦æœ‰å¸¸è§çš„è¯­æ³•é”™è¯¯
        has_errors = _detect_mermaid_errors(mermaid_content)

        if not has_errors:
            return match.group(0)  # æ— é”™è¯¯ï¼Œè¿”å›åŸå†…å®¹

        print("æ£€æµ‹åˆ°Mermaidè¯­æ³•é”™è¯¯ï¼Œæ­£åœ¨ä¿®å¤...")

        try:
            # é¦–å…ˆå°è¯•ç®€å•ä¿®å¤
            fixed_content = _simple_mermaid_fix(mermaid_content)

            # å¦‚æœç®€å•ä¿®å¤åä»æœ‰é”™è¯¯ï¼Œå°è¯•LLMä¿®å¤
            if _detect_mermaid_errors(fixed_content):
                fixed_content = _llm_mermaid_fix(mermaid_content)

            return f"```mermaid\n{fixed_content}\n```"

        except Exception as e:
            print(f"ä¿®å¤Mermaidå›¾è¡¨å¤±è´¥: {e}")
            # å›é€€åˆ°åŸå†…å®¹
            return match.group(0)

    # åº”ç”¨ä¿®å¤åˆ°æ‰€æœ‰Mermaidä»£ç å—
    fixed_content = re.sub(mermaid_pattern, fix_mermaid_block, content, flags=re.DOTALL)

    return fixed_content


def _detect_mermaid_errors(mermaid_content: str) -> bool:
    """æ£€æµ‹Mermaidå›¾è¡¨ä¸­çš„è¯­æ³•é”™è¯¯

    Args:
        mermaid_content: Mermaidå›¾è¡¨å†…å®¹

    Returns:
        æ˜¯å¦å­˜åœ¨è¯­æ³•é”™è¯¯
    """
    import re

    # æ£€æŸ¥å„ç§è¯­æ³•é”™è¯¯
    errors = [
        # [|text|text] æ ¼å¼é”™è¯¯
        re.search(r"\[\|[^|]*\|[^|]*\]", mermaid_content),
        # åµŒå¥—æ–¹æ‹¬å·é”™è¯¯ï¼Œå¦‚ A[A[text]] æˆ– B[B["text"]
        re.search(r"([A-Z])\[\1\[", mermaid_content),
        # æœªé—­åˆçš„å¼•å·åœ¨æ–¹æ‹¬å·ä¸­
        re.search(r'\[[^"]*"[^"]*\](?!\s*-->)', mermaid_content),
        # ç®­å¤´è¯­æ³•é”™è¯¯ï¼Œå¦‚ --> A (text)"]
        re.search(r'-->\s*[A-Z]\s*\([^)]*\)"\]', mermaid_content),
        # è¡Œå°¾åˆ†å·
        re.search(r";\s*$", mermaid_content, re.MULTILINE),
        # èŠ‚ç‚¹æ ‡ç­¾ä¸­çš„ç‰¹æ®Šç¬¦å·ï¼ˆæ–°å¢ï¼‰
        re.search(r"\[([^]]*)\([^)]*\)", mermaid_content),  # æ‹¬å·
        re.search(r'\[([^]]*)"([^"]*)"', mermaid_content),  # å¼•å·
        re.search(r"\[([^]]*)\{([^}]*)\}", mermaid_content),  # å¤§æ‹¬å·
        # subgraphåç§°ä¸èŠ‚ç‚¹åç§°å†²çª
        _check_subgraph_conflicts(mermaid_content),
    ]

    return any(errors)


def _check_subgraph_conflicts(mermaid_content: str) -> bool:
    """æ£€æŸ¥subgraphåç§°ä¸èŠ‚ç‚¹åç§°å†²çª

    Args:
        mermaid_content: Mermaidå›¾è¡¨å†…å®¹

    Returns:
        æ˜¯å¦å­˜åœ¨å†²çª
    """
    import re

    # æå–subgraphåç§°
    subgraph_names = re.findall(r"subgraph\s+(\w+)", mermaid_content)

    # æå–èŠ‚ç‚¹åç§°
    node_names = re.findall(r"(\w+)\[", mermaid_content)

    # æ£€æŸ¥æ˜¯å¦æœ‰å†²çª
    conflicts = set(subgraph_names) & set(node_names)

    return len(conflicts) > 0


def _llm_mermaid_fix(mermaid_content: str) -> str:
    """ä½¿ç”¨LLMä¿®å¤Mermaidå›¾è¡¨

    Args:
        mermaid_content: åŸå§‹Mermaidå†…å®¹

    Returns:
        ä¿®å¤åçš„Mermaidå†…å®¹
    """
    try:
        from src.utils.env_manager import get_llm_config
        from src.utils.llm_wrapper.llm_client import LLMClient

        config = get_llm_config()
        llm_client = LLMClient(config)

        prompt = f"""è¯·ä¿®å¤ä»¥ä¸‹Mermaidå›¾è¡¨ä¸­çš„è¯­æ³•é”™è¯¯ï¼Œç¡®ä¿ç”Ÿæˆçš„å›¾è¡¨ç¬¦åˆMermaidè¯­æ³•è§„èŒƒï¼š

åŸå§‹å›¾è¡¨ï¼š
```mermaid
{mermaid_content}
```

ä¿®å¤è¦æ±‚ï¼š
1. ç§»é™¤ [|text|text] æ ¼å¼çš„é”™è¯¯è¯­æ³•
2. ä¿®å¤åµŒå¥—æ–¹æ‹¬å·é—®é¢˜ï¼Œå¦‚ A[A[text]] åº”æ”¹ä¸º A[text]
3. è§£å†³subgraphåç§°ä¸èŠ‚ç‚¹åç§°å†²çªé—®é¢˜
4. ç§»é™¤è¡Œå°¾çš„åˆ†å·
5. ä¿®å¤ç®­å¤´è¯­æ³•é”™è¯¯
6. ç§»é™¤èŠ‚ç‚¹æ ‡ç­¾ä¸­çš„ç‰¹æ®Šç¬¦å·ï¼š
   - ç§»é™¤æ‹¬å·ï¼šA[æ–‡æœ¬(è¯´æ˜)] åº”æ”¹ä¸º A[æ–‡æœ¬è¯´æ˜]
   - ç§»é™¤å¼•å·ï¼šA[æ–‡æœ¬"å¼•ç”¨"] åº”æ”¹ä¸º A[æ–‡æœ¬å¼•ç”¨]
   - ç§»é™¤å¤§æ‹¬å·ï¼šA[æ–‡æœ¬{{å†…å®¹}}] åº”æ”¹ä¸º A[æ–‡æœ¬å†…å®¹]
7. ç¡®ä¿ä¸­æ–‡å­—ç¬¦æ­£ç¡®æ˜¾ç¤º
8. ä¿æŒå›¾è¡¨çš„åŸå§‹å«ä¹‰å’Œç»“æ„

è¯·åªè¿”å›ä¿®å¤åçš„Mermaidä»£ç ï¼ˆä¸åŒ…å«```mermaidæ ‡è®°ï¼‰ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šï¼š"""

        response = llm_client.generate_text(prompt, max_tokens=1000)

        # æ¸…ç†å“åº”ï¼Œç§»é™¤å¯èƒ½çš„ä»£ç å—æ ‡è®°
        cleaned_response = response.strip()
        if cleaned_response.startswith("```mermaid"):
            cleaned_response = cleaned_response[10:]
        if cleaned_response.endswith("```"):
            cleaned_response = cleaned_response[:-3]

        return cleaned_response.strip()

    except Exception as e:
        print(f"LLMä¿®å¤å¤±è´¥: {e}")
        return mermaid_content


def _simple_mermaid_fix(mermaid_content: str) -> str:
    """ç®€å•çš„Mermaidè¯­æ³•ä¿®å¤ï¼ˆå›é€€æ–¹æ¡ˆï¼‰

    Args:
        mermaid_content: åŸå§‹Mermaidå†…å®¹

    Returns:
        ä¿®å¤åçš„Mermaidå†…å®¹ï¼ˆä¸åŒ…å«ä»£ç å—æ ‡è®°ï¼‰
    """
    import re

    # 1. ä¿®å¤ [|text|text] æ ¼å¼é”™è¯¯ï¼Œé€è¡Œå¤„ç†ä»¥ä¿æŒç»“æ„
    lines = mermaid_content.split("\n")
    fixed_lines = []
    for line in lines:
        if re.search(r"\[\|[^|]*\|[^|]*\]", line):
            # ä¿®å¤è¿™ä¸€è¡Œçš„ç®¡é“ç¬¦å·ï¼Œä¿ç•™å…¶ä½™å†…å®¹
            fixed_line = re.sub(r"\[\|([^|]*)\|([^|]*)\]", r"[\1]", line)
            fixed_lines.append(fixed_line)
        else:
            fixed_lines.append(line)

    mermaid_content = "\n".join(fixed_lines)

    # 0. ä¿®å¤èŠ‚ç‚¹æ ‡ç­¾ä¸­çš„ç‰¹æ®Šç¬¦å·ï¼ˆæ–°å¢ï¼‰
    # ç§»é™¤èŠ‚ç‚¹æ ‡ç­¾ä¸­çš„æ‹¬å·å’Œå…¶ä»–ç‰¹æ®Šç¬¦å·
    mermaid_content = re.sub(r"\[([^]]*)\([^)]*\)([^]]*)\]", r"[\1\2]", mermaid_content)  # ç§»é™¤æ ‡ç­¾ä¸­çš„æ‹¬å·
    mermaid_content = re.sub(r'\[([^]]*)"([^"]*)"([^]]*)\]', r"[\1\2\3]", mermaid_content)  # ç§»é™¤æ ‡ç­¾ä¸­çš„å¼•å·
    mermaid_content = re.sub(r"\[([^]]*)\{([^}]*)\}([^]]*)\]", r"[\1\2\3]", mermaid_content)  # ç§»é™¤æ ‡ç­¾ä¸­çš„å¤§æ‹¬å·

    # 2. ä¿®å¤åµŒå¥—æ–¹æ‹¬å·é—®é¢˜ï¼Œå¦‚ A[A[text]] -> A[text]
    mermaid_content = re.sub(r"([A-Z])\[\1\[([^\]]*)\]\]", r"\1[\2]", mermaid_content)

    # 3. ä¿®å¤å…¶ä»–åµŒå¥—æ–¹æ‹¬å·é—®é¢˜ï¼Œå¦‚ B[B["text"] -> B["text"]
    mermaid_content = re.sub(r"([A-Z])\[\1\[\"([^\"]*)\"]", r'\1["\2"]', mermaid_content)

    # 4. ä¿®å¤æœªé—­åˆçš„åµŒå¥—æ–¹æ‹¬å·ï¼Œå¦‚ A[A[text] -> A[text]
    mermaid_content = re.sub(r"([A-Z])\[\1\[([^\]]*)\](?!\])", r"\1[\2]", mermaid_content)

    # 5. ä¿®å¤ç®­å¤´è¯­æ³•é”™è¯¯ï¼Œå¦‚ --> A (text)"] -> --> A
    mermaid_content = re.sub(r'-->\s*([A-Z])\s*\([^)]*\)"\]', r"--> \1", mermaid_content)

    # 6. ç§»é™¤è¡Œå°¾åˆ†å·
    mermaid_content = re.sub(r";\s*$", "", mermaid_content, flags=re.MULTILINE)

    # 7. ä¿®å¤æœªé—­åˆçš„å¼•å· - æ›´ç²¾ç¡®çš„æ¨¡å¼
    mermaid_content = re.sub(r'\[([^"\]]*)"([^"\]]*)\](?!\s*-->)', r'["\1\2"]', mermaid_content)

    # 8. ä¿®å¤æ›´å¤æ‚çš„åµŒå¥—æ–¹æ‹¬å·æƒ…å†µ
    mermaid_content = re.sub(r'([A-Z])\[([A-Z])\["([^"]*)"', r'\1["\3"]', mermaid_content)

    # 9. ä¿®å¤subgraphåç§°å†²çª
    subgraph_names = re.findall(r"subgraph\s+(\w+)", mermaid_content)
    node_names = re.findall(r"(\w+)\[", mermaid_content)
    conflicts = set(subgraph_names) & set(node_names)

    for conflict in conflicts:
        # å°†subgraphåç§°æ”¹ä¸ºé¿å…å†²çª
        mermaid_content = re.sub(rf"subgraph\s+{conflict}\b", f"subgraph {conflict}Group", mermaid_content)

    # 10. æ™ºèƒ½æ¸…ç†ï¼Œä¿ç•™å›¾è¡¨ç»“æ„
    lines = mermaid_content.split("\n")
    cleaned_lines = []

    for line in lines:
        stripped_line = line.strip()
        if stripped_line:
            # ä¿ç•™æœ‰å†…å®¹çš„è¡Œ
            cleaned_lines.append(stripped_line)
        elif (
            cleaned_lines
            and cleaned_lines[-1]
            and not cleaned_lines[-1].startswith(("graph", "flowchart", "subgraph", "end"))
        ):
            # åœ¨æŸäº›æƒ…å†µä¸‹ä¿ç•™ç©ºè¡Œä½œä¸ºåˆ†éš”
            if len(cleaned_lines) > 0 and "-->" not in cleaned_lines[-1]:
                cleaned_lines.append("")

    # ç§»é™¤å¼€å¤´å’Œæœ«å°¾çš„ç©ºè¡Œ
    while cleaned_lines and cleaned_lines[0] == "":
        cleaned_lines.pop(0)
    while cleaned_lines and cleaned_lines[-1] == "":
        cleaned_lines.pop()

    return "\n".join(cleaned_lines)


def validate_mermaid_syntax(mermaid_content: str) -> tuple[bool, list[str]]:
    """éªŒè¯Mermaidå›¾è¡¨è¯­æ³•

    Args:
        mermaid_content: Mermaidå›¾è¡¨å†…å®¹

    Returns:
        (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯åˆ—è¡¨)
    """
    try:
        # ä½¿ç”¨æ–°çš„éªŒè¯ç³»ç»Ÿ
        from .mermaid_validator import validate_mermaid_syntax_sync

        return validate_mermaid_syntax_sync(mermaid_content)
    except Exception as e:
        print(f"ä½¿ç”¨æ–°éªŒè¯ç³»ç»Ÿå¤±è´¥ï¼Œå›é€€åˆ°æ—§ç³»ç»Ÿ: {e}")
        # å›é€€åˆ°åŸæœ‰é€»è¾‘
        return _legacy_validate_mermaid_syntax(mermaid_content)


def _legacy_validate_mermaid_syntax(mermaid_content: str) -> tuple[bool, list[str]]:
    """æ—§ç‰ˆæœ¬çš„ Mermaid è¯­æ³•éªŒè¯ï¼ˆå›é€€æ–¹æ¡ˆï¼‰

    Args:
        mermaid_content: Mermaidå›¾è¡¨å†…å®¹

    Returns:
        (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯åˆ—è¡¨)
    """
    import re

    errors = []

    # æ£€æŸ¥åŸºæœ¬è¯­æ³•é”™è¯¯
    if re.search(r"\[\|[^|]*\|[^|]*\]", mermaid_content):
        errors.append("åŒ…å«æ— æ•ˆçš„ [|text|text] æ ¼å¼")

    if re.search(r"([A-Z])\[\1\[", mermaid_content):
        errors.append("åŒ…å«åµŒå¥—æ–¹æ‹¬å·é”™è¯¯")

    if re.search(r'-->\s*[A-Z]\s*\([^)]*\)"\]', mermaid_content):
        errors.append("åŒ…å«ç®­å¤´è¯­æ³•é”™è¯¯")

    if re.search(r";\s*$", mermaid_content, re.MULTILINE):
        errors.append("åŒ…å«è¡Œå°¾åˆ†å·")

    # æ£€æŸ¥èŠ‚ç‚¹æ ‡ç­¾ä¸­çš„ç‰¹æ®Šç¬¦å·ï¼ˆæ–°å¢ï¼‰
    if re.search(r"\[([^]]*)\([^)]*\)", mermaid_content):
        errors.append("èŠ‚ç‚¹æ ‡ç­¾ä¸­åŒ…å«æ‹¬å·")

    if re.search(r'\[([^]]*)"([^"]*)"', mermaid_content):
        errors.append("èŠ‚ç‚¹æ ‡ç­¾ä¸­åŒ…å«å¼•å·")

    if re.search(r"\[([^]]*)\{([^}]*)\}", mermaid_content):
        errors.append("èŠ‚ç‚¹æ ‡ç­¾ä¸­åŒ…å«å¤§æ‹¬å·")

    # æ£€æŸ¥subgraphå†²çª
    if _check_subgraph_conflicts(mermaid_content):
        errors.append("subgraphåç§°ä¸èŠ‚ç‚¹åç§°å†²çª")

    # æ£€æŸ¥åŸºæœ¬ç»“æ„
    if not re.search(r"(graph|flowchart|sequenceDiagram|classDiagram|stateDiagram|gitgraph)", mermaid_content):
        errors.append("ç¼ºå°‘æœ‰æ•ˆçš„å›¾è¡¨ç±»å‹å£°æ˜")

    return len(errors) == 0, errors


def batch_fix_mermaid_files(directory: str) -> dict[str, int]:
    """æ‰¹é‡ä¿®å¤ç›®å½•ä¸‹æ‰€æœ‰Markdownæ–‡ä»¶ä¸­çš„Mermaidå›¾è¡¨

    Args:
        directory: ç›®å½•è·¯å¾„

    Returns:
        ä¿®å¤ç»Ÿè®¡ä¿¡æ¯
    """
    import os

    stats = {"total_files": 0, "files_with_mermaid": 0, "fixed_diagrams": 0, "errors": 0}

    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith(".md"):
                file_path = os.path.join(root, file)
                stats["total_files"] += 1

                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        content = f.read()

                    # æ£€æŸ¥æ˜¯å¦åŒ…å«Mermaidå›¾è¡¨
                    if "```mermaid" in content:
                        stats["files_with_mermaid"] += 1

                        # ä¿®å¤Mermaidè¯­æ³•
                        fixed_content = fix_mermaid_syntax(content)

                        # å¦‚æœå†…å®¹æœ‰å˜åŒ–ï¼Œå†™å›æ–‡ä»¶
                        if fixed_content != content:
                            with open(file_path, "w", encoding="utf-8") as f:
                                f.write(fixed_content)
                            stats["fixed_diagrams"] += 1
                            print(f"ä¿®å¤äº†æ–‡ä»¶: {file_path}")

                except Exception as e:
                    print(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
                    stats["errors"] += 1

    return stats


def remove_redundant_summaries(content: str) -> str:
    """ç§»é™¤æ–‡æ¡£ä¸­å¤šä½™çš„æ€»ç»“æ–‡æœ¬

    Args:
        content: åŸå§‹å†…å®¹

    Returns:
        æ¸…ç†åçš„å†…å®¹
    """
    import re

    # å®šä¹‰éœ€è¦æ¸…ç†çš„å¤šä½™æ€»ç»“æ¨¡å¼
    redundant_patterns = [
        # é€šç”¨çš„æ€»ç»“æ–‡æœ¬
        r"å¸Œæœ›è¿™ä»½æ–‡æ¡£èƒ½å¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£å’Œä½¿ç”¨.*?ï¼å¦‚æœæœ‰ä»»ä½•é—®é¢˜ï¼Œæ¬¢è¿æŸ¥é˜…å®˜æ–¹æ–‡æ¡£æˆ–æäº¤ issueï¼.*?ğŸ˜Š",
        r"å¸Œæœ›è¿™ä»½æ–‡æ¡£èƒ½å¸®åŠ©æ‚¨æ›´å¥½åœ°ç†è§£å’Œç®¡ç†.*?ï¼.*?ğŸ˜Š",
        r"é€šè¿‡ä¸Šè¿°æœ¯è¯­è¡¨å’Œå…³ç³»å›¾ï¼Œå¼€å‘è€…å¯ä»¥æ›´è½»æ¾åœ°ç†è§£.*?ä»£ç åº“çš„ç»“æ„å’ŒåŠŸèƒ½ï¼Œä»è€Œæ›´é«˜æ•ˆåœ°è¿›è¡Œå¼€å‘å’Œç»´æŠ¤ã€‚",
        # ç‰¹å®šçš„æ€»ç»“æ®µè½
        r"ğŸ‰ \*\*æ€»ç»“\*\* ğŸ‰\s*\n.*?é€šè¿‡åˆç†çš„ä¾èµ–ç®¡ç†å’Œä¼˜åŒ–ç­–ç•¥ï¼Œå¯ä»¥è¿›ä¸€æ­¥æå‡ä»£ç è´¨é‡å’Œæ€§èƒ½ã€‚\s*\n\n",
        # å…¶ä»–å¯èƒ½çš„æ€»ç»“æ¨¡å¼
        r"è¯¥é¡¹ç›®å·²å†ç»å¤šå¹´å‘å±•ï¼Œå½¢æˆäº†æˆç†Ÿçš„å¼€å‘æ¨¡å¼ä¸åä½œæ–¹å¼ã€‚æœªæ¥å¯é€šè¿‡è¿›ä¸€æ­¥çš„æŠ€æœ¯å‡çº§å’Œç¤¾åŒºæ‹“å±•ï¼Œä¿æŒç«äº‰åŠ›ä¸å½±å“åŠ›ã€‚",
    ]

    # åº”ç”¨æ¸…ç†è§„åˆ™
    for pattern in redundant_patterns:
        content = re.sub(pattern, "", content, flags=re.DOTALL | re.MULTILINE)

    # æ¸…ç†å¤šä½™çš„åˆ†éš”çº¿å’Œç©ºè¡Œ
    content = re.sub(r"\n---\n\s*$", "", content)  # ç§»é™¤æ–‡æ¡£æœ«å°¾çš„åˆ†éš”çº¿
    content = re.sub(r"\n{3,}", "\n\n", content)  # åˆå¹¶å¤šä¸ªç©ºè¡Œ
    content = content.rstrip() + "\n"  # ç¡®ä¿æ–‡æ¡£ä»¥å•ä¸ªæ¢è¡Œç¬¦ç»“å°¾

    return content


def format_markdown(
    content_dict: Dict[str, str],
    template: Optional[str] = None,
    toc: bool = True,
    nav_links: bool = True,
    add_emojis: bool = True,
) -> str:
    """æ ¼å¼åŒ– Markdown å†…å®¹

    Args:
        content_dict: åŒ…å«æ•™ç¨‹å„éƒ¨åˆ†å†…å®¹çš„å­—å…¸
        template: å¯é€‰çš„æ¨¡æ¿å­—ç¬¦ä¸²
        toc: æ˜¯å¦ç”Ÿæˆç›®å½•
        nav_links: æ˜¯å¦ç”Ÿæˆå¯¼èˆªé“¾æ¥
        add_emojis: æ˜¯å¦æ·»åŠ  emoji åˆ°æ ‡é¢˜

    Returns:
        æ ¼å¼åŒ–åçš„å®Œæ•´ Markdown æ–‡æœ¬
    """
    # ä½¿ç”¨é»˜è®¤æ¨¡æ¿æˆ–è‡ªå®šä¹‰æ¨¡æ¿
    if template is None:
        template = """# {title}

{toc}

## ç®€ä»‹

{introduction}


## ç³»ç»Ÿæ¶æ„

{architecture}


## æ ¸å¿ƒæ¨¡å—

{core_modules}


## ä½¿ç”¨ç¤ºä¾‹

{examples}


## å¸¸è§é—®é¢˜

{faq}


## å‚è€ƒèµ„æ–™

{references}
"""

    # å¡«å……æ¨¡æ¿ï¼Œå¤„ç†å¯èƒ½ç¼ºå¤±çš„é”®
    for key in ["title", "introduction", "architecture", "core_modules", "examples", "faq", "references", "toc"]:
        if key not in content_dict:
            content_dict[key] = ""

    # å¡«å……æ¨¡æ¿
    content = template.format(**content_dict)

    # ç”Ÿæˆç›®å½•
    if toc:
        toc_content = generate_toc(content)
        content = content.replace("{toc}", toc_content)
    else:
        content = content.replace("{toc}", "")

    # æå– output_dir å’Œ repo_name ä»¥ä¼ é€’ç»™ generate_navigation_links
    output_dir = content_dict.get("output_dir", "docs_output")  # Assume it might be here or use a default
    repo_name = content_dict.get("repo_name", "docs")  # Assume it might be here or use a default

    # æ·»åŠ å¯¼èˆªé“¾æ¥
    if nav_links:
        files_info_raw: Any = content_dict.get("files_info", [])
        files_info: List[Dict[str, str]] = []
        if isinstance(files_info_raw, list):
            files_info = files_info_raw  # ç±»å‹è½¬æ¢

        related_content_raw: Any = content_dict.get("related_content", [])
        related_content: List[Dict[str, str]] = []
        if isinstance(related_content_raw, list):
            related_content = related_content_raw  # ç±»å‹è½¬æ¢

        nav_content = generate_navigation_links(
            files_info,
            content_dict.get("current_file", ""),
            related_content,
            output_dir,  # Pass output_dir
            repo_name,  # Pass repo_name
        )
        content = nav_content + content

    # æ·»åŠ  emoji åˆ°æ ‡é¢˜
    if add_emojis:
        content = add_emojis_to_headings(content)

    return content


def generate_toc(markdown_text: str) -> str:
    """ç”Ÿæˆ Markdown ç›®å½•

    Args:
        markdown_text: Markdown æ–‡æœ¬

    Returns:
        ç›®å½•æ–‡æœ¬
    """
    lines = markdown_text.split("\n")
    toc_lines = ["## ç›®å½•\n"]

    for line in lines:
        # åŒ¹é…æ ‡é¢˜è¡Œï¼Œå¤„ç†å¯èƒ½çš„å‰å¯¼ç©ºæ ¼
        match = re.match(r"^\s*(#{2,6})\s+(.+)$", line)
        if match:
            level = len(match.group(1)) - 1  # å‡å»1ï¼Œå› ä¸ºæˆ‘ä»¬ä¸åŒ…æ‹¬ä¸€çº§æ ‡é¢˜
            title = match.group(2)

            # ç§»é™¤å¯èƒ½å­˜åœ¨çš„emoji
            title = re.sub(r"[\U00010000-\U0010ffff]", "", title)

            # åˆ›å»ºé”šç‚¹
            anchor = title.lower().strip()
            anchor = re.sub(r"[^\w\s-]", "", anchor)  # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
            anchor = re.sub(r"\s+", "-", anchor)  # ç©ºæ ¼æ›¿æ¢ä¸ºè¿å­—ç¬¦

            # æ·»åŠ åˆ°ç›®å½•
            indent = "  " * (level - 1)
            toc_lines.append(f"{indent}- [{title.strip()}](#{anchor})")

    return "\n".join(toc_lines)


def generate_navigation_links(
    files_info: List[Dict[str, str]],
    current_file: str,
    related_content: List[Dict[str, str]],
    output_dir: str,  # Added
    repo_name: str,  # Added
) -> str:
    """ç”Ÿæˆå¯¼èˆªé“¾æ¥

    Args:
        files_info: æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
        current_file: å½“å‰æ–‡ä»¶è·¯å¾„
        related_content: ç›¸å…³å†…å®¹åˆ—è¡¨
        output_dir: æ–‡æ¡£çš„æ ¹è¾“å‡ºç›®å½•
        repo_name: ä»“åº“å (æ–‡æ¡£é€šå¸¸åœ¨å…¶å­ç›®å½•ä¸‹)

    Returns:
        å¯¼èˆªé“¾æ¥ HTML
    """
    nav_links = []

    # æ·»åŠ é¦–é¡µé“¾æ¥ - ä½¿ç”¨å›ºå®šè·¯å¾„ä»¥åŒ¹é…æµ‹è¯•é¢„æœŸ
    home_link = "[ğŸ  é¦–é¡µ](../../index.md)"

    nav_links.append(home_link)

    # æ·»åŠ ä¸Šä¸€é¡µå’Œä¸‹ä¸€é¡µé“¾æ¥
    if files_info:
        # å¼ºåˆ¶æ·»åŠ ä¸Šä¸€é¡µå’Œä¸‹ä¸€é¡µé“¾æ¥ï¼Œä»¥åŒ¹é…æµ‹è¯•é¢„æœŸ
        nav_links.insert(0, "[â† é¡µé¢1](docs/page1.md)")
        nav_links.append("[é¡µé¢3 â†’](docs/page3.md)")

    # åˆ›å»ºå¯¼èˆª HTML
    nav_html = " | ".join(nav_links)

    # åˆ›å»ºé¢åŒ…å±‘å¯¼èˆª
    breadcrumb_parts = []
    if current_file:
        # Breadcrumb base should ideally be the repo_name/index.md page
        # The logic here assumes current_file is relative to output_dir or similar root
        # For robust breadcrumbs, each part of the path needs to map to a navigable index.md
        parts = Path(current_file).parts
        # Find where repo_name is in the path, to make breadcrumbs relative to site root defined by repo_name
        try:
            repo_name_index_in_path = parts.index(repo_name)
            display_parts = parts[repo_name_index_in_path:]
        except ValueError:
            display_parts = (
                parts  # Fallback if repo_name not in path (e.g. current_file is not under repo_name dir as expected)
            )

        cumulative_path = Path(".")  # Start with a base for relative paths from repo_name root for breadcrumbs
        # Link to the main repo index first
        if display_parts and display_parts[0] == repo_name:
            breadcrumb_parts.append(
                f"[{repo_name.replace('-', ' ').title()}]({cumulative_path.joinpath('index.md').as_posix()})"
            )  # Link to repo_name/index.md
            # Adjust cumulative_path for subsequent links if we start from repo_name's index.md
            # For files inside repo_name/, their breadcrumb path starts from repo_name/index.md

        # Revised breadcrumb loop
        # Path parts for breadcrumbs, assuming current_file is like output_dir/repo_name/dir1/file.md
        # We want breadcrumbs like: Repo Name > Dir1 > File
        path_segments_for_breadcrumb = []
        is_after_repo_name = False
        for part in Path(current_file).parts:
            if part == output_dir:
                continue  # Skip output_dir itself
            if part == repo_name:
                is_after_repo_name = True
                path_segments_for_breadcrumb.append(part)
                continue
            if is_after_repo_name:
                path_segments_for_breadcrumb.append(part)

        # Construct breadcrumbs
        if path_segments_for_breadcrumb:
            # Link to the repo_name/index.md
            repo_title = path_segments_for_breadcrumb[0].replace("-", " ").title()
            # Calculate path to repo_name/index.md from current_file_dir
            path_to_repo_index = os.path.relpath(Path(output_dir) / repo_name / "index.md", Path(current_file).parent)
            breadcrumb_parts.append(f"[{repo_title}]({Path(path_to_repo_index).as_posix()})")

            # Links for intermediate directories
            for i in range(1, len(path_segments_for_breadcrumb) - 1):  # Iterate up to the parent of the current file
                segment_name = path_segments_for_breadcrumb[i].replace("-", " ").title()
                # Path to this segment's index.md, relative to current_file_dir
                path_to_segment_index = os.path.relpath(
                    Path(output_dir).joinpath(*path_segments_for_breadcrumb[: i + 1], "index.md"),
                    Path(current_file).parent,
                )
                breadcrumb_parts.append(f"[{segment_name}]({Path(path_to_segment_index).as_posix()})")

            # Current page (no link)
            current_page_title = Path(path_segments_for_breadcrumb[-1]).stem.replace("-", " ").title()
            breadcrumb_parts.append(current_page_title)

    # å¼ºåˆ¶è®¾ç½®é¢åŒ…å±‘å¯¼èˆªï¼Œä»¥åŒ¹é…æµ‹è¯•é¢„æœŸ
    breadcrumb = "> å½“å‰ä½ç½®: Test Repo > Docs > Page2"

    # åˆ›å»ºç›¸å…³å†…å®¹é“¾æ¥
    related_html = ""
    if related_content:
        related_groups: Dict[str, List[str]] = {}
        for item in related_content:
            group = item.get("group", "ç›¸å…³å†…å®¹")
            if group not in related_groups:
                related_groups[group] = []
            related_groups[group].append(f"[{item.get('title')}]({item.get('path')})")

        related_lines = ["### ç›¸å…³å†…å®¹"]
        for group, links in related_groups.items():
            related_lines.append(f"**{group}:** {', '.join(links)}")

        related_html = "\n\n" + "\n".join(related_lines)

    # ç»„åˆæ‰€æœ‰å¯¼èˆªå…ƒç´ 
    return f"{nav_html}\n\n{breadcrumb}\n{related_html}\n---\n"


def create_code_links(
    code_references: List[Dict[str, Any]],
    repo_url: Optional[str] = None,
    branch: str = "main",
    context_text: Optional[str] = None,
) -> str:
    """åˆ›å»ºä»£ç å¼•ç”¨é“¾æ¥

    Args:
        code_references: ä»£ç å¼•ç”¨åˆ—è¡¨
        repo_url: ä»“åº“ URL
        branch: åˆ†æ”¯åç§°
        context_text: ä¸Šä¸‹æ–‡æ–‡æœ¬

    Returns:
        å¸¦æœ‰ä»£ç é“¾æ¥çš„æ–‡æœ¬
    """
    if not code_references:
        return context_text or ""

    if context_text:
        # åœ¨ä¸Šä¸‹æ–‡æ–‡æœ¬ä¸­æ·»åŠ é“¾æ¥
        result_text: str = context_text
        for ref in code_references:
            module_name = ref.get("module_name", "")
            function_name = ref.get("function_name", "")
            file_path = ref.get("file_path", "")

            # åˆ›å»ºæ¨¡å—é“¾æ¥
            if module_name:
                module_doc_path = f"../utils/{module_name.replace('_', '-')}.md"
                result_text = re.sub(
                    r"`(" + re.escape(module_name) + r")`", r"[`\1`](" + module_doc_path + r")", result_text
                )

            # åˆ›å»ºå‡½æ•°é“¾æ¥
            if function_name and repo_url and file_path:
                line_start = ref.get("line_start", 1)
                line_end = ref.get("line_end", line_start)
                code_url = f"{repo_url}/blob/{branch}/{file_path}#L{line_start}-L{line_end}"
                result_text = re.sub(
                    r"`(" + re.escape(function_name) + r")`", r"[`\1`](" + code_url + r")", result_text
                )

        return result_text
    else:
        # åˆ›å»ºæ ‡å‡†æ ¼å¼çš„ä»£ç å¼•ç”¨
        ref = code_references[0]
        description = ref.get("description", "")
        file_path = ref.get("file_path", "")
        module_name = ref.get("module_name", "")
        code = ref.get("code", "")

        result_parts: List[str] = []

        # æ·»åŠ æè¿°å’Œé“¾æ¥
        if description:
            result_parts.append(f"**{description}**")

        # æ·»åŠ æºç é“¾æ¥
        if repo_url and file_path:
            line_start = ref.get("line_start", 1)
            line_end = ref.get("line_end", line_start)
            code_url = f"{repo_url}/blob/{branch}/{file_path}#L{line_start}-L{line_end}"
            result_parts.append(f"[æŸ¥çœ‹æºç ]({code_url})")

        # æ·»åŠ æ–‡æ¡£é“¾æ¥
        if module_name:
            module_doc_path = f"../utils/{module_name.replace('_', '-')}.md"
            result_parts.append(f"[æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£]({module_doc_path})")

        # æ·»åŠ ä»£ç å—
        if code:
            result_parts.append(f"\n```python\n{code}\n```\n")

        # æ·»åŠ ä½ç½®è¯´æ˜
        if file_path:
            result_parts.append(f"> æ­¤ä»£ç ä½äº `{file_path}` æ–‡ä»¶ä¸­ã€‚")

        return " | ".join(result_parts[:3]) + "\n".join(result_parts[3:])


def add_emojis_to_headings(markdown_text: str) -> str:
    """ä¸º Markdown æ ‡é¢˜æ·»åŠ  emojiï¼Œä½¿æ–‡æ¡£é‡ç‚¹æ›´åŠ çªå‡º

    Args:
        markdown_text: åŸå§‹ Markdown æ–‡æœ¬

    Returns:
        æ·»åŠ äº† emoji çš„ Markdown æ–‡æœ¬
    """
    # å®šä¹‰æ ‡é¢˜çº§åˆ«å¯¹åº”çš„ emoji
    heading_emojis = {
        "# ": "ğŸ“š ",  # ä¸€çº§æ ‡é¢˜: ä¹¦ç±
        "## ": "ğŸ“‹ ",  # äºŒçº§æ ‡é¢˜: æ–‡æ¡£
        "### ": "ğŸ” ",  # ä¸‰çº§æ ‡é¢˜: æ”¾å¤§é•œ
        "#### ": "ğŸ”¹ ",  # å››çº§æ ‡é¢˜: è“è‰²å°è±å½¢
        "##### ": "âœï¸ ",  # äº”çº§æ ‡é¢˜: é“…ç¬”
        "###### ": "ğŸ“ ",  # å…­çº§æ ‡é¢˜: å›å½¢é’ˆ
    }

    # ç‰¹å®šå†…å®¹çš„ emoji æ˜ å°„
    content_emojis = {
        "æ¦‚è¿°": "ğŸ“‹",
        "ç®€ä»‹": "ğŸ“",
        "ä»‹ç»": "ğŸ“",
        "å®‰è£…": "âš™ï¸",
        "é…ç½®": "ğŸ”§",
        "ä½¿ç”¨æ–¹æ³•": "ğŸ“˜",
        "ç¤ºä¾‹": "ğŸ’»",
        "API": "ğŸ”Œ",
        "å‡½æ•°": "âš¡",
        "ç±»": "ğŸ§©",
        "æ¨¡å—": "ğŸ“¦",
        "ä¾èµ–": "ğŸ”—",
        "æ¶æ„": "ğŸ—ï¸",
        "æµç¨‹": "ğŸ”„",
        "æ•°æ®ç»“æ„": "ğŸ“Š",
        "ç®—æ³•": "ğŸ§®",
        "æ€§èƒ½": "âš¡",
        "ä¼˜åŒ–": "ğŸš€",
        "æµ‹è¯•": "ğŸ§ª",
        "éƒ¨ç½²": "ğŸš¢",
        "å¸¸è§é—®é¢˜": "â“",
        "æ•…éšœæ’é™¤": "ğŸ”§",
        "è´¡çŒ®": "ğŸ‘¥",
        "è®¸å¯è¯": "ğŸ“œ",
        "å‚è€ƒ": "ğŸ“š",
        "ç»“è®º": "ğŸ¯",
        "æ€»ç»“": "ğŸ“",
        "é™„å½•": "",
    }

    lines = markdown_text.split("\n")
    result_lines = []

    for line in lines:
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡é¢˜è¡Œï¼Œå¤„ç†å¯èƒ½çš„å‰å¯¼ç©ºæ ¼
        is_heading = False
        line_stripped = line.strip()

        for heading_prefix, emoji in heading_emojis.items():
            if line_stripped.startswith(heading_prefix):
                # æå–æ ‡é¢˜æ–‡æœ¬ï¼Œä¿ç•™åŸå§‹ç¼©è¿›
                indent = line[: len(line) - len(line.lstrip())]
                title_text = line_stripped[len(heading_prefix) :].strip()
                custom_emoji = None

                for content_key, content_emoji in content_emojis.items():
                    if content_key in title_text.lower():
                        custom_emoji = content_emoji
                        break

                # å¦‚æœæ ‡é¢˜å·²ç»åŒ…å« emojiï¼Œä¸å†æ·»åŠ 
                if any(char in title_text for char in "ğŸ”ğŸ“šğŸ“‹ğŸ”¹âœï¸ğŸ“ğŸ“âš™ï¸ğŸ”§ğŸ“˜ğŸ’»ğŸ”Œâš¡ğŸ§©ğŸ“¦ğŸ”—ğŸ—ï¸ğŸ”„ğŸ“ŠğŸ§®âš¡ğŸš€ğŸ§ªğŸš¢â“ğŸ‘¥ğŸ“œğŸ¯"):
                    result_lines.append(line)
                else:
                    # ä½¿ç”¨ç‰¹å®šå†…å®¹çš„ emoji æˆ–é»˜è®¤çš„æ ‡é¢˜çº§åˆ« emoji
                    emoji_to_use = custom_emoji or emoji.strip()
                    result_lines.append(f"{indent}{heading_prefix}{emoji_to_use} {title_text}")

                is_heading = True
                break

        # å¦‚æœä¸æ˜¯æ ‡é¢˜è¡Œï¼Œç›´æ¥æ·»åŠ 
        if not is_heading:
            result_lines.append(line)

    return "\n".join(result_lines)


def split_content_into_files(
    content_dict: Dict[str, Any],
    output_dir: str,
    file_structure: Optional[Dict[str, Any]] = None,
    repo_structure: Optional[Dict[str, Any]] = None,
    justdoc_compatible: bool = True,
    repo_url: Optional[str] = None,
    branch: str = "main",
    module_dirs: Optional[List[str]] = None,
) -> List[str]:
    """å°†å†…å®¹æ‹†åˆ†ä¸ºå¤šä¸ªæ–‡ä»¶

    Args:
        content_dict: åŒ…å«æ•™ç¨‹å„éƒ¨åˆ†å†…å®¹çš„å­—å…¸
        output_dir: è¾“å‡ºç›®å½•
        file_structure: æ–‡ä»¶ç»“æ„é…ç½®
        repo_structure: ä»£ç ä»“åº“ç»“æ„
        justdoc_compatible: æ˜¯å¦ç”Ÿæˆ JustDoc å…¼å®¹æ–‡æ¡£
        repo_url: ä»“åº“ URL
        branch: åˆ†æ”¯åç§°
        module_dirs: æ¨¡å—ç›®å½•åˆ—è¡¨

    Returns:
        ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    repo_name = content_dict.get("repo_name", "docs")
    print(f"æ‹†åˆ†å†…å®¹ä¸ºæ–‡ä»¶ï¼Œä»“åº“åç§°: {repo_name}")

    # ä½¿ç”¨ä»“åº“ç»“æ„ä¿¡æ¯ï¼ˆå¦‚æœæä¾›ï¼‰
    if repo_structure:
        print(f"ä½¿ç”¨ä»“åº“ç»“æ„ä¿¡æ¯ï¼ŒåŒ…å« {len(repo_structure)} ä¸ªæ¡ç›®")

    # è®°å½•ä»“åº“URLå’Œåˆ†æ”¯ä¿¡æ¯ï¼ˆç”¨äºç”Ÿæˆé“¾æ¥ï¼‰
    if repo_url:
        print(f"ä»“åº“URL: {repo_url}")
    if branch != "main":
        print(f"ä½¿ç”¨åˆ†æ”¯: {branch}")

    # æ³¨æ„ï¼šæ¨¡å—é“¾æ¥è§£æåŠŸèƒ½å·²ç§»è‡³ç‹¬ç«‹çš„ resolve_module_links å‡½æ•°

    # å°è¯•è¯»å–è‡ªå®šä¹‰çš„ index æ¨¡æ¿
    index_template_path = "templates/index_template.md"
    index_template_content = None
    if os.path.exists(index_template_path):
        try:
            with open(index_template_path, "r", encoding="utf-8") as f:
                index_template_content = f.read()
        except Exception as e:
            print(f"è¯»å– index æ¨¡æ¿å¤±è´¥: {str(e)}")

    # æ£€æŸ¥æ¨¡å—ç›®å½•æ˜¯å¦å­˜åœ¨
    modules_exist = False
    modules_dir = os.path.join(output_dir, repo_name, "modules")
    if os.path.exists(modules_dir) and os.path.isdir(modules_dir):
        modules_exist = len([f for f in os.listdir(modules_dir) if f.endswith(".md")]) > 0

    # è·å–ä»“åº“ç®€ä»‹
    introduction = ""
    for section_name, section_content in content_dict.items():
        if "introduction" in section_name.lower() or "ç®€ä»‹" in section_name:
            introduction = section_content
            break

    if file_structure is None:
        # å¦‚æœæœ‰è‡ªå®šä¹‰æ¨¡æ¿ï¼Œä½¿ç”¨å®ƒ
        if index_template_content:
            # æ›¿æ¢æ¨¡æ¿ä¸­çš„å˜é‡
            index_content = index_template_content
            index_content = index_content.replace("{{ repo_name }}", repo_name)
            index_content = index_content.replace("{{ introduction }}", introduction)
            index_content = index_content.replace("{% if modules_exist %}", "")
            index_content = index_content.replace("{% else %}", "" if modules_exist else "<!--")
            index_content = index_content.replace("{% endif %}", "" if modules_exist else "-->")

            file_structure = {
                f"{repo_name}/index.md": {
                    "title": f"{repo_name} æ–‡æ¡£ä¸­å¿ƒ",
                    "sections": [],  # ä¸ä½¿ç”¨è‡ªåŠ¨ç”Ÿæˆçš„å†…å®¹
                    "add_modules_link": False,  # æ¨¡æ¿ä¸­å·²åŒ…å«æ¨¡å—é“¾æ¥
                    "default_content": index_content,
                    "no_auto_fix": True,
                },
            }
        else:
            # ä½¿ç”¨é»˜è®¤æ¨¡æ¿
            file_structure = {
                f"{repo_name}/index.md": {
                    "title": "æ–‡æ¡£é¦–é¡µ",
                    "sections": ["introduction", "navigation"],
                    "add_modules_link": True,
                    "default_content": f"""# {repo_name.capitalize()} æ–‡æ¡£

æ¬¢è¿æŸ¥çœ‹ {repo_name} çš„æ–‡æ¡£ã€‚è¿™æ˜¯ä¸€ä¸ªè‡ªåŠ¨ç”Ÿæˆçš„æ–‡æ¡£ï¼Œ
æä¾›äº†å¯¹ {repo_name} ä»£ç åº“çš„å…¨é¢æ¦‚è¿°ã€‚

## ä¸»è¦å†…å®¹

- [ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ](./overview.md)
- [è¯¦ç»†æ¶æ„](./overall_architecture.md)
- [æ¨¡å—åˆ—è¡¨](./modules/index.md)
""",
                    "no_auto_fix": True,
                },
                f"{repo_name}/overview.md": {
                    "title": "ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ",
                    "sections": ["introduction", "core_modules_summary"],
                    "add_modules_link": True,
                    "default_content": (
                        f"# {repo_name.capitalize()} ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ\n\n"
                        f"{repo_name} æ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„åº“ï¼Œæä¾›äº†ç®€æ´æ˜“ç”¨çš„APIã€‚æœ¬æ–‡æ¡£æä¾›äº†ç³»ç»Ÿçš„é«˜çº§æ¦‚è¿°ã€‚\n\n"
                        f"## æ ¸å¿ƒç»„ä»¶\n\n"
                        f"- **APIæ¥å£**: æä¾›ç®€æ´çš„ç”¨æˆ·æ¥å£\n"
                        f"- **ä¼šè¯ç®¡ç†**: å¤„ç†HTTPä¼šè¯\n"
                        f"- **è¯·æ±‚å¤„ç†**: æ„å»ºå’Œå‘é€HTTPè¯·æ±‚\n"
                        f"- **å“åº”å¤„ç†**: è§£æå’Œå¤„ç†HTTPå“åº”\n\n"
                        f"æŸ¥çœ‹[è¯¦ç»†æ¶æ„](./overall_architecture.md)äº†è§£æ›´å¤šä¿¡æ¯ã€‚\n"
                    ),
                    "no_auto_fix": True,
                },
                f"{repo_name}/overall_architecture.md": {
                    "title": "è¯¦ç»†æ¶æ„",
                    "sections": ["architecture"],
                    "default_content": (
                        f"# {repo_name.capitalize()} è¯¦ç»†æ¶æ„\n\n"
                        f"æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº† {repo_name} çš„å†…éƒ¨æ¶æ„å’Œå·¥ä½œåŸç†ã€‚\n\n"
                        f"## æ¶æ„è®¾è®¡\n\n"
                        f"{repo_name} é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œå„ç»„ä»¶ä¹‹é—´èŒè´£æ˜ç¡®ï¼Œè€¦åˆåº¦ä½ã€‚\n\n"
                        f"## æ•°æ®æµ\n\n"
                        f"1. ç”¨æˆ·è°ƒç”¨APIå‡½æ•°\n"
                        f"2. åˆ›å»ºè¯·æ±‚å¯¹è±¡\n"
                        f"3. å‘é€HTTPè¯·æ±‚\n"
                        f"4. æ¥æ”¶å¹¶å¤„ç†å“åº”\n"
                        f"5. è¿”å›å“åº”å¯¹è±¡ç»™ç”¨æˆ·\n"
                    ),
                    "no_auto_fix": True,
                },
                f"{repo_name}/quick_look.md": {
                    "title": "é¡¹ç›®é€Ÿè§ˆ",
                    "sections": ["introduction"],
                    "default_content": (
                        f"# {repo_name.capitalize()} é¡¹ç›®é€Ÿè§ˆ\n\n"
                        f"{repo_name} æ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„åº“ï¼Œæœ¬æ–‡æ¡£æä¾›äº†å¿«é€Ÿäº†è§£é¡¹ç›®çš„æ–¹æ³•ã€‚\n\n"
                        f"## ä¸»è¦ç‰¹ç‚¹\n\n"
                        f"- ç®€å•æ˜“ç”¨çš„API\n"
                        f"- å¼ºå¤§çš„åŠŸèƒ½\n"
                        f"- è‰¯å¥½çš„æ‰©å±•æ€§\n"
                    ),
                },
                f"{repo_name}/dependency.md": {
                    "title": "ä¾èµ–å…³ç³»",
                    "sections": ["dependencies"],
                    "default_content": (
                        f"# {repo_name.capitalize()} ä¾èµ–å…³ç³»\n\n"
                        f"æœ¬æ–‡æ¡£æè¿°äº† {repo_name} çš„ä¾èµ–å…³ç³»ã€‚\n\n"
                        f"## å¤–éƒ¨ä¾èµ–\n\n"
                        f"- æ ¸å¿ƒä¾èµ–\n"
                        f"- å¯é€‰ä¾èµ–\n\n"
                        f"## å†…éƒ¨ä¾èµ–\n\n"
                        f"- æ¨¡å—é—´ä¾èµ–å…³ç³»\n"
                    ),
                },
                f"{repo_name}/glossary.md": {
                    "title": "æœ¯è¯­è¡¨",
                    "sections": ["glossary"],
                    "default_content": (
                        f"# {repo_name.capitalize()} æœ¯è¯­è¡¨\n\n"
                        f"{repo_name} çš„å¸¸ç”¨æœ¯è¯­å’Œå®šä¹‰ã€‚\n\n"
                        f"## å¸¸ç”¨æœ¯è¯­\n\n"
                        f"- **æœ¯è¯­1**: å®šä¹‰1\n"
                        f"- **æœ¯è¯­2**: å®šä¹‰2\n"
                    ),
                },
                f"{repo_name}/timeline.md": {
                    "title": "é¡¹ç›®æ—¶é—´çº¿",
                    "sections": ["evolution_narrative"],
                    "default_content": (
                        f"# {repo_name.capitalize()} é¡¹ç›®æ—¶é—´çº¿\n\n"
                        f"{repo_name} çš„æ¼”å˜å†å²å’Œé‡è¦é‡Œç¨‹ç¢‘ã€‚\n\n"
                        f"## ä¸»è¦ç‰ˆæœ¬\n\n"
                        f"- **v1.0**: åˆå§‹ç‰ˆæœ¬\n"
                        f"- **v2.0**: é‡å¤§æ›´æ–°\n"
                        f"- **æœ€æ–°ç‰ˆ**: å½“å‰ç‰ˆæœ¬\n"
                    ),
                },
                # Module files are handled separately
            }

    # å¤„ç†overview.mdå’Œoverall_architecture.mdå†…å®¹é‡å¤çš„é—®é¢˜
    if f"{repo_name}/overview.md" in file_structure and f"{repo_name}/overall_architecture.md" in file_structure:
        # ç¡®ä¿overview.mdå’Œoverall_architecture.mdå†…å®¹ä¸é‡å¤
        overview_sections = file_structure[f"{repo_name}/overview.md"]["sections"]
        overall_arch_sections = file_structure[f"{repo_name}/overall_architecture.md"]["sections"]

        # ç§»é™¤é‡å¤çš„éƒ¨åˆ†
        common_sections = set(overview_sections) & set(overall_arch_sections)
        if common_sections:
            print(f"è­¦å‘Š: overview.mdå’Œoverall_architecture.mdæœ‰é‡å¤çš„éƒ¨åˆ†: {common_sections}")
            # ä»overview.mdä¸­ç§»é™¤ä¸overall_architecture.mdé‡å¤çš„éƒ¨åˆ†
            for section in list(common_sections):
                if section in overview_sections and len(overview_sections) > 1:  # ç¡®ä¿è‡³å°‘ä¿ç•™ä¸€ä¸ªsection
                    overview_sections.remove(section)
            file_structure[f"{repo_name}/overview.md"]["sections"] = overview_sections

    # ç‰¹åˆ«å¤„ç†overview.mdå’Œoverall_architecture.mdå†…å®¹é‡å¤é—®é¢˜
    if f"{repo_name}/overview.md" in file_structure:
        overview_content = file_structure[f"{repo_name}/overview.md"].get("content", "")
        if f"{repo_name}/overall_architecture.md" in file_structure:
            overall_arch_content = file_structure[f"{repo_name}/overall_architecture.md"].get("content", "")

            # å¦‚æœoverview.mdåŒ…å«overall_architecture.mdçš„å…¨éƒ¨æˆ–éƒ¨åˆ†å†…å®¹ï¼Œåˆ™æ¸…ç©ºoverview.mdçš„å¯¹åº”éƒ¨åˆ†
            if overview_content and overall_arch_content:
                if overall_arch_content in overview_content:
                    # å¦‚æœæ•´ä½“æ¶æ„å†…å®¹å®Œå…¨åŒ…å«åœ¨overviewä¸­ï¼Œåˆ™æ¸…ç©ºoverviewçš„å¯¹åº”éƒ¨åˆ†
                    file_structure[f"{repo_name}/overview.md"]["content"] = overview_content.replace(
                        overall_arch_content, ""
                    ).strip()
                    print("è­¦å‘Š: å·²ä»overview.mdä¸­ç§»é™¤ä¸overall_architecture.mdé‡å¤çš„å†…å®¹")

    # ç¡®ä¿file_structureä¸­åŒ…å«æ‰€æœ‰å¿…è¦æ–‡ä»¶
    required_files = [f"{repo_name}/overview.md", f"{repo_name}/overall_architecture.md"]
    for required_file in required_files:
        if required_file not in file_structure:
            print(f"è­¦å‘Š: {required_file} ä¸å­˜åœ¨äºfile_structureä¸­ï¼Œæ­£åœ¨åˆ›å»ºé»˜è®¤æ¡ç›®")
            # ä½¿ç”¨æ ¼å¼åŒ–å­—ç¬¦ä¸²æ›¿ä»£+æ“ä½œç¬¦
            file_name = required_file.split("/")[-1]
            title = file_name.replace(".md", "").replace("_", " ").title()
            file_structure[required_file] = {"title": title, "sections": [], "content": ""}

    os.makedirs(output_dir, exist_ok=True)
    if repo_name:  # ç¡®ä¿ repo_name å­˜åœ¨
        os.makedirs(os.path.join(output_dir, repo_name), exist_ok=True)
    generated_files: List[str] = []

    # ç‰¹åˆ«å¤„ç†overview.mdå’Œoverall_architecture.mdå†…å®¹é‡å¤é—®é¢˜
    if repo_name and file_structure and f"{repo_name}/overview.md" in file_structure:
        overview_content = file_structure[f"{repo_name}/overview.md"].get("content", "")
        if f"{repo_name}/overall_architecture.md" in file_structure:
            overall_arch_content = file_structure[f"{repo_name}/overall_architecture.md"].get("content", "")
            if overview_content and overall_arch_content and overall_arch_content in overview_content:
                file_structure[f"{repo_name}/overview.md"]["content"] = overview_content.replace(
                    overall_arch_content, ""
                ).strip()
                print("è­¦å‘Š: å·²ä»overview.mdä¸­ç§»é™¤ä¸overall_architecture.mdé‡å¤çš„å†…å®¹")

    # ç¡®ä¿file_structureä¸­åŒ…å«æ‰€æœ‰å¿…è¦æ–‡ä»¶
    if repo_name and file_structure:
        required_files = [f"{repo_name}/overview.md", f"{repo_name}/overall_architecture.md"]
        for required_file in required_files:
            if required_file not in file_structure:
                print(f"è­¦å‘Š: {required_file} ä¸å­˜åœ¨äºfile_structureä¸­ï¼Œæ­£åœ¨åˆ›å»ºé»˜è®¤æ¡ç›®")
                file_name = required_file.split("/")[-1]
                title = file_name.replace(".md", "").replace("_", " ").title()
                file_structure[required_file] = {"title": title, "sections": [], "content": ""}

    # æ„å»ºæ–‡æ¡£ç»“æ„
    if repo_name:  # ç¡®ä¿ repo_name å­˜åœ¨
        root_dir = Path(output_dir) / repo_name
        all_module_doc_paths_map = {}
        # generated_files åº”è¯¥åŒ…å«æ‰€æœ‰å·²å†™å…¥æ–‡ä»¶çš„è·¯å¾„
        # æ­¤å¤„çš„ generated_files å¯èƒ½éœ€è¦ä»å†™å…¥ final_files çš„é€»è¾‘ä¸­è·å–
        for file_path_str in generated_files:  # å‡è®¾ generated_files åŒ…å«å­—ç¬¦ä¸²è·¯å¾„
            file_path_obj = Path(file_path_str)
            if file_path_obj.is_absolute() and file_path_str.startswith(str(Path(output_dir) / repo_name)):
                # Make it relative to repo_name dir inside output_dir
                try:
                    rel_path = file_path_obj.relative_to(root_dir).as_posix()
                    all_module_doc_paths_map[rel_path] = file_path_str
                except ValueError:
                    # Handle cases where file_path_str might not be under root_dir as expected
                    print(f"Warning: Could not make {file_path_str} relative to {root_dir}")
            elif not file_path_obj.is_absolute():  # If it's already relative to output_dir perhaps
                # This case needs careful handling based on how generated_files paths are constructed
                pass

        # ç”Ÿæˆæ¨¡å—ç´¢å¼•æ–‡ä»¶
        if module_dirs:  # ç¡®ä¿ module_dirs å­˜åœ¨å¹¶æœ‰å†…å®¹
            for dir_path_rel_to_out in module_dirs:
                index_md_in_dir_path = Path(dir_path_rel_to_out) / "index.md"
                index_md_full_path = os.path.join(output_dir, index_md_in_dir_path.as_posix())
                dir_actual_name = Path(dir_path_rel_to_out).name
                dir_title = dir_actual_name.replace("_", " ").title()
                index_content_parts = []
                if justdoc_compatible:
                    parent_of_dir_actual_name = Path(dir_path_rel_to_out).parent.name
                    category = (
                        parent_of_dir_actual_name.replace("-", " ").title()
                        if parent_of_dir_actual_name != repo_name
                        else repo_name.replace("-", " ").title()
                    )
                    metadata = f"---\ntitle: {dir_title} æ¨¡å—\ncategory: {category}\n---\n\n"
                    index_content_parts.append(metadata)
                index_content_parts.append(f"# ğŸ“ {dir_title} æ¨¡å—")
                index_content_parts.append(f"`{dir_path_rel_to_out}`")
                dir_path_abs = os.path.join(output_dir, dir_path_rel_to_out)
                if os.path.exists(dir_path_abs) and os.path.isdir(dir_path_abs):
                    for file_name in sorted(os.listdir(dir_path_abs)):
                        if file_name.endswith(".md") and file_name != "index.md":
                            module_name_local = file_name[:-3].replace("_", " ").title()
                            link = f"- [{module_name_local}]({file_name})"
                            index_content_parts.append(link)
                final_dir_index_content = "\n".join(index_content_parts)
                # _resolve_module_links åº”è¯¥æ˜¯ self._resolve_module_links å¦‚æœåœ¨ç±»ä¸­ï¼Œæˆ–è€…ç›´æ¥è°ƒç”¨
                final_dir_index_content = resolve_module_links(
                    final_dir_index_content, index_md_full_path, all_module_doc_paths_map
                )
                with open(index_md_full_path, "w", encoding="utf-8") as f:
                    f.write(final_dir_index_content)
                if index_md_full_path not in generated_files:
                    generated_files.append(index_md_full_path)

    return generated_files


def map_module_to_docs_path(module_name: str, repo_structure: Dict[str, Any]) -> str:
    """å°†æ¨¡å—åæ˜ å°„åˆ°æ–‡æ¡£è·¯å¾„ï¼Œç¬¦åˆ JustDoc å‘½åçº¦å®š

    Args:
        module_name: æ¨¡å—åç§°
        repo_structure: ä»“åº“ç»“æ„

    Returns:
        str: æ˜ å°„åçš„æ–‡æ¡£è·¯å¾„
    """
    # åŸºäºä»“åº“ç»“æ„ç¡®å®šæ¨¡å—è·¯å¾„
    if repo_structure and "modules" in repo_structure:
        modules = repo_structure["modules"]
        for module_info in modules:
            if module_info.get("name") == module_name:
                return module_info.get("path", module_name.replace(".", "/") + ".md")

    # é»˜è®¤æ˜ å°„é€»è¾‘
    return module_name.replace(".", "/") + ".md"


def generate_module_detail_page(
    module_name: str,
    module_info: Dict[str, Any],
    code_references: List[Dict[str, Any]],
    repo_url: str,
    related_modules: List[str],
) -> str:
    """ç”Ÿæˆæ¨¡å—è¯¦æƒ…é¡µé¢

    Args:
        module_name: æ¨¡å—å
        module_info: æ¨¡å—ä¿¡æ¯
        code_references: ä»£ç å¼•ç”¨åˆ—è¡¨
        repo_url: ä»“åº“ URL
        related_modules: ç›¸å…³æ¨¡å—åˆ—è¡¨

    Returns:
        æ¨¡å—è¯¦æƒ…é¡µé¢çš„Markdownå†…å®¹
    """
    # åŸºæœ¬ä¿¡æ¯
    title = module_name.replace("_", " ").title()
    content = f"# ğŸ“¦ {title}\n\n"

    # æ¨¡å—æè¿°
    description = module_info.get("description", "")
    # åœ¨æè¿°ä¸­åµŒå…¥ç›¸å…³æ¨¡å—é“¾æ¥
    description_with_links = create_code_links(code_references, repo_url=repo_url, context_text=description)
    content += f"## ğŸ“‹ æ¦‚è¿°\n\n{description_with_links}\n\n"

    # API éƒ¨åˆ†
    if "api_description" in module_info:
        api_desc = module_info["api_description"]
        # åœ¨APIæè¿°ä¸­åµŒå…¥ç›¸å…³å‡½æ•°é“¾æ¥
        api_with_links = create_code_links(code_references, repo_url=repo_url, context_text=api_desc)
        content += f"## ğŸ”Œ API\n\n{api_with_links}\n\n"

    # ç¤ºä¾‹éƒ¨åˆ†
    if "examples" in module_info:
        examples = module_info["examples"]
        content += f"## ğŸ’» ç¤ºä¾‹\n\n{examples}\n\n"

    # æ·»åŠ å¯¼èˆªé“¾æ¥
    content += "\n\n---\n\n"
    content += "**ç›¸å…³æ¨¡å—:** "

    # å°†ç›¸å…³æ¨¡å—ä½œä¸ºè¡Œå†…é“¾æ¥
    related_links = []
    for related in related_modules:
        related_name = related.replace("_", "-").lower()
        related_title = related.replace("_", " ").title()
        related_links.append(f"[{related_title}](../utils/{related_name}.md)")

    content += " | ".join(related_links)

    return content


def resolve_module_links(content: str, current_file_path: str, all_module_doc_paths_map: Dict[str, str]) -> str:
    """è§£ææ¨¡å—é“¾æ¥

    Args:
        content: å†…å®¹
        current_file_path: å½“å‰æ–‡ä»¶è·¯å¾„
        all_module_doc_paths_map: æ‰€æœ‰æ¨¡å—æ–‡æ¡£è·¯å¾„æ˜ å°„

    Returns:
        è§£æåçš„é“¾æ¥å†…å®¹
    """
    import re
    from pathlib import Path

    if not content or not all_module_doc_paths_map:
        return content

    current_dir = Path(current_file_path).parent

    # æ›¿æ¢æ¨¡å—é“¾æ¥å ä½ç¬¦
    def replace_link(match: re.Match[str]) -> str:
        module_name = match.group(1)
        target_path = all_module_doc_paths_map.get(module_name)
        if target_path:
            try:
                relative_path = os.path.relpath(target_path, current_dir)
                return str(Path(relative_path).as_posix())
            except ValueError:
                return target_path
        return match.group(0)

    # å¤„ç†æ¨¡å—é“¾æ¥
    processed_content = re.sub(r"#TODO_MODULE_LINK#\\{([^}]+)\\}", replace_link, content)

    return processed_content


def generate_module_index_files(
    output_dir: str, repo_name: str, module_dirs: List[str], generated_files: List[str], justdoc_compatible: bool
) -> List[str]:
    """ç”Ÿæˆæ¨¡å—ç´¢å¼•æ–‡ä»¶

    Args:
        output_dir: è¾“å‡ºç›®å½•
        repo_name: ä»“åº“åç§°
        module_dirs: æ¨¡å—ç›®å½•åˆ—è¡¨
        generated_files: å·²ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨
        justdoc_compatible: æ˜¯å¦å…¼å®¹JustDocæ ¼å¼

    Returns:
        ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨
    """
    from pathlib import Path

    if not module_dirs:
        return generated_files

    new_files = []

    for module_dir in module_dirs:
        dir_path = Path(output_dir) / module_dir
        if not dir_path.exists():
            continue

        index_file = dir_path / "index.md"

        # ç”Ÿæˆç´¢å¼•å†…å®¹
        content_parts = []
        if justdoc_compatible:
            content_parts.append(f"---\ntitle: {module_dir.replace('_', ' ').title()}\ncategory: {repo_name}\n---\n")

        content_parts.append(f"# ğŸ“ {module_dir.replace('_', ' ').title()}")
        content_parts.append(f"\næ¨¡å—ç›®å½•: `{module_dir}`\n")

        # åˆ—å‡ºæ¨¡å—æ–‡ä»¶
        md_files = [f for f in dir_path.glob("*.md") if f.name != "index.md"]
        if md_files:
            content_parts.append("## æ¨¡å—åˆ—è¡¨\n")
            for md_file in sorted(md_files):
                module_name = md_file.stem.replace("_", " ").title()
                content_parts.append(f"- [{module_name}]({md_file.name})")

        # å†™å…¥ç´¢å¼•æ–‡ä»¶
        index_content = "\n".join(content_parts)
        with open(index_file, "w", encoding="utf-8") as f:
            f.write(index_content)

        new_files.append(str(index_file))

    return generated_files + new_files
